
======= 数理基础-1 =======

题目1：1、问：甲、乙两地相距S，火车A以20的速度从甲开向乙，火车B以15的速度从乙开向甲，A上有一只小鸟以30的速度和A同时出发，小鸟碰到另一辆火车的时候立刻调头，问：火车AB相遇的时候，小鸟飞了多少距离？（腾讯）
答案：S*(10/21)
解析：在小鸟开始飞行至火车AB相遇的时间轴中有两个关键节点：小鸟与火车B相遇，火车AB相遇。以下从这两个关键节点进行分析求解。
1） 小鸟与火车B相遇
小鸟与火车B相遇时，小鸟总飞行时长为S/(30+15)=S/45，其飞行距离为S(30/45)=S(2/3)。
2） 火车AB相遇
火车AB相遇时，小鸟总飞行时长为S/(20+15)=S/35。因此，小鸟自与火车B相遇至火车AB相遇之间飞行时长为S/35-S/45=S(2/315)，其飞行距离为[公式:图片说明|https://www.nowcoder.com/equation?tex=-S%5Ctimes(30%5Ctimes2%2F315)%3D-S%5Ctimes(4%2F21)]  。所以小鸟总飞行距离为S(2/3)-S(4/21)=S(10/21)。
二、随机变量

题目2：1、问：面对大方差如何解决？（滴滴出行）
答案：● AB实验场景下，如果一个指标的方差较大表示它的波动较大，那么实验组和对照组的显著差异可能是因为方差较大即随机波动较大。解决方法有：PSM方法、CUPED(方差缩减)
● 机器学习场景下，特征的方差反而越大越好，因为如果一个特征方差为0，那么其实这个特征对于模型来说没有什么意义，所以特征方差大对于模型的训练才是有帮助的
解析：● PSM倾向值匹配方法（Propensity Score Matching)：观测性研究有时无法人为控制干扰因素，因此可能会导致因果推断的偏差。 常规的解决思路是尽量模拟随机试验, 这样实验组与对照组在结果变量上的差异就可归因与实验条件的改变而非干扰因素或协变量施加的影响。PSM基于反事实因果模理论发展而成，属于因果推断的一种，相当于人为去造一个理想的实验环境
● CUPED方差缩减方法（Controlled-experiment Using Pre-Experiment Data）：先分层计算后汇总，举个例子，我们计算对照组和实验组的用户平均使用时长，可以分别按照城市划分，先计算每个城市的用户平均使用时长，然后再按照权重(各城市实验用户)计算总的。(前提是城市这个特征与用户平均使用时长高度相关)

题目3：2、问：数据分析指标的阈值怎么确定？（携程）
答案：人为划定：根据过往经验设定阈值
统计分类：基于统计分类结果设定阈值
自动选择：通过数据挖掘方法确定阈值
解析：指标阈值的确定是业务中最常遇到的问题，确定指标阈值主要可以考虑人为划定、统计分类、模型自动选择三种方法。
对于一些有明确目的或者是凭借过往经验可直接判断的阈值标准，就可以人为划定。这种方法的优势在于简单便捷成本低。
而对于有一定业务知识但是历史经验不足的情况，可以在人为划定的基础上加入统计学原理，用统计分类的思想进行指标阈值确定。这种情况下需要掌握数据的整体情况，了解数据指标的基本分布，根据数据分位数、3-sigma原则、统计指标的拒绝域等进行划分。这种方法既包含了对业务指标有多了解，又用到了统计分析的科学方法，具备科学性和稳定性。
而在数据维度多、指标数量大的情况下，上述两种方法则变得十分困难，此时可以通过机器学习的方法让模型自动调整参数，确定最优阈值。这个过程中最常用的方法有分类、聚类、关联、回归，每种方法下都有多个模型可以进行选择，根据各类模型的评价指标进行参数选择、阈值确定。

题目4：3、问：如何不用自带函数统计一段话每个单词出现的次数（招联金融）
答案：sentence = 'xxx xx x'

 words = sentence.split()

 dic = {}

 for w in words:

 if w in dic:

                dic[w] += 1

    else:
                dic[w] = 1

 for w, cnt in dic.items():

    print('单词%s出现%d'%(w,cnt))
解析：python能够便捷地处理文本相关的问题。在统计词频时，首先将语句拆分为一个个单词，然后将单词写入字典并统计每个单词出现的次数，最终输出即可。
对于有大小写的情况，可以先用lower函数统一转成小写后进行统计。

题目5：4、问：SQL中如何利用replace函数统计给定重复字段在字符串中的出现次数？（拼多多）
答案：##All_String表示完整字符串，Target_String表示待统计的目标字段

 select (

    length('All_String')-    

    length(replace('All_String',

    'Target_String',''))     

    )/length('Target_String') as cnt  

 from table
解析：此处我们用All_String表示完整字符串，用Target_String表示待统计的目标字段。
解题的基本思想是：字符串的总长度减去去掉目标字段的字符串长度，就得到了目标字段出现的总长度，除以目标字段长度就得到目标字段出现次数。SQL中提供了获取字符串长度的函数length( )以及从字符串里删除字符的函数replace( )。
● length('All_String') 用来计算字符串的总长度；
● length(replace('All_String','Target_String','')) 首先将字符串中目标字段替换为空然后再计算替换后的字符串长度；
● (length('All_String')-length(replace('All_String','Target_String',''))) 两个长度相减则得到重复字段在字符串中出现的总长度；
●(length('All_String')length(replace('All_String','Target_String','')))/length('Target_String') 在重复字段总长度的基础上除以单个重复字段长度则得到重复字段的出现次数。

题目6：5、问：常见的统计分析方法有哪些？（锐明科技）
答案：● 描述统计
    ○ 数据的概括性度量(集中趋势、离散趋势、偏态和峰度等)、数理统计(概率分布等)
● 推断统计
    ○ 检验统计量及抽样分布、参数估计、假设检验，以及它们间的联系和区别
    ○ 重点关注假设检验的思想及使用场景，以及一些重要的概念(第一类和第二类错误、置信区间和置信度)
● 列联分析与独立性检验
● 方差分析
    ○ 方差分析是通过检验各总体的均值是否相等来判断分类型自变量是否对数值型因变量有影响
● 相关分析与回归分析
    ○ 相关分析是相关关系，回归分析是因果关系，各自的使用场景
● 主成分分析与因子分析
● 时间序列分析
● 非参数检验
解析：● 假设检验在工作之后更重要的一个应用就是AB实验。AB实验是快速验证策略是否有效的方法，其中涉及的大量统计学知识以及实验步骤：确定目标及假设、确定指标、确定实验单位、样本量估算、测试时间估算、实施测试、分析测试结果等
● 参数估计和假设检验的联系是：
    ○ 参数估计和假设检验都是样本去估计总体，都是建立在概率基础上的统计，可以相互转换
● 参数估计和假设检验的区别是：
    ○ 参数估计是用样本统计量估计总体参数的方法；假设检验是先对总体参数提出一个假设，然后利用样本信息去检验这个假设是否成立
    ○ 参数估计是以置信区间(大概率)估计总体参数；假设检验是利用小概率事件是否发生来判断假设是否成立


======= 数理基础-2 =======

题目1：6、问：统计学的基本方法论，也就是拿到数据怎么分析？（京东数科）
答案：统计学是一门综合性的学科，会通过收集、处理、分析、描述等一系列步骤从数据中得出结论。以下分别介绍包括描述统计和推断统计在内的统计学的基本方法论，以这两种方法论为分析主线能够较为全面地对数据进行分析。
1） 描述统计
描述统计通过图表或数学方法，对样本数据进行整理、分析，然后概括总结出反映客观现象的规律。其中图表描述方法就是使用各类图表在不同的维度下描述数据，比如直方图、饼图、雷达图、散点图等等。而数学描述方法的分析方法更丰富，常有集中趋势分析、离散程度分析、相关分析三种分析方法。
A. 集中趋势分析
平均数、中数、众数等是集中趋势分析常用来表示数据集中趋势的统计指标，通过这些指标能够反映样本数据的一般水平。
B. 离散程度分析
离中趋势分析主要依赖标准差、方差（协方差）等统计指标来研究数据的离散程度，能够出色地表示数据之间的差异程度。
C. 相关分析
无论是自变量与自变量之间还是自变量与因变量之间都存在潜在地关联性，相关分析探讨的就是变量之间是否具有统计学上的关联性。进行相关分析时，变量数量可以是两个也可以是多个，能够进行单一或多重相关关系分析。
2） 推断统计
推断统计是一种通过样本数据来推断总体特征的统计方法，以部分抽样样本进行延伸推论，并进一步给出推理性结论。
A. 参数估计
顾名思义，参数估计就是根据样本数据对总体参数进行估计的过程，可分为点估计和区间估计两种分析方法。点估计是以样本具体数值为代表数据，区间估计是根据样本数据，计算置信区间及该区间的置信度。
B. 假设检验
假设检验是一种先假设后推理论证检验的思想。首先对总体参数提出一个假设，然后基于样本数据判断该假设是否成立，做出接受还是拒绝该假设的结论。
解析：

题目2：7、问：如何用统计学的角度看待新冠疫情？（用统计学知识对疫情相关指标进行分析/解释）（京东数科）
答案：新冠病毒潜伏期（统计学知识点：数据分布）
疾病的潜伏期通常可以用对数正态分布来近似，我们现阶段采取的隔离措施是将一般潜伏期设定为14天内，但是在后续的病例中我们发现个别患者的潜伏期长达24天，并不是病毒发生了变异，而是新冠病毒的潜伏期实际呈右偏状态，属于长尾分布，较长潜伏期的病例并非不会出现，而是概率很小。
新冠病毒传播（统计学知识点：随机过程）
病毒传播实际上是一个随机事件，这一过程可以用随机微分方程来进行模拟，比如SEIR模型。
（1）易感状态S （Susceptible）∶表示潜在的可感染个体。在以往的一些文章中，会有学者将S设置为一个地区的总人口数，导致模型中的感染人数预测结果偏高，这是因为实际上只有有机会接触到感染者的个体才属于易感人群，因此易感状态个体的数量最好由实际数据去拟合。
（2）潜伏状态E（Exposed）∶已被感染但尚未表现出感染症状的个体。
（3）感染状态I（Infected）∶已有感染症状并且可以将疾病传染给其他人的个体。
（4）移除状态R（Removed）∶已经治愈并获得免疫力或已经死亡等不会再被传染的个体。记N为人群中个体的总数量，则有N = S＋E＋Ⅰ＋R。
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210701/897353_1625141375958/77D1872C1B5DE1405253E42454EDE678] 
新冠患者诊断（统计学知识点：模型评价）
疫情期间，随着病毒不断传播，全国各地每天都在进行核酸检测与病例诊断，但现阶段我们无法完全准确地区别出病例，这就有可能导致误诊。各种检测手段和医生的诊断结合起来类似一个判别模型，患者的各项指标输入到这个模型得出最终的分类结果，患者的实际患病情况和医生的诊断结果共同构成混淆矩阵，当误诊率越低，说明当前的模型（诊断方法）越好。
疫情分析观测指标（统计学知识点：基本统计指标）
感染率=感染人数/总人口数
病死率=因某种病死亡人数/患病人数
死亡率=因某种疾病死亡人数/总人口数=感染率*病死率
解析：

题目3：8、简述方差分析概念（京东）
答案：参考回答
方差分析（Analysis of variance，简称ANOVA）为数据分析中常见的统计模型，主要为探讨连续型因变量与类别型自变量的关系，当自变量的因子中包含等于或超过三个类别情况下，检验其各类别间平均数是否相等的统计模式。广义上可将T检验中方差相等的合并T检验视为是方差分析的一种，基于T检验为分析两组平均数是否相等，实际上当方差分析套用在合并T检验的分析上时，产生的F值则会等于T检验的平方项。
方差分析依靠F-分布为概率分布的依据，利用平方和与自由度所计算的组间与组内均方估计出F值，若有显著差异则考量进行事后比较或称多重比较。
在方差分析的基本运算概念下，依照因子数量而可分为单因子方差分析、双因子方差分析、多因子方差分析三大类；依照因子的特性不同而有三种型态，固定效应方差分析、随机效应方差分析与混合效应方差分析。
方差分析优于两组比较的T检验之处，在于后者会导致多重比较的问题而致使第一型错误的机会增高，因此比较多组平均数是否有差异则是方差分析的主要命题。
在统计学中，方差分析是一系列统计模型及其相关的过程总称，其中某一变量的方差可以分解为归属于不同变量来源的部分。其中最简单的方式中，方差分析的统计检验能够说明几组数据的平均值是否相等，因此得到两组的T检验。在做多组双变量T检验的时候，错误的概率会越来越大，特别是第一型错误，因此方差分析只在二到四组平均值的时候比较有效。
解析：

题目4：9. 商城每天的人流量属于什么分布？泊松分布和二项分布的关系？（猿辅导）
答案：参考回答
泊松分布。泊松分布是⼆项分布的近似，当⼆项分布的p很⼩，重复试验次数
n很⼤时,两者分布接近。
答案解析
二项分布指已知某件事情发⽣的概率是p，那么做n次试验，事情发⽣的次数就服从于二项分布。
泊松分布是指某段连续的时间内某件事情发⽣的次数，⽽且“某件事情”发生所用的时间是可以忽略的。
商场每天是⼀个连续的时间，如果把每⼀天分割成⽆数的⼩份，那么每⼀段时间内发生的事件都是独立的，在⼀个极小的时间内，⼈们进出的概率为p。那么在一天内，就有n次发⽣⼈们进出这个事件。⽽当n很⼤，p很⼩，二项分布计算概率的公式会趋向于泊松分布。
解析：二项分布指已知某件事情发⽣的概率是p，那么做n次试验，事情发⽣的次数就服从于二项分布。
泊松分布是指某段连续的时间内某件事情发⽣的次数，⽽且“某件事情”发生所用的时间是可以忽略的。
商场每天是⼀个连续的时间，如果把每⼀天分割成⽆数的⼩份，那么每⼀段时间内发生的事件都是独立的，在⼀个极小的时间内，⼈们进出的概率为p。那么在一天内，就有n次发⽣⼈们进出这个事件。⽽当n很⼤，p很⼩，二项分布计算概率的公式会趋向于泊松分布。

题目5：10、二项分布趋近泊松分布的n和p大概是多少，这个值怎么来的？（猿辅导）
答案：参考回答
泊松分布，二项分布都是离散分布。二项分布有两个参数，一个 n 表示试验次数，一个 p 表示一次试验成功概率。考虑一列二项分布，其中试验次数 n 无限增加，而 p 是 n 的函数，如果 np 存在有限极限 λ，则这列二项分布就趋于参数为 λ 的 泊松分布。
答案解析
二项分布描述的是发生次数，而不是量值。二项分布的公式如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210331/897353_1617172349988/1CE443BACD6B40A6CAB49C5919BFF705]
其中，n 是观测值数量，p 是发生概率，x 是成功次数（从 0 到 n）。如果 n 值较大且 p 值较小，则二项分布接近泊松分布。这种情况下使用泊松分布会更加简便。二项分布将返回代表 n 次试验中成功次数的随机变量，其中每次试验的成功概率为 p（例如，硬币正面朝上的概率为 p）。
泊松分布是一种离散型概率分布。泊松分布适合在给定一个已知平均值的情况下对固定时间步长内事件的发生次数概率进行模拟。泊松分布的公式如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210331/897353_1617172356980/4372E631AB7AABC06BEB3FF5C73B9324]
其中，e 是自然对数的底，x 是事件的可能发生次数（正整数），λ（平均值）是一个正数，代表指定区间内事件的预期发生次数。如果事件在 1 小时内（60 分钟）每 10 分钟发生一次，则 λ 为 6。
泊松分布与二项分布类似，但泊松分布是在不知道事件的可能发生总次数的情况下对小概率事件建模。例如，泊松分布的建模对象是十字路口的事故发生次数，而二项分布的建模对象是事故发生次数与经由十字路口的汽车数量之间的相对关系。
解析：二项分布描述的是发生次数，而不是量值。二项分布的公式如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210331/897353_1617172349988/1CE443BACD6B40A6CAB49C5919BFF705]
其中，n 是观测值数量，p 是发生概率，x 是成功次数（从 0 到 n）。如果 n 值较大且 p 值较小，则二项分布接近泊松分布。这种情况下使用泊松分布会更加简便。二项分布将返回代表 n 次试验中成功次数的随机变量，其中每次试验的成功概率为 p（例如，硬币正面朝上的概率为 p）。
泊松分布是一种离散型概率分布。泊松分布适合在给定一个已知平均值的情况下对固定时间步长内事件的发生次数概率进行模拟。泊松分布的公式如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210331/897353_1617172356980/4372E631AB7AABC06BEB3FF5C73B9324]
其中，e 是自然对数的底，x 是事件的可能发生次数（正整数），λ（平均值）是一个正数，代表指定区间内事件的预期发生次数。如果事件在 1 小时内（60 分钟）每 10 分钟发生一次，则 λ 为 6。
泊松分布与二项分布类似，但泊松分布是在不知道事件的可能发生总次数的情况下对小概率事件建模。例如，泊松分布的建模对象是十字路口的事故发生次数，而二项分布的建模对象是事故发生次数与经由十字路口的汽车数量之间的相对关系。


======= 数理基础-3 =======

题目1：11、简单说一下各种分布之间的关系？（猿辅导）
答案：二项分布的极限是泊松分布；几何分布的极限是指数分布；由正态分布导出的几个比较重要的分布有：
● 卡方分布：随机变量X1,X2,X3...相互独立，且X1,,X2,X3...都服从标准正态分布，那它们的平方和服从自由度为n的卡方分布
● t分布：设z服从标准正态分布，X服从自由度为n的卡方分布，那么[公式:图片说明|https://www.nowcoder.com/equation?tex=T%3Dz%2F%5Csqrt%7B%7D%5Cfrac%7Bx%7D%7Bn%7D] 服从自由度为n的t分布
● F分布：设随机变量U和V互相独立，且U和V分别服从自由度为n1和n2的卡方分布，那么[公式:图片说明|https://www.nowcoder.com/equation?tex=F%3D(U%E2%81%84n1)%2F(V%E2%81%84n2)] 服从第一自由度为n1，第二自由度为n2的F分布
解析：

题目2：12、简述逻辑回归概念（携程）
答案：Logistic 回归是二分类任务中最常用的机器学习算法之一，通过使用其固有的 logistic 函数估计概率，来衡量因变量与一个或多个自变量之间的关系。它输出一个 0 到 1 之间的结果。回归过程中使用到了Sigmoid 函数，这是一个 S 形曲线，它可以将任意实数值映射到介于 0 和 1 之间的值，然后使用阈值分类器将 0 和 1 之间的值转换为 0 或 1，最终得到离散结果。
解析：Logistic 分布是一种连续型的概率分布，其分布函数和密度函数分别为：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210512/897353_1620791854778/FF9E7AA9B8D57EF0663241CBE295041E]
其中， μ 表示位置参数， γ 为形状参数。其分布的形状与正态分布的形状相似，但是尾部更长，所以我们可以使用 Logistic 分布来模拟比正态分布具有更长尾部和更高波峰的数据分布。Sigmoid 函数就是 Logistic 的分布函数在μ=0,γ=1的特殊形式。
对于Logistic模型，考虑如下函数形式：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210512/897353_1620791885528/435D062F3BD55195E7C8D4A20047253E]
其中y 为 x 为正例的概率，则 1-y 为 x 为其反例的概率。两者的比值称为几率（odds），指该事件发生与不发生的概率比值，若事件发生的概率为 p。则对数几率：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210512/897353_1620791921747/6DE5520F5BC9A9608A0E8F52A7784A63]
将 y 视为类后验概率估计，重写公式有：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210512/897353_1620791937362/EFF7D3F50D87430770FDCE11B553B60E]
输出 Y=1 的对数几率是由输入 x 的线性函数表示的模型，这就是Logistic回归模型。

题目3：13、t分布是有什么分布构成的，表达式是什么（猿辅导）
答案：由中心极限定理可知，在样本量足够大时，统计量的样本均值符合正态分布。但是当样本量较小时，样本的标准差不能用于估计总体标准差。考虑到小样本量带来额外的不确定性，t分布诞生了，其概率密度函数如下：
[公式:  |https://uploadfiles.nowcoder.com/images/20210701/897353_1625141983094/B9F463E9D8EE72880D76139743A64D23]
t分布中n是自由度，[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210527/510094950_1622107355740/7829FF094CBF049302207AB4D8543D8F] 是伽马函数。t 分布类似于正态分布，比正态分布平坦分散，且随其自由度增大趋近于标准正态分布。
解析：

题目4：14、如何向小朋友们解释正态分布（联易融）
答案：如何向小朋友解释正态分布？
解析：因为成绩身高等这些数据都是符合大部分在中间，只有极少数分布在极大值或者极小值，画在图中是一个钟型的分布，也就是正态分布。正态分布是生活中最常见的分布，因为根据中心极限定理，不管总体的分布是什么，从均值为a,方差为b的任意一个总体中抽取样本量为n的样本，当n充分大时，样本均值的抽样分布近似服从均值为a,方差为b/n的正态分布

题目5：15、100个人，初始各有100块，每人每分钟随机给别人1块钱，问最后的分布（拼多多）
答案：均匀分布：在每个人发钱和得钱的概率及金额完全相等的情况下，最终的结果将是大家的财富值一样。（完全公平情况）
正态分布：根据中心极限定理说明，在适当的条件下，大量相互独立随机变量的均值经适当标准化后依分布收敛于正态分布。房间中的人多次交换金钱后剩余钱数的概率，每次实验均有多个人进行金钱交换。（但此处每个人之间并非独立的，他们手中的财富总值是一个常数）
幂律分布：在每个人发钱和得钱的概率及金额不等时，最终的财富分配是少数人掌握社会中大量的财富。（类似于现实生活中的社会财富分配）
解析：


======= 数理基础-4 =======

题目1：16、随机误差的分布（同盾科技）
答案：正态分布（高斯分布）
解析：根据中心极限定理，大量独立的随机变量之和趋向于某个稳定的分布，该分布后来被人们称作正态分布（高斯分布）。人们认为误差是随机的，所以误差的和服从正态分布。

题目2：17、简单说一下两类错误（猿辅导）
答案：第一类错误α叫弃真错误或显著性水平，即原假设为真时却被我们拒绝的概率；第二类错误β叫采伪错误，即原假设为伪我们没有拒绝的概率。在一定样本量的情况下，减小一类错误必然会增大另一类错误，在实践中我们一般会优先控制第一类错误，因为原假设是非常明确的
解析：1-第一类错误也即原假设为真的情况我们接受的概率，对于A/B测试，犯这个错误代表新策略没有收益，我们却认为有收益，然后上线的错误，一般第一类错误不超过5%，第一类错误是明显的，也就是说在原假设为真的情况下接受原假设的概率要超过95%；统计功效=1-第二类错误，也即当AB两组实际有差异时,能被我们检测出来差异的概率

题目3：18、简单说一下说说置信区间、置信度（滴滴、广联达）
答案：为了降低测量误差，通常多次实验并取其平均值。为了评估一名射击运动员的真实水平，经过一次测试，他射击10次的平均值为8环，那8环就能代表他的真实水平了吗？当然不能这么简单得出结论，有可能再经过一次测试，他射击的平均水平就变成了7环。在这种情况下，不能简单地进行运动员射击水平的点估计，而是给出一个可信度及在此置信度下对射击水平进行估计的置信区间[a,b]。由此引出置信区间和置信度，接下来介绍置信区间和置信度的概念。
在概率统计中进行参数的区间估计时，会涉及确定置信度和计算置信区间的过程。那置信度到底是什么呢？在科学实验中经过多次抽样（一次抽样有多个数据，一次抽样构建一个置信区间），重复构建多次的置信区间中覆盖总体参数真值的次数所占比例为置信度，也称为置信水平或置信系数。置信度通常有90%、95%和99%，由于95%的置信度计算出来的置信区间具有较高的可信度，而且波动幅度相对不会太大，在区间估计中普遍会将置信度设置为95%。在此置信度下，再由样本统计量对总体参数进行区间估计得到置信区间。
假设样本总体符合正态分布，即满足[公式:图片说明|https://www.nowcoder.com/equation?tex=X~(%CE%BC%2C%CF%83%5E2)] 。由中心极限定理可知样本均值符合正态分布，计算得到X~(μ,σ^2/n)  。基于确定的置信度查询Z表即标准正态分布表，确认Z值。因此置信区间可确定为[μ-Z σ/√n,μ+Z σ/√n]  ，其中 μ 为样本统计量的期望， σ 为样本统计量对样本整体标准差的估计值。
解析：

题目4：19、协方差是啥，怎么判断协方差正负（滴滴）
答案：[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210331/897353_1617179461124/EB18A2DCBB196EE82188D26C833ABC14]
解析：

题目5：20、说一下辛普森悖论的例子吧（拼多多）
答案：[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210331/897353_1617178773930/B183324FB91D117F0E7A1FBDFE3D23A7]
美国加州大学伯克利分校研究生录取数据中，男生录取率为44%，女生录取率为35%，那能依据这一观测数据，认为伯克利分校研究生录取存在性别歧视吗？
Bicke 对此做了研究，他发现，虽然总体上，男生录取率高于女生，但是拆开专业后发现，几乎每个专业均是女生的录取率更高。
为什么你比较总体结论与比较总体各部分的结论会存在差异呢？因为男女生在专业上的分布不一样，男生主要集中在录取率较高的专业，女生主要集中在录取率较低的专业，这样整体看来，就是女生录取率更低了。
解析：


======= 数理基础-5 =======

题目1：21、相关系数（字节跳动）
答案：协方差的大小受变量的相关程度及变量的方差影响，并不能真实反映两个变量的相关程度，而统计学家皮尔逊为了充分反映变量之间线性相关程度，设计了相关系数这一应用广泛的统计指标。其公式如下：
[公式:图片说明|https://www.nowcoder.com/equation?tex=%CF%81%3D(COV(X%2CY))%2F(%CF%83_X%20%CF%83_Y%20)%3D(E%5B(X-%CE%BC_X%20)(Y-%CE%BC_X%20)%5D)%2F(%CF%83_X%20%CF%83_Y%20)] 相关系数在协方差基础上进行了标准化，消除了两个变量变化幅度的影响，能够充分反应两个变量的相关关系。与协方差不同的是，相关系数的波动范围是有限的，上下浮动范围是[-1,1]。相关系数越趋近于0，表示两个变量相关程度越弱。相关系数越接近于1，两个变量的正相关程度越高。相关系数越接近于-1，两个变量的负相关程度越高。
解析：

题目2：22、如何估计样本量（字节跳动）
答案：按照功效分析的方法，根据预期的功效、效应值、显著性水平来计算样本大小。
解析：当我们在设计一个实验的时候，需要考虑很多问题，其中一个就是实验流量的分发大小，也就是这个实验中需要需要多少样本才能有意义。
这类问题可以通过功效分析（power analysis）来进行计算，在实验前计算得到所需要的样本量，或者预估在给定样本量下得到不同实验效果的概率。功效分析可以帮助在给定显著性水平的情况下，判断检测到给定效应值时所需的样本大小。 反过来， 它也可以帮助你在给定显著性水平情况下，计算在某样本大小内能检测到给定效应值的概率。
我们在功效分析中一般关注四个量：功效、样本大小、效应值、显著性水平，当我们给定任意三个量后，就可以推算出第四个量。比如，在给定功效、显著性水平、效应值的情况下，我们可以推算需要多大的样本量。
样本大小指的是实验设计中每种条件/组中观测的数目。
显著性水平由Ⅰ型错误的概率来定义，也就是α。
功效通过1减去Ⅱ型错误的概率来定义，我们可以把它看作真实效应发生的概率。
效应值指的是在备择或研究假设下效应的量，效应值的表达式依赖于假设检验中使用的统计方法。

题目3：23、辛普森悖论，以及如何避免这种现象（字节跳动）
答案：⾟普森悖论指在某个条件下的两组数据，分别讨论时都会满⾜某种性质，可是⼀旦合并考虑却可能导致相反的结论。为了避免⾟普森悖论导致我们得出两个相反的结论，我们需要选择将数据分组或将 它们聚合在⼀起。其中我们要学会思考因果关系：数据如何⽣成，基于此，哪些因素会影响我们未展示的结果？
例如之前说到的例子，目的是探究伯利克里分校研究生录取是否存在性别歧视。即性别与录取率的关系。但是性别会导致兴趣的不同，而兴趣会决定专业的不同，不同专业的录取率也会不同。总体上，我们只看到了性别和录取率的关系，但是却忽略了专业这个内在原因。而拆分专业去观察，就是控制男女在专业上是相同的，这样更有利于判断因果关系。
解析：

题目4：24、作为出行领域的小玩家，司机端的订单构成是什么样的? 头部优秀司机聚集大量订单，还是订单分布比较发散。（滴滴）
答案：若为较成熟健康的体系中，应为后者；在初期时为前者。
解析：在较健康的供给端体系中，司机端的订单构成应为倒三角或者菱形分布，即头部和腰部司机的订单较多，尾部的订单较少；而在初期时则是头部效应明显，订单集中在头部，后期随着司机和订单量的增多，不可能由头部司机撑起大部分订单的。

题目5：25、说一下t检验，z检验和卡方检验的原理，及其适用条件。（拼多多）
答案：原理：
t检验：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617777450136/393296A0118F70B5388090890903FEDB]
z检验：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617777456986/5340A05145C5D38905918B1CEFC7A32E]
卡方检验：
[公式:  |https://uploadfiles.nowcoder.com/images/20210407/897353_1617777503277/3173320C5B672B690A25DDF283CB9E61]
Ai为实际频数(出现的次数)，Ti为理论频数
适用条件：
一般用于大样本（即样本容量大于30）平均值差异性检验的方法。它是用标准正态分布的理论来推断差异发生的概率，从而比较两个平均数的差异是否显著。
T检验是一种适合小样本的统计分析方法，通过比较不同数据的均值，研究两组数据是否存在差异
卡方检验是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为0，表明理论值完全符合。
解析：


======= 数理基础-6 =======

题目1：26、ARIMA模型原理(猿辅导)
答案：ARIMA由AR（自回归）、I（差分）、MA（移动平均）三个部分组成。
1） AR模型
自回归描述的是序列中历史观测值与当前值拥有紧密的关系，可以通过历史值对当前值进行预测，AR模型将当前值看作p阶历史观测值的线性组合：
[公式:  |https://www.nowcoder.com/equation?tex=X_t%3D%CE%B1_1%20X_(t-1)%2B%CE%B1_2%20X_(t-2)%2B%E2%8B%AF%2B%CE%B1_p%20X_(t-p)%2Bu_t]
其中[公式:图片说明|https://www.nowcoder.com/equation?tex=u_t] 为随机扰动项。
解析：

题目2：27、几何平均是什么？（滴滴）
答案：几何平均数是一种均值，等于n个变量值乘积的n次方根，多用于计算平均比率、平均速度等。主要分为简单几何平均和加权几何平均。
解析：简单几何平均：
[公式: |https://uploadfiles.nowcoder.com/images/20210406/897353_1617694009300/92376EBDD1AF76015644725FE7D99DC6]
加权几何平均：
[公式: |https://uploadfiles.nowcoder.com/images/20210406/897353_1617694017179/E00C8762815E2701A670800701C0FDF8]
其主要特点有：
（1）受极端值影响较小，小于算术平均数；
（2）若变量值有负数，计算出的几何平均数可能会出现负数或虚数；
（3）仅适用于等比或近似等比关系的数据；
（4）几何平均数的对数是个变量值对数的算术平均数。

题目3：28、协方差的定义？（滴滴）
答案：协方差（Covariance）用于衡量两个随机变量的联合变化程度。如果变量X的较大值主要与另一个变量Y的较大值相对应，而两者的较小值也相对应，则可以说，两个变量倾向于表现出相似的行为，协方差为正。在相反的情况下，当一个变量的较大值主要对应于另一个变量的较小值时，则两变量倾向于表现出相反的行为，协方差为负。协方差为0的两个随机变量称为是不相关的。
解析：协方差公式：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694066394/6D5DFAD169E3066CE830E0E1E2FCEC1A]
协方差图像：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694074671/E42997A2A167E5B0F7674332A85499D3]
协方差的性质：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694087028/8C1AADB7760087D7CFC2A5B989C72431]
三、中心极限定理

题目4：1、中心极限定理（快手）
答案：中心极限定理：设从均值为a，方差为b ** 2的任意一个总体中抽取样本量为n的样本，当n充分大的时候，样本均值的抽样分布近似服从均值为a，方差为b ** 2/n的正态分布，也就是说不管总体的分布是什么，样本均值的分布总是接近正态分布
解析：有了中心极限定理，我们就可以把业务中的大部分指标都近似成正态分布了。这一点非常重要，因为 A/B 测试中的很多重要步骤，比如计算样本量大小和分析测试结果，都是以指标为正态分布为前提的。均值类的指标比如用户平均使用时长、平均购买金额，概率类的比如点击率、购买率等等，在数据量足够大的时候都服从正态分布，概率类的本质上服从二项分布，但在数据量足够大时，也服从正态分布
四、概率计算

题目5：1、贝叶斯定理是什么？（滴滴）
答案：贝叶斯定理（Bayes' theorem）是概率论中的一个定理，描述在已知条件下，某事件的发生概率。通常，事件A在事件B已发生的条件下发生的概率，与事件B在事件A已发生的条件下发生的概率是不一样的。然而，这两者是有确定的关系的，贝叶斯定理就是这种关系的陈述。贝叶斯公式的一个用途，即透过已知的三个概率而推出第四个概率。贝叶斯定理跟随机变量的条件概率以及边际概率分布有关。
解析：贝叶斯定理涉及到的相关公式如下：
（1）全概率公式：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694168091/631B75CAB25121583ED52C1C2F2E08A2]
（2）双状态下的贝叶斯公式：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694174929/1F68003628EB1A0B6BEFFA5D403D082A]
（3）多状态下的的贝叶斯公式：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694180911/A439FC5C26A3A39E5164DF4D7E22DF5E]
贝叶斯定理常用在信息检索、文本分类、疾病检测等场景。
应用举例（疾病检测）：
假设一个常规的检测结果的灵敏度和特异度均为99%，即患病者每次检测呈阳性（+）的概率为99%，而未患病者每次检测呈阴性（-）的概率为99%。假设医院对全体就诊人员进行疾病检测，已知0.5%的就诊者患病，请问每位检测结果呈阳性的就诊者患病的概率有多高？
令“D”为就诊人员患病事件，“N”为就诊人员未患病事件，“+”为检测呈阳性事件，则某人检测呈阳性时确实患病的条件概率为：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694192463/817024ABE7E7F0C1E3A14485E6961B59]


======= 数理基础-7 =======

题目1：2、对朴素贝叶斯的理解？（快手）
答案：朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。“朴素”是指假定给定目标值时属性之间相互条件独立。
解析：由于各属性之间相互独立，可以得到朴素贝叶斯计算公式为：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617694949272/D4492FEF0B6F2B61921A6DC7ED11802C]
优点：朴素贝叶斯算法假设了数据集属性之间是相互独立的，因此算法的逻辑性十分简单，并且算法较为稳定，当数据呈现不同的特点时，朴素贝叶斯的分类性能不会有太大的差异。即朴素贝叶斯算法的稳定性比较好，对于不同类型的数据集不会呈现出太大的差异性。当数据集属性之间的关系相对比较独立时，朴素贝叶斯分类算法会有较好的效果。
缺点：数据集属性的独立性在很多情况下是很难满足的，因为数据集的属性之间往往都存在着相互关联，如果在分类过程中出现这种问题，会导致分类的效果大大降低。

题目2：3、两个人相约在8点到9点时间段见面，彼此等15分钟，见不到人就走。两人在8点至9点任一时刻到达目的地，求两人能见面的概率（bigo）
答案：7/16
解析：几何概型。在平面坐标系下，0<x,y<1，|x-y|<15/60，满足条件的面积即为1-3/4 * 3/4=7/16

题目3：4、抛硬币直到连续两次出现正面的概率，求扔的期望次数（猿辅导）
答案：6次
解析：假设期望次数为X，有三种情况：1.第一次为反面，则期望需要X+1次；2.前两次都为反面，则期望需要X+2次；3.前两次均为正面，结束。建立方程：[图片:https://www.nowcoder.com/equation?tex=X%3D0.5*(X%2B1)%2B0.5*0.5*(X%2B2)%2B0.5*0.5*2&preview=true]；解得X=6。

题目4：5、50个红球50个白球放入两个黑箱，怎么分配摸到红球概率最大（百度）
答案：1个红球放在一个箱子，其余99个球放在另一个箱子里。
解析：该情况下，P（拿到红球）=0.5+0.5（49/99）≈ 0.75（74/99）


======= 数理基础-8 =======

题目1：6、概率几大学派（拼多多）
答案：比较常见的统计学派分为：频率学派、贝叶斯学派、似然学派，各学派的区别如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210406/897353_1617695705634/2D91C8001CC5AD73693987A2CA1D0131]
解析：

题目2：7、一个班20个人，至少两个人同一天生日的概率。（猿辅导）
答案：0.41
解析：● 20个人可能的生日组合是365×365×365×……×365(20)个；
● 20个人生日都不重复的组合是365×364×363×……×346(20)个；
● 20个人生日有重复的概率是1-b/a。
这里，20个人生日全不相同的概率是b/a=0.59，因此50个人生日有重复的概率是1-0.59＝0.41

题目3：8、次品率千分之一，取1000次，得到2个次品率的概率。（猿辅导）
答案：[公式:  %E3%80%97%5E2%20%E3%80%96(999%2F1000)%E3%80%97%5E999 "图片标题") |https://uploadfiles.nowcoder.com/images/20210701/897353_1625142475642/B291B6A1052BE18C7CCF76FD7CA5E680]
解析：

题目4：9、某个概率分布的期望方差。（携程）
答案：[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617777904440/1434B04FF5F41B480E0910F6D805FB29]
解析：

题目5：10、100次掷硬币60次朝上，可以认为正反概率相等吗？（拼多多）
答案：可以认为在100次抛硬币事件中，正反的频率是不相等的。
解析：考察概率与频率的区别与联系。频率一般是大概统计数据经验值, 概率是系统固 有的准确值；频率是近似值,概率是准确值


======= 数理基础-9 =======

题目1：11、条件概率的概念（滴滴）
答案：假设我们已知A事件发生，想要在此基础上求出B事件发生的概率时，需要考虑构建条件概率P(A|B)，即A事件发生条件下B事件发生的概率。条件概率的计算公式为：P(A|B)=P(AB)/P(B)。
解析：

题目2：12、概率和似然是什么（字节跳动）
答案：概率（probability)和似然（likelihood)，都是指可能性，都可以被称为概率，但在统计应⽤中有所区别。
1.概率是给定某⼀参数值，求某⼀结果的可能性的函数。
例如，抛⼀枚匀质硬币，抛10次，6次正⾯向上的可能性多⼤？
解读：“匀质硬币”，表明参数值是0.5，“抛10次，六次正⾯向上”这是⼀个结果，概
率（probability)是求这⼀结果的可能性。
2.似然是给定某⼀结果，求某⼀参数值的可能性的函数。
例如，抛⼀枚硬币，抛10次，结果是6次正⾯向上，其是匀质的可能性多⼤？
解读：“抛10次，结果是6次正⾯向上”，这是⼀个给定的结果，问“匀质”的可能性，
即求参数值=0.5的可能性。
解析：

题目3：13、两个孩子，已知一孩子是男孩，另一孩子是男孩的概率。（字节跳动）
答案：1/2或者1/3
解析：1/2：两者为独立事件，互不影响，故为1/2；
1/3：如果区分顺序两个孩子可能为：男男，男女，女男，女女；已知其一为男孩，则可能为：男男，男女，女男；男男的概率为1/3

题目4：14、说一下显著性水平（滴滴）
答案：显著性水平是估计总体参数落在某一区间内，可能犯错误的概率，一般用α表示。即原假设为真，但是却拒绝原假设的概率。
解析：

题目5：15、简单讲一下三门问题（拼多多）
答案：A=你选中了⻋，B=打开了⼀扇有⽺的⻔
在条件B下A的概率，有⻉叶斯公式：[公式:   |https://uploadfiles.nowcoder.com/images/20210407/897353_1617778821000/F675E02A26A795B7D531062AB667D462]
 B事件已经发⽣了，所以B事件其实是和A⽆关的[公式:  |https://uploadfiles.nowcoder.com/images/20210407/897353_1617778832841/85E26B7271D03D76CCEE854D0C1F3E83]
以上代⼊得[公式:  |https://uploadfiles.nowcoder.com/images/20210407/897353_1617778386613/B240A63CD2EFC28EE181D767642C5CAF]
所以主持⼈根本就是个幌⼦，这⾥的关键是P(A)到底等于多少。
P(A)的计算在这个问题⾥依据古典概型：[公式:  |https://uploadfiles.nowcoder.com/images/20210407/897353_1617778368542/616C8833C6FDA9CD4872761F4883E3CA]
得出1/2的结论其实是把事件的顺序弄反了，你先选然后主持⼈再选，跟主持⼈先选
你再选是不⼀样的：
如果你先选，那么你选中⻋的概率就是1/3 ，所以⻋在除这个⻔之外的⻔⾥
的概率2/3 ，然后只剩⼀个⻔了，换之后有⻋的概率就是2/3。
如果主持⼈先选，那么你选中⻋的概率就是1/2，所以换之后选中⻋的概率也是
1/2，换不换都⼀样。 所以主持⼈的⾏为只是改变了古典概型的基本事件总数罢了。
可以看⼀下4个⻔的情况，你先选，选中⻋的概率 1/4，⻋在除这个⻔之外的⻔⾥的概率
3/4， 主持⼈开了⼀个⻔，还剩两个⻔，所以随便换⼀个⻔有⻋的概率是 3/8。
如果主持⼈⼀个⻔都不开，那么随便换⼀个⻔有⻋的概率是 1/4，符合直觉。
如果主持⼈开了两个⻔，还剩⼀个⻔，那么跟前⾯3个⻔⼀样就是3/4。
所以换⻔有⻋的概率其实是[公式:  |https://uploadfiles.nowcoder.com/images/20210407/897353_1617778351278/E358480D44D22D426257F19CB2D3D459]
解析：


======= 数理基础-10 =======

题目1：16、请你说说假设检验是什么（滴滴、拼多多、字节跳动）
答案：假设检验是先对总体参数提出一个假设值，然后利用样本信息判断这一假设是否成立；假设有原假设，备择假设；检验方式有单侧检验和双侧检验；其步骤通常为：提出原假设与备择假设；从所研究总体中出抽取一个随机样本；构造检验统计量；根据显著性水平确定拒绝域临界值；计算检验统计量与临界值进行比较。
解析：

题目2：17、AB实验实例，假设检验的应用（拼多多）
答案：案例分析:
某网网站优化了商品详情⻚，现在新旧两个版本同时运行，新版页面覆盖了10%的⽤户，旧版覆盖90%的⽤户。现在需要了解，新版页面是否能够提⾼商品详情页到支付页的转化率，并决定是否要覆盖旧版，你能为决策提供哪些信息，需要收集哪些指标，给出统计方法及过程。
1.收集指标,建立指标体系
宏观KPI指标:GMV,订单量等,衡量业务增长用户体验辅助指标:页面点击率,页面平均停留时长,跳出率等,量化用户行为,判断实验对⽤户体验的影响实验预期提升指标:商详转化率
2.分配流量,AA实验
实际AB实验中可能出现抽样不均的情况,例如实验组恰好有很多土豪,那么结果就会产生偏差,为了保证实验数据的变化仅仅是实验本身引起的,可以⼀次性抽取4,5组流量,选择任意两组不加策略空跑,监控核心指标数据,选取两组数据最接近的上实验(控制变量)
3.假设检验
(1)通过确定实验周期(⼀般为7天),可以通过用户使⽤频率来判断产品周期
(2)确定实验所需样本量
如何决定样本的数量？太多了会浪费很多 资源，太少了会因为统计灵敏度太低而得到不显著的结论。
利用第⼀类错误α不超过5%,即Significance Level(显著性⽔平) = 5%。
第⼆类错误β不超过20%,即Statistical Power(统计功效) = 1 -β = 80%
直观上理解,AB两组即使有差异，也不⼀定能被你观测出来，必须保证⼀定的条件（比如样本要充⾜）才能使你观测出统计量之间的差异; 而统计功效就是当AB两组实 际有差异时,能被我们检测出来差异的概率(当备择假设为真,我们接受的概率)
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617781169728/C236B0FC013130B5CEA35D49C419B469]
AB实验时，要同时满足，且相对差值满足阈值条件。（相对差值:绝对差值对照组均值 >= 阈值） 相当于在部分情况下，要更小的P值才能拒绝原假设。 会使⼀类错误概率降低，⼆类错误概率提⾼。 要使⼆类错误概率不过高，可以通过增加样本量来解决。
4.决策方案
结论给出:正收益,负收益,持平
—正收益:确定发布新版本。本次页面改进在显著性⽔平内，证明了‘转化率提升的假设’。并且收益提升率达到预期⽔平。进⼀步验证实验是否正确-实验反转当得出实验正向结论后，将实验反转，对照组变成实验组，实验组变成对照组。
原因:反转实验能够验证实验数据的差别是由实验本事引起的。但需要注意的是，建议只在实验为正向收益时反转实验。如果收益为负，反转实验，只会多损伤原对照组的⽤户体验。
具体做法:举个例子，实验目的为“按钮大小对该按钮点击率的影响”。A 组流量按钮变⼤,B 组为对照组,按钮大小正常,数据显示A组的按钮点击率升高，效果更好.在反转试验中,A 组流量按钮回复正常,B组变为实验组,按钮变⼤。如果此时数据显示B组按钮点击率升高，说明按钮大小对点击率有影响。
—负收益:优化迭代方案重新开发，本次页面改进在显著性⽔平内,核⼼指标负向变化显著。
—持平:调整分流比例继续测试
1.本次页面改进不显著无法证明‘转化率提升的假设’。分析原因可能是新版本样本空间不足。
2.产品变化本身收益不明显
解析：

题目3：18、假设检验的原理和步骤（贝壳找房）
答案：假设检验的原理：
小概率事件原理，小概率事件在一次实验中基本是不可能发生的，而一旦发生就有充分的理由拒绝原假设。去证明假设是错误的，从而反证假设的另一面很可能是正确的，运用的是反证法。
假设检验的步骤：
步骤：
确定原假设和备择假设
确定适当的检验统计量，并计算其数值。选择哪个统计量作为检验统计量需要考虑一些因素，例如进行检验的样本量多还是少，总体标准差是已知还是未知等等
最后看这个数据是落在接受域还是拒绝域，如果落在接受域则接受原假设，如果落在拒绝域则接受备择假设
解析：

题目4：19、参数估计和假设检验分别是什么？区别在哪里？（广联达）
答案：及
解析：● 假设检验在工作之后更重要的一个应用就是AB实验。AB实验是快速验证策略是否有效的方法，其中涉及的大量统计学知识以及实验步骤：确定目标及假设、确定指标、确定实验单位、样本量估算、测试时间估算、实施测试、分析测试结果等
● 参数估计和假设检验的联系是：
    ○ 参数估计和假设检验都是样本去估计总体，都是建立在概率基础上的统计，可以相互转换
● 参数估计和假设检验的区别是：
    ○ 参数估计是用样本统计量估计总体参数的方法；假设检验是先对总体参数提出一个假设，然后利用样本信息去检验这个假设是否成立
    ○ 参数估计是以置信区间(大概率)估计总体参数；假设检验是利用小概率事件是否发生来判断假设是否成立

题目5：20、实习内容中：假设、验证涉及的假设检验、a/btest（猿辅导）
答案：假设检验：假设检验是先对总体参数提出一个假设值，然后利用样本信息判断这一假设是否成立；假设有原假设，备择假设；检验方式有单侧检验和双侧检验；其步骤通常为：提出原假设与备择假设；从所研究总体中出抽取一个随机样本；构造检验统计量；根据显著性水平确定拒绝域临界值；计算检验统计量与临界值进行比较。
a/b test：流程为：1.收集指标,建立指标体系；2.分配流量,AA实验；3.假设检验；4.决策方案。
 
本题在解答的时候需要在参考答案的基础上结合自己的业务场景来进行解答
解析：


======= 数理基础-11 =======

题目1：21、假设检验的基本原理（字节跳动、快手）
答案：假设检验(hypothesis testing)是用来判断样本与样本、样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。显著性检验是假设检验中最常用的一种方法，也是一种最基本的统计推断形式，其基本原理是先对总体的特征做出某种假设，然后通过抽样研究的统计推理，对此假设应该被拒绝还是接受做出推断。常用的假设检验方法有Z检验、t检验、卡方检验、F检验等。
其基本思想是利用“小概率事件”原理，即小概率事件在一次试验中基本上不会发生。为了检验一个假设H0是否正确，首先假定该假设H0正确，然后根据样本对假设H0做出接受或拒绝的决策。如果样本观察值导致了“小概率事件”发生，就应拒绝假设H0，否则应接受假设H0。
解析：假设检验的基本步骤：
（1）提出检验假设H0，备择假设H1。
H0：样本与总体或样本与样本间的差异是由抽样误差引起的；
H1：样本与总体或样本与样本间存在本质差异；
预先设定的检验水平α（当检验假设为真但被错误地拒绝的概率），通常取α=0.05。
（2）选定统计方法，由样本观察值按相应的公式计算出统计量的大小，如X2值、t值等。根据数据的类型和特点，可分别选用Z检验，T检验，秩和检验和卡方检验等。
（3）根据统计量的大小及其分布确定检验假设成立的可能性P的大小并判断结果。若P>α，结论为按α所取水平不显著，不拒绝H0，即认为差别很可能是由于抽样误差造成的，在统计上不成立；如果P≤α，结论为按所取α水平显著，拒绝H0，接受H1，则认为此差别不大可能仅由抽样误差所致，很可能是实验因素不同造成的，故在统计上成立。

题目2：22、假设检验的显著性水平（猿辅导）
答案：假设检验是利用“小概率事件”原理做出统计判断的，而“小概率事件”是否发生与一次抽样所得的样本及所选择的显著性水平α有关，由于样本的随机性及选择显著性水平α的不同，因此检验结果与真实情况也可能不吻合，从而假设检验是可能犯错误的。
一般地，假设检验可能犯的错误有如下两类：
（1）弃真：当假设H0正确时，拒绝假设H0。称此为第一类错误，犯此类错误的概率恰好就是“小概率事件”发生的概率α，即P{拒绝H0/H0为真}=α；
（2）取伪：当假设H0不正确，接受H0。称此为第二类错误，记β为犯第二类错误的概率，即P{接受H0/H0不真}=β。
我们通常希望犯这两类错误的概率都很小。但当样本容量n固定时，α、β不能同时都小，α变小时β就变大，而β变小时α就变大。只有当样本容量n增大时，才有可能使两者变小。在实际应用中，一般原则是控制犯第一类错误的概率，即给定α，然后通过增大样本容量n来减小β。这种着重对第一类错误的概率α加以控制的假设检验称为显著性检验，α就是显著性水平。
解析：

题目3：23、假设检验相关的第一类错误、第二类错误，怎么降低第一类错误，如何同时降低第一类和第二类错误（拼多多）
答案：第一类错误α叫弃真错误或显著性水平，即原假设为真时却被我们拒绝的概率；第二类错误β叫采伪错误，即原假设为伪我们没有拒绝的概率。在一定样本量的情况下，减小一类错误必然会增大另一类错误，在实践中我们一般会优先控制第一类错误，因为原假设是非常明确的
解析：1-第一类错误也即原假设为真的情况我们接受的概率，对于A/B测试，犯这个错误代表新策略没有收益，我们却认为有收益，然后上线的错误，一般第一类错误不超过5%，第一类错误是明显的，也就是说在原假设为真的情况下接受原假设的概率要超过95%；统计功效=1-第二类错误，也即当AB两组实际有差异时,能被我们检测出来差异的概率

题目4：24、如何判断实验组和对照组的某个指标是否有显著差异？（滴滴）
答案：在实验开始前就对实验组和对照组进行数据指标监测，若实验前两组指标无明显差异，观测实验后的情况，根据假设检验原理设置所需的显著性水平，在该水平下判断两组的指标是否有显著差异；若实验前两组指标即存在差异，则可以采用DID（双重差分）的方法，查看两组的指标差距在设定显著性水平下实验前后是否有显著差异。
解析：

题目5：25、显著性水平、置信区间、假设检验（字节跳动）
答案：显著性水平：其实就是第一类错误也叫弃真错误，也即原假设为真时被拒绝的概率
置信区间：在区间估计中，由样本统计量所构造的总体参数的估计区间称为置信区间
假设检验：先对总体要估计的值提出一个假设，然后利用样本信息去检验这个假设是否成立
解析：


======= SQL-1 =======

题目1：1、UNION和JOIN的区别（滴滴、京东）
答案：UNION是两张表进行上下拼接，产生的两个记录集(字段要一样的)并在一起，成为一个新的记录集，分为UNION和UNION ALL两种方法；JOIN 是两张表进行左右连接，条件匹配的记录将合并产生一个记录集，有LEFT JOIN、RIGHT JOIN、INNER JOIN、OUTER JOIN等多种方法。
解析：（1）UNION
UNION 操作符用于合并两个或多个 SELECT 语句的结果集。UNION 内部的每个 SELECT 语句必须拥有相同数量的列。列也必须拥有相似的数据类型。同时，每个 SELECT 语句中的列的顺序必须相同。UNION 结果集中的列名总是等于 UNION 中第一个 SELECT 语句中的列名。若要对结果去重，可用 UNION 方法；如果允许存在重复的值，使用 UNION ALL。
示例：
table1:
[公式: |https://uploadfiles.nowcoder.com/images/20210422/510094950_1619083278410/934C49E6CD1B9ACC0C2E273F45637739]
table2:
[公式: |https://uploadfiles.nowcoder.com/images/20210422/510094950_1619083297802/50B1A08C16D675374459398B3F6A8577]
要求：从 table1 和 table2 中选取所有的中国(CN)的数据（允许存在重复的值）
SELECT country, name 
FROM table1
WHERE country='CN'
UNION ALL
SELECT country, app_name as name 
FROM table2
WHERE country='CN'
结果：
[公式: |https://uploadfiles.nowcoder.com/images/20210422/510094950_1619083326847/36BA18AD8C7E0BFFD017CE3617645E35]
（2）JOIN
JOIN 用于把来自两个或多个表的行结合起来。下图展示了 LEFT JOIN、RIGHT JOIN、INNER JOIN、OUTER JOIN 相关的 7 种用法。
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210423/897353_1619146544804/FB5C81ED3A220004B71069645F112867]

题目2：2、Sql题目，求连续访问ID（猿辅导）
答案：现有用户访问登陆表log_table，记录了usr_id和访问日期：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617783814166/C613507CC65F709244991B39FC502B47]
求连续访问ID的问题可以转化为寻找有过连续3天以上访问记录usr_id的问题，具体代码如下：
SELECT DISTINCT usr_id
FROM(
    SELECT usr_id
        , DATE_SUB(log_dte, INTERVAL rank_id DAY) AS flg_dte
    FROM(
    SELECT usr_id, log_dte, dense_rank() over(partion by usr_id order by log_dte) rank_id
    FROM log_table
    ) A
    GROUP BY usr_id, flg_dte
    HAVING COUNT(DISTINCT log_dte) >= 3
) B；
解析：

题目3：3、sql窗口函数并举例（滴滴、网易）
答案：1.窗口函数
窗口函数和普通聚合函数的区别：
①聚合函数是将多条记录聚合为⼀条；窗⼝函数是每条记录都会执行，有几条记录执行完还是几条。
②聚合函数也可以⽤于窗⼝函数。
原因就在于窗⼝函数的执⾏顺序（逻辑上的）是在FROM，JOIN，WHERE， GROUP BY，HAVING之后，在ORDER BY，LIMIT，SELECT DISTINCT之前。它 执⾏时GROUP BY的聚合过程已经完成了，所以不会再产⽣数据聚合。
注:窗口函数是在where之后执行的，所以如果where子句需要用窗口函数作为条件，需要多⼀层查询，在子查询外面进行,例如:
select user_id,avg(diff)
from
(
    select user_id,lead(log_time)over(partition user_id order by
log_time) - log_time as diff
    from user_log
)t
where datediff(now(),t.log_time)<=30
group by user_id
2.窗口函数的基本用法：
over关键字用来指定函数执⾏的窗⼝范围,若后⾯括号中什么都不写,则意味着窗口包含满足WHERE条件的所有行，窗口函数基于所有行进行计算；如果不为空,则⽀持以下4中语法来设置窗⼝。
 ①window_name:给窗口指定⼀个别名。如果SQL中涉及的窗口较多,采用别名可以看起来更清晰易读
②partition by子句：窗口按照哪些字段进⾏分组,窗⼝函数在不同的分组上分别执⾏
③order by子句：按照哪些字段进⾏排序,窗⼝函数将按照排序后的记录顺序进⾏编号
④frame子句：frame是当前分区的⼀个子集,子句⽤来定义子集的规则,通常⽤来作为滑动窗⼝使⽤
3.（⾯试考点）序号函数:row_number(),rank(),dense_rank()的区别
ROW_NUMBER():顺序排序——1、2、3
RANK():并列排序，跳过重复序号——1、1、3
DENSE_RANK():并列排序，不跳过重复序号——1、1、2
4.分布函数:percent_rank(),cume_dist()
percent_rank(): 每⾏按照公式 (rank-1) / (rows-1) 进⾏计算。其中，rank为RANK()函数产⽣的序号，rows 为当前窗⼝的记录总⾏数
--给窗口指定别名：WINDOW w AS(PARTITION BY stu_id ORDER BY score) rows
=5
mysql> SELECT
    -> RANK() OVER w AS rk,
    -> PERCENT_RANK()OVER w AS prk,
    -> stu_id,lesson_id,score
    -> FROM t_score
    -> WHERE stu_id=1
    -> WINDOW w AS (PARTITION BY stu_id ORDER BY score)
    -> ;
+----+-----+--------+-----------+-------+
| rk | prk | stu_id | lesson-id | score |
+----+-----+--------+-----------+-------+
| 1  |   0 |      1 | L003      |    79 | 
| 2  | 0.25|      1 | L002      |    86 |
| 3  |  0.5|      1 | L004      |    88 |
| 4  | 0.75|      1 | L005      |    98 |
| 5  | 0.75|      1 | L001      |    98 | 
+----+-----+--------+-----------+-------+
cume_dist(): 分组内⼩于、等于当前rank值的⾏数/分组内总⾏数 eg:查询⼩于等于当前成绩（score）的⽐例
--cd1: 没有区分，则所有数据均为一组，总行数为8
--cd2: 按照lesson_id分成了两组，行数各为4
mysql> SELECT stu_id,lesson_id,score
    -> CUME_DIST() OVER (ORDER BY score) AS cd1,
    -> CUME_DIST() OVER (PARTITION BY  lesson_id ORDER BY score) AS
cd2
    -> FROM t_score
    -> WHERE lesson_id IN('L001','L002')
    -> ;
+--------+-----------+-------+-------+------+
| stu_id | lesson_id | score | cd1   | cd2  |
+--------+-----------+-------+-------+------+
|      2 | L001      |    84 | 0.125 | 0.25 |
|      1 | L001      |    98 |  0.75 |  0.5 |
|      4 | L001      |    99 | 0.875 | 0.75 |
|      3 | L001      |   100 |     1 |    1 |
|      1 | L001      |    86 |  0.25 | 0.25 |
|      4 | L002      |    88 | 0.375 |  0.5 |
|      2 | L002      |    90 |   0.5 | 0.75 |
|      3 | L002      |    91 | 0.625 |    1 |
+--------+-----------+-------+-------+------+
5.前后函数:lag(expr,n),lead(expr,n)
用途：返回位于当前行的前n行（ LAG(expr,n) ）或后n⾏ （ LEAD(expr,n) ）的expr的值
应用场景：查询前1名同学的成绩和当前同学成绩的差值
mysql> SELECT stu_id,lesson_id,scire,pre_score
    -> score-pre_score AS diff
    -> FROM(
    ->     SELECT stu_id,lesson_id,score
    ->     LAG(score,1) OVER w AS pre_score
    ->     FROM t_score
    ->     WHERE lesson_id IN('L001','L002')
    ->     WINDOW w AS (PARTITION BY lesson_id ORDER BY score)) t
    -> ;
6.头尾函数：FIRST_VALUE(expr),LAST_VALUE(expr)
⽤途：返回第⼀个（ FIRST_VALUE(expr) ）或最后⼀个（ LAST_VALUE(expr) ）expr的值
应用场景：截⽌到当前成绩，按照⽇期排序查询第1个和最后1个同学的分数
解析：

题目4：4、SQL里面的like的用法（滴滴）
答案：LIKE 操作符用于在 WHERE 子句中搜索列中的指定模式。
示例：
table1:
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617784825992/CBBE59C20BB41927866221554CBEA767]
要求：从 table1中选取以G开头的网站数据（允许存在重复的值）
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617784835882/5DAB8423E8EB2B2C4EA3615D6D1C176C]
结果：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617784839681/03E0E7C05E6B4685819F8D7986614FAC]
解析：

题目5：5、SQL留存问题：现场写一道SQL：给定用户表，求用户的次日留存率（快手、oppo）
答案：假设usrlogs用户表记录了用户的登陆日期，如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617788781113/82A1921DAEE5E3591552DE8729A4DBE4]
首先计算用户登陆的日期间隔，并写入临时表date_interval：
解析：


======= SQL-2 =======

题目1：6、求单日留存及一个月的每日留存（快手）
答案：select first_data as '日期'
       count(distinct l.user_id) as '新增用户数',
       round(
           count(distinct case when datediff(log_date,first_date) = 1 then l.user_id else null end) / 
           count(distinct l.user_id)
           ,
           2
       ) as '次日留存率',
       round(       
           count(distinct case when datediff(log_date,first_date) = 29 then l.user_id else null end) / 
           count(distinct l.user_id)
           ,
           2
       ) as '30日留存率',
from user_log l left join
(
    select user_id,min(log_date) as first_date
    from user_log
    group by user_id
)t on l.user_id = t.user_id
group by dirst_date
解析：

题目2：7、sql如何进行优化（拼多多）
答案：sql优化看运⾏环境，可以分为mysql和Hive，前者是数据库查询优化，后者基于MapReduce。互联⽹分析师更多是基于Hive查询数据，所以下⽂针对Hive如何优化进⾏分析。
(1) 理解数据仓库的分层和数据粒度是⾸要的。因为相⽐于与数据库是为了数据的储存，更新⽽设计的，数据仓库则是更多为了数据的查询。针对具体的业务需求，选择合适的数据粒度，是sql优化的基础。例如选择⽤户粒度的Hive表，比起访问pv粒度的Hive表，数据量要⼩很多，sql查询也更快。
(2) 针对典型的问题，例如数据倾斜。
产⽣原因
1.group by维度过小,某值的数量过多(后果:处理某值的reduce⾮常耗时)
2.去重
distinct count(distinct xx) 某特殊值过多(后果：处理此特殊值的reduce耗时)
3.连接
join,count(distinct),group by,join等操作，这些都会触发Shuffle动作，⼀旦触发，所有相同key的值就会拉到⼀个或⼏个节点上，就容易发⽣单点问题。
(2)解决方案
1.业务逻辑:例如我们从业务上就知道在做group by时某些key对应数据量很⼤,我们可以单独对这些key做计算,再与其他key进行join
2.Hive参数设置:
设置hive.map.aggr = true 在map中会做部分聚集操作，效率更高但需要更多的内存设置hive.groupby.skewindata=true 数据倾斜时负载均衡，当选项设定为true，⽣成的查询计划会有两个MRJob。第⼀个MRJob中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的GroupBy Key有可能被分发到不同的Reduce中，从⽽达到负载均衡的⽬的；第⼆个MRJob再根据预处理的数据结果按照GroupBy Key分布到Reduce中（这个过程可以保证相同的GroupBy Key被分布到同⼀个Reduce中），最后完成最终的聚合操作。
(3)查询语句优化:
1.在count(distinct) 操作前先进⾏⼀次group by,把key先进⾏⼀次reduce,去重
2.map join:使⽤map join让⼩的维度表（1000 条以下的记录条数）先进内存,在map端完成reduce.
解析：

题目3：8、是否会SQL、Python、R等分析工具（阿里）
答案：引申
数据分析师通常会使用EXCEL、SQL、Python和R进行数据处理及数据分析的工作。
EXCEL用于小样本量中基本的数据处理操作，而SQL用于从数据库中取数操作，做一些简单的数据处理工作，通过表连接、嵌套查询等动作完成最终的数据统计工作。SQL基本上可以完成大部分的数据分析工作，对当前公司运营的成效进行数据呈现及分析。而Python和R则属于更高阶的分析工作，可以借助多种多样的工具库，可以通过数据建模，可用于有监督或无监督模型的训练，解决分类或预测问题。
解析：

题目4：9、count()和count(distinct)用法（京东）
答案：COUNT() 函数返回匹配指定条件的行数。在表中，一个列可能会包含多个重复值，有时我们希望仅仅列出不同的值，DISTINCT 关键词用于返回唯一不同的值，COUNT(DISTINCT column_name) 函数返回指定列的不同值的数目。
示例：
table1:
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617793201789/45CE3E89606C145AB053B824900A361C]
要求：从 table1的 "country" 列中选取唯一不同的值，也就是去掉 "country" 列重复值
SELECT COUNT(country) as c1, COUNT(distinct country) as c2
FROM table1
结果：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617793219658/2802CDF325409D36E59B858B49DB00EE]
解析：

题目5：10、SQL常用函数（京东）
答案：（1）常用聚合函数：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617793281165/D492EDE54D53A52775CCAAA4271B0301]
 （2）常用其它函数：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210407/897353_1617793294693/80681E1A3B4501969126C41B2A3AE053]
解析：


======= SQL-3 =======

题目1：11、提取一个班级第一名的全部信息（招联金融）
答案：select classid
,userid
,score
,other_info
from(

  select classid
  ,userid
  ,score 
  ,other_info
  ,rank()over(partition by classid order by score desc ) as rk
  from r

) final
where rk = 1
解析：

题目2：12、sql怎么样/SQL掌握运用的程度？/问对sql的掌握程度。/学过sql吗？（三诺生物、滴滴、京东、京东数科、网易、快手）
答案：引申知识点
1） 基本操作
掌握增删改查等SQL基本语法：
解析：

题目3：13、你说在销售运营这个岗位上会涉及到一些报表的出具，包括日报/月报等等这些工作，用到的工具除了EXCEL，像SQL这些用得到吗？（京东）
答案：会用到，比如提取销售情况的时候，需要先用sql将数据从数据库中取出，在一些较复杂的场景中，会将提出的数据导入python中进行数据处理，然后再用excel产出。
解析：考察是否有过使用sql或者python的经验

题目4：14、给了用户安装的应用列表和对应分类，取出每个用户安装类型最多的应用top5（SQL题，一道，给了用户安装的应用列表和对应分类，第一问相对简单）（拼多多）
答案：参考答案：表a：uid：用户id；appid：应用id；tid：对应分类
select uid, tid
from
(select uid, tid, row_number() over(order by cnt desc) as rk
from
    (select uid, tid, count(distinct appid) as cnt
    from a
    group by uid, tid) t1) t2
where rk <= 5
解析：

题目5：15、选取订单量前1000的商品，并且选出每个商品订单量排名前100的销售渠道（拼多多）
答案：订单表a：sid：商品id；channel：销售渠道；amount：订单量。
select sid, channel
from
    (select sid, sum(amount) as amt 
    from a
    group by sid) t1
join 
    (select sid, channel, row_number() over (partition by sid order by amount desc) as rk
    from a) t2 on t1.sid = t2.sid
where rk <= 100
order by amt desc
limit 1000
解析：


======= SQL-4 =======

题目1：16、找出每个用户得分最高的视频，得分相同时按照视频id选择最大的（原：找出每个用户哪一类型得分最高的视频，视频相同时按照视频id选择最大的）（快手）
答案：表a：uid：用户id；aid：视频id；score：得分
select uid, aid, score
from
    (select uid, aid, score, row_number() over(partition by uid order by score desc, aid desc) as rk
    from a) t
where rk = 1
解析：

题目2：17、找出开播三分钟内无人进入的直播房间号（快手）
答案：主播表a：upid：主播id；rid：直播间id；stime：开播时间
   观众表b：uid：观众id；rid：进入的直播间id；intime：进入时间
select a.upid, a.rid
from a 
left join b on a.rid = b.rid and a.stime < dateadd(minute,-3,b.intime)
where b.uid is null
解析：

题目3：18、sql window function/ full join（字节跳动）
答案：1） window function
SQL中常用的窗口函数基本语法如下，常用的窗口函数有排序和聚合两类函数：
<窗口函数> over (partition by <用于分组的字段> order by <用于排序的字段>)
假设现有学生的分数表scores：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210408/897353_1617853292391/199A1F4B61BD0AF6EB58085F8FDA1D46]
A. 排序函数
rank、dense_rank、row_number都是排序函数，但是排序的机制不一样，当排序中存在相同的值时会出现不同的排序结果，根据以下查询方式：
SELECT *
, row_number() over(order by score desc) AS row_seq
, rank() over(order by score desc) AS rank_seq
, dense_rank() over(order by score desc) AS dense_seq
FROM scores;
得到的结果如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210408/897353_1617853319304/6B5BA74EF91BB7F2B06BEE11DB377759]
B. 聚合函数
聚合函数即为max、min、sum这类常用的函数，只是计算方式略有不同，我们尝试使用以下代码进行SQL查询：
SELECT *
, max(score) over(order by student asc) AS score_max
, min(score) over(order by student asc) AS score_min
, sum(score) over(order by student asc) AS score_sum
FROM scores;
得到的结果如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210408/897353_1617853344194/0C75D8E5A5CAF2FA3FFAC5903B338199]
2） full join
全联接full join表示在将左表和右表进行连接时，只要在其中一个表存在就会返回该行，覆盖了left join和right join的结果。
[公式:
|https://uploadfiles.nowcoder.com/images/20210408/897353_1617853354124/D92E1A761BAA467D0A05A7F39137C639]
解析：

题目4：19、找出个分类下粉丝数提升（跟昨天）最多的20个id（字节跳动）
答案：表a：uid：用户id；logdate：记录日期；fans：粉丝数
解析：

题目5：20、SQL窗口函数、如何去重（京东）
答案：假设table表中有字段a、b、c，现需要对字段a、b进行去重，在SQL中通常有三种方法能够实现去重的功能：
1） DISTINCT 关键字
使用DISTINCT去重的方法很简单，在查询数据时在字段前增加DISTINCT关键字既可对字段内容进行去重。如下代码将输出table表中字段a和b的组合不重复的数据：
SELECT DISTINCT a,b
FROM table;
2） GROUP BY关键字
使用GROUP BY进行去重的方法和DISTINCT类似，仅需在查询语句末端增加GROUP BY即可，而且能够对分组数据进行筛选。
SELECT a, b
FROM table
GROUP BY a, b;
3） 窗口函数
使用窗口函数进行去重时，比DISTINCT和GROUP BY稍微复杂些，可以采用窗口函数+over(partition by 去重字段)的方式。去重方式如下：
-- 窗口函数+over(partition by 去重字段)，其中窗口函数可采用row_number
SELECT a, b
FROM(
    SELECT *, row_number() over(partition by a, b order by c) rank_id
    FROM table
) A
WHERE rank_id = 1;
解析：


======= SQL-5 =======

题目1：21、给定用户表，求用户的次日留存率（京东）
答案：假设usrlogs用户表记录了用户的登陆日期，如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210408/897353_1617854230911/9BEAE56BD6399879020B61A6686A01ED]
首先计算用户登陆的日期间隔，并写入临时表date_interval：
SELECT usr_id, A.log_date AS log_d, datediff(A.log_date, B.log_date) AS day_diff
FROM usrlogs A
LEFT JOIN usrlogs B
ON A.usr_id = B.usr_id;
然后根据用户登陆的日期间隔筛选出留存的用户，从而计算出次日留存及次日留存率：
SELECT log_d
, COUNT(DISTINCT CASE WHEN day_diff = 1 THEN usr_id ELSE NULL END) AS '次日留存'
, COUNT(DISTINCT CASE WHEN day_diff = 1 THEN usr_id ELSE NULL END)/COUNT(DISTINCT usr_id) AS '次日留存率'
FROM date_interval
GROUP BY log_d;
次日留存考虑的是某日登陆的用户次日依旧登陆的用户量及比率，而三日和七日分别考虑的是某日登陆的用户三日和七日后登陆的用户量及比率，因此只需将上述代码中day_diff日期间隔设置为3、7即可计算出三日和七日留存及留存率。
解析：

题目2：22、SQL行列转换/SQL代码题：行、列转换（小米、腾讯）
答案：假设数据库只现有一张销售记录表Sales：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210408/897353_1617854379693/2DDE70AA3BA413578048A5571581B329]
对该数据表进行行列转换的代码如下：
SELECT 年份
, SUM(CASE WHEN 销售员='小明' THEN 销售量 ELSE 0 END) AS '小明'
, SUM(CASE WHEN 销售员='小张' THEN 销售量 ELSE 0 END) AS '小张'
, SUM(CASE WHEN 销售员='小王' THEN 销售量 ELSE 0 END) AS '小王'
FROM Sales
GROUP 年份;
解析：


======= 数据分析-1 =======

题目1：1、说一说数据分析流程（龙湖）
答案：第一步：与业务方沟通问题，明确分析目标；第二步：对目标进行拆解，可以采用两步分析法，也可以采用人货场分析法，通过数据定位问题源头；第三步：与产品、运营和技术沟通，找到问题原因。
解析：本题考查数据分析的结构化思路，需要对数据分析有大致的了解，并能够用结构化的语言描述。

题目2：2、游戏内数据分析涉猎的少，如何证明自己有能力胜任？（字节跳动）
答案：虽然我对游戏数据分析的经验较少，但是我认为对于应届生而言，更重要的是学习能力以及对该行业的热情。我的学习能力不错（举例说明，最好结合实习的例子，其次是在学校学习的例子等）；并且我非常热爱网络游戏，自身职业规划也和游戏相关，希望能在这个行业里深耕；最后我认为数据分析的方法是相通的，我学习的其他数据分析方法论也可以应用其中。
解析：投递岗位前认真阅读岗位JD，通过JD分析自身匹配度，结合自身情况，举例证明对其的匹配性。

题目3：3、之前的经历中单品数据分析的经验丰富，但缺少平台分析经验，你认为字节小游戏平台分析需要涉及哪些指标？哪个是最重要的？为什么？（字节跳动）
答案：从游戏自身出发：核心玩法的参与度，游戏留存等；从游戏玩家出发：ARPU，DAU，留存率；从游戏性能出发：闪退率，卡顿率等。最重要的是游戏的渗透率，因为字节游戏主要依靠从抖音或今日头条引流用户，如何把内容用户转变为游戏用户，是字节游戏现在最重要的事情
解析：

题目4：4、你对数据分析的认知是什么，那你是如何学习数据分析的？（除上课外）（阿里、百度）
答案：据分析是通过数据的角度，发现业务的痛点和痒点，通过分析原因得出解决策略，并推动策略落地，达到提升业务质量的过程。主要通过课外阅读以及实习来学习数据分析，通过把在“人人都是产品经理”网站、公众号文章、知乎文章等学习到的数据分析方法论，通过实习的方法实践出来，也让我对数据分析有了更加清晰的认识。
解析：

题目5：5、数据分析常用软件（招商银行信用卡）
答案：取数和处理数据的工具：Sql、Excel、Python、VS-code、SPSS等
数据可视化工具：Tableau、airflow、matebase等
解析：需要结构化的回答，将常用的数据分析软件按照功能分类，再分别回答。


======= 数据分析-2 =======

题目1：6. 你觉得数据分析应该具备的能力是什么（贝壳找房、京东）
答案：快速学习能力、数据化思维和较强的业务逻辑化能力。数据分析师需要接触不同的业务，在学习新的业务中，我们需要快速学习能力，来提高我们工作的效率；数据化思维能够帮助数据分析师提高数据敏感度，对异常数据有敏感的识别能力；业务逻辑化能力能够让我们与业务方沟通时更加顺畅，数据分析并非独立完成的，是需要与其他人协同产出的。
解析：

题目2：7. 以往经历中，你是怎么做数据分析报表（京东）
答案：在学校的学习中，主要使用Python和Excel产出可视化报表，所以我对这两项工具的使用也非常熟练。在公司的实习中，主要使用Tableau和公司的报表平台，我也能够熟练的使用这两项工具，对于不同的平台也有较快的上手能力。
解析：需要在回答中表现出自己的匹配能力，能够熟练使用数据分析工具，且对于陌生的工具有较快的上手能力。

题目3：8. 数据分析必备的技能（跟谁学、蓝月亮）
答案：数据处理技能：SQL、Excel、Python；数据可视化技能：Python、Tableau、PPT；沟通协调技能：与其他团队沟通，以及将数据分析结果呈现的能力。
解析：

题目4：9. 你觉得数据分析师必备的素质；结合数据分析师的素质，给自己打个分，讲述扣分的理由（京东）
答案：数据敏感度、快速学习能力和业务思维。满分十分给自己七分。扣分主要在于自己接触业务，像实习经历这种会比较匮乏，缺乏一定的业务思维，但是我的学习能力较强，能够快速上手业务，对数据分析的工具掌握较熟练，所以勉强及格的水平，还需要进一步学习。
解析：

题目5：10. 有哪些数据分析经历（京东、快手、滴滴、百度）
答案：按照自身简历情况，如果有实习经历，则回答自身实习中所做的，优先级：实验设计评估落地 -> 专题分析报告 -> 简单业务分析。如果没有实习经历，则说自己的项目经历。
解析：


======= 数据分析-3 =======

题目1：11. 对做数据分析做了哪些准备（拼多多）
答案：分业务学习、工具学习、理论学习三个层面进行回答。
业务学习：在人人都是产品经理、知乎、公众号阅读了大量数据分析的文章，并进行方法论总结。
工具学习：熟练掌握Sql、Python、Excel、Tableau等数据分析工具。
理论学习：对数据分析所用的统计学理论、机器学习理论有较为全面的理解掌握。
解析：

题目2：12. 说一下SVM（拼多多）
答案：SVM是在特征空间上找到最佳的分离超平面，使得训练集上的正负样本间隔最大。是用来解决二分类问题的有监督学习算法，在引入核方法后也可以解决非线性问题。
解析：不需要详细描述原理，简要说明原理+运用场合即可。

题目3：13. 说一个无监督学习算法，阐述原理，优缺点，实际应用点（拼多多）
答案：k-means聚类算法。
原理：首先选择k个点作为初始点，随后将每个点指派到最近的质心，形成k个簇并重新计  算每个簇的质心，直到簇不发生变化或达到最大迭代次数。
优缺点：优点是处理大数据时较为高效且伸缩性较好；缺点是需要事先确定k，不适合非凸集合的聚类。
实际应用点：潜在的簇是凸面，且簇之间区别明显，大小相近，适用于大数据。
解析：选取较为简单的即可。

题目4：14. 从数据分析角度，推荐模块怎么用指标衡量？（拼多多）
答案：推荐模块主要目的是将用户进行转化，所以其主指标是推荐的转化率。对于其他指标，可以从用户、模块功能的角度进行衡量。用户层面：每日推荐用户数、点击推荐用户数、对推荐不感兴趣数等，并且可以计算各用户数的占比情况，再具体可以看不同层级的用户情况；模块功能层面：各模块的点击人数、各模块的点击率、各模块点击后的跳转时间等，可以看出该模块功能是否合理有效。
解析：从推荐的功能出发，先给出主指标，再给出其他指标。

题目5：15. 为什么想做数据分析？（从数据分析相关专业和不相关专业给出两种答案）（滴滴）
答案：数据分析相关专业：1、对数据分析十分感兴趣，对自己未来的职业规划也是在数据分析这条路深耕，非常希望能够进入该行业。2、有一定的专业水平，自己本科/硕士阶段所学习到的很多统计和管理学上的知识，希望能够学以致用。3、认为该行业十分有前景，未来是大数据时代，而数据分析能够让企业更明确未来的方向，是非常有发展前景的行业。
数据分析不相关专业：1、对数据分析十分感兴趣，对自己未来的职业规划也是在数据分析这条路深耕，非常希望能够进入该行业。2、有一定的专业水平，虽然专业并非与数据分析相关，但是为了走数据分析这条路也做了需要努力，自学了很多统计学和机器学习相关的理论知识，并且在实践实习中将在公众号和知乎等文章上学到的数据分析方法学以致用，并且对数据分析的工具掌握非常熟练，认为自己非常适合数据分析。3、认为该行业十分有前景，未来是大数据时代，而数据分析能够让企业更明确未来的方向，是非常有发展前景的行业。
解析：


======= 数据分析-4 =======

题目1：16.根据数据分析去调整高峰期打车供需问题（滴滴）
答案：①首先明确分析目的：关键词为“高峰期”、“供需问题”；供需问题即订单使用情况。
②随后根据订单问题构建指标体系：订单满足率，高峰期时段，订单高峰地段，平均响应时间，平均订单时长。
③然后我们需要提出分析的问题：在各个地段的订单满足率如何？打车高峰期是什么时候？平均订单完成时间有多长？
④通过数据分析回答上述问题，并对数据进行可视化，得到分析结论。
解析：框架为：明确问题关键词-->构建问题相关指标-->根据关键词得到具象化问题-->通过数据分析回答问题

题目2：17.认为数据挖掘和数据分析有什么不同（中银金科）
答案：①数据挖掘是在大量数据中，通过机器学习或深度学习等方法，去挖掘一些有价值或者是未知的信息，重点就在于寻找未知的模式，例如通过现状预测未来；
②数据分析则更偏向于使用数据工具来进行数据的处理，提取出有价值的数据，需要与业务相结合，例如异常归因分析，经营现状分析等。
解析：

题目3：18.说下数据分析常用的算法（中银金科）
答案：a. 分类分析算法：对已人工打标好的样本数据进行归类，并且找到其分类个体的特征属性，常用的有决策树，随机森林算法。
b. 聚类分析算法：对未打标的样本数据进行归类，并找到分类个体的特征属性，常见的有k-means算法。
c.时间序列分析算法：对事件或对象行为随时间变化的规律或趋势建立模型进行分析，常见的有ARMA和ARIMA算法。
解析：考察在数据分析中，可能需要用到机器学习的场景，以及场景所对应使用的机器学习算法。

题目4：19.原专业与数据分析的哪些内容相关（三诺生物、蓝月亮、锐明科技）
答案：（通用套话）
在基础课的学习上，概率论与数理统计这门课程学习的比较好，对统计学有较为深刻的认识。
在逻辑能力上，原专业也需要我们有较好的逻辑思维和结构化思维，对问题可以进行一定的拆解分析，找到问题原因。
在沟通表达能力上，在原专业的学习上，也需要与他人协作沟通，才能够取得不错的成果。
解析：需要从几个本专业和数据分析有联系的方面分别阐述为什么自己匹配数据分析这个岗位。建议事先研究岗位JD，找出与岗位JD所匹配的素质要求，联系自身情况，最好有事件案例说明。

题目5：20.假设我是美团的数据分析师，会构建怎样的指标体系。（滴滴）
答案：美团的业务线很多，以美团商家业务线为例，我会这样构建指标体系。
分为主指标和辅助指标：
主指标包括：收入、有效订单数、入店转化率和订单转化率。
辅助指标分为营业数据、流量数据、顾客数据。
营业数据的指标可以有营业额、活动补贴总额、顾客实付费用、实付单均价；流量数据的指标可以有曝光人数、入店人数、下单人数、曝光次数、入店次数；顾客数据的指标可以从顾客的用户画像入手，例如新老客户占比、价格偏好情况等。
解析：


======= 数据分析-5 =======

题目1：21.认为自己数据分析能力如何？一般会从什么角度进行数据分析？（快手）
答案：我认为我的逻辑思维较好，但是业务经验比较缺乏，还有很大的提升空间。角度：首先我会定位问题所出现的原因，按照用户、渠道等维度进行分层探索，找到出现问题的原因；定位好问题源头后，我会从内部和外部的角度进行归因，内部我会分别从产品、运营和技术侧寻找原因，外部我会从经济政策环境和竞品的角度归因。
解析：需要表现出较好的逻辑思维能力（数据分析的基础能力）和结构化的表达能力。

题目2：22.谈一下瀑布流和双列点选两种形式，你能从哪些角度进行数据分析以为业务方提供指导建议呢？（快手）
答案：答案解析
首先，明确单列与双列各自的优点：单列能够减少用户思考的时间和提高单个内容的转化率；双列能够展示更多元化的内容，用户找到想看的内容的效率更高。
然后，针对其特点建立指标体系，看观察两者的差异程度：平均用户观看视频时长，用户的点赞率，用户转化率等。通过与业务方沟通得到对方想要提升的目标，依照指标针对性的给出建议。
解析：首先，明确单列与双列各自的优点：单列能够减少用户思考的时间和提高单个内容的转化率；双列能够展示更多元化的内容，用户找到想看的内容的效率更高。
然后，针对其特点建立指标体系，看观察两者的差异程度：平均用户观看视频时长，用户的点赞率，用户转化率等。通过与业务方沟通得到对方想要提升的目标，依照指标针对性的给出建议。

题目3：23.从数据分析怎么去挖掘出你说的客户相似性？（快手）
答案：客户相似性即用户画像的相似程度。我们可以按照用户基本信息数据、用户个人行为数据和用户消费行为数据筛选特征，建立机器学习中的聚类分析模型，可以采用k-means等方法，对其进行聚类，并输出主要相似特征。
解析：

题目4：24.什么样的人适合做数据分析（字节跳动）
答案：1.具有数据敏感度，与数据打交道需要能够从众多的数据中发现统计规律，需要有较强的数据敏感度。
2.快速学习能力较强，数据分析师可能需要同时推进不同的业务，需要快速学习不同业务。
3.沟通协调能力较强，数据分析不是独自一人干活，而是需要与业务方沟通，才能完成工作的。
解析：每点后最好结合自身经历，说明自己在这方面有优势，会比较加分。

题目5：25.数据分析日常工作内容以及工具时间占比（滴滴）
答案：日常工作：数据提取、数据处理、与业务方沟通、数据实验、数据报表制作、数据分析报告。
工具时间占比：数据清洗方面：sql占绝大部分时间，50%-60%；python和excel做数据处理也会占据部分时间，10-20%；数据实验：实验流量工具，5%-10%；数据可视化：数据报表工具（tableau)，15%-20%。
解析：工具最好按照工作内容划分说出来，显得比较有结构条理。


======= 数据分析-6 =======

题目1：26.金融以及中小微方向数据分析的想法（同盾科技）
答案：可以通过过去数据，分析未来走势。例如通过过去的借款金额，通过对人群进行用户画像上的划分，分别预测出未来该部分客群的借款情况。也可以通过人群的消费和画像等维度数据，通过机器学习深度学习，对每个人设计有竞争力的还款利率。
解析：

题目2：27.对数据分析的看法，你怎么理解数据分析师这个职业（同盾科技、字节跳动、哔哩哔哩、小红书、贝壳找房、京东）
答案：数据分析是通过数据的角度，发现业务的痛点和痒点，通过分析原因得出解决策略，并推动策略落地，达到提升业务质量的过程。
职业看法：我认为这个职业是非常有前景的，未来许多企业都将完成数字化转型，对数据分析师的需要和要求也会逐渐提高，未来我也希望能够在这一领域深耕，不断学习提升自己的分析能力和业务水准，希望能够成为一名优秀的数据分析师。
解析：主要是通过这个问题映射出自己的职业规划，需要明确的说明自己很看好这个职业，以及未来希望能在这个行业里深耕的意愿。

题目3：28.自己想做的数据分析是什么类型之类的。（同盾科技）
答案：我希望做的是偏业务方向的数据分析。因为：第一，我认为数据分析是需要与业务相结合的，通过数据分析业务的痛点和痒点，推动策略，业务方向的数分也会让我更有成就感。第二，我认为我个人也比较适合这个方向。我具有一定的快速学习能力和业务理解能力，在之前的几份实习中我都能比较快的上手业务，也通过这几次实习让我找准了之后的职业发展方向。
解析：一点是说明你了解这个方向是做什么，一点是自己为什么匹配这个方向。

题目4：29.那你知不知道逻辑是数据分析师最重要的技能，你觉得它会是你日后工作致命的缺陷吗（字节跳动）
答案：我也同样认为逻辑能力是非常重要的，数据分析需要从数据中得出分析结论，需要十分严谨的逻辑能力才能够让业务方信服。但我认为我的逻辑能力还是比较强的，学习数理知识时培养了我的逻辑能力，并且在之前的实习过程中，我与业务方的沟通也较顺畅，所以我并不认为这个是我的缺点，但是我认为我可以继续提高我的逻辑能力，顺便问你有推荐的书籍或方法吗？
解析：说明重要性+举例说明自己有这项能力。

题目5：30.介绍一个数据分析项目（字节跳动）
答案：（答题模板）
先介绍项目背景：在xxx上线后，数据效果不明显，所以需要我们对其进行分析，找到原因。
随后介绍分析思路：我们从xxx，xxx等角度进行分析xxx指标，得到xxx的现象。
后说明分析结论和对应的解决策略。如果后续有继续观察策略落地的情况可以继续说策略落地后的效果。
解析：


======= 数据分析-7 =======


======= 业务指标-1 =======

题目1：1.怎么制定某某具体业务的目标？（举例说明）（美团）
答案：需要制订美团外卖接下来几个月各个城市销售额的kpi。首先，我们定义[公式:图片说明|https://www.nowcoder.com/equation?tex=%E9%94%80%E5%94%AE%E9%A2%9D%3DMAU%5Ctimes%E8%B4%AD%E4%B9%B0%E6%A6%82%E7%8E%87%5Ctimes%E5%AE%A2%E5%8D%95%E4%BB%B7] 。我们需要对各个城市分别指定接下来几个月的MAU，购买概率和客单价。可以通过各个城市过去几个月的表现来预测出接下来几个月各指标的表现，然后根据运营情况指定详细的kpi。
解析：指定大的指标时，需要将其拆解成小指标，然后对客群进行划分，再对不同的客群制订不同的小指标，制定过程言之有理，逻辑清晰即可。

题目2：2.业务题，怎么分析指标异常（猿辅导）
答案：两步分析法：首先定位问题原因，这里可以通过计算各个维度该指标的变动系数=（指标异常前-指标异常后）/指标异常前，选出变动系数较大的前几个维度，对其进行分析。然后可以从内部和外部进行分析，内部从产品、技术、运营侧分别沟通看是否能找到原因。外部从政策和竞品的角度找原因。
解析：定位问题+找到原因

题目3：3.短视频业务需要哪些指标 哪三个指标最重要（快手）
答案：1.短视频本身的数据，比如短视频发布时间、视频时长、发布渠道。这个都是视频发布后即有的固定属性。
2.短视频消费测相关的数据，比如累计播放量、点赞率、完播率。
3.短视频供给侧相关数据，投稿用户数、连续投稿用户数、优质投稿人涨粉率等。我认为最重要的三个指标有：播放量、点赞量和收藏量。这三个指标可以反映出短视频消费的健康情况。也是我认为最应该关注的指标。
解析：先说明自己了解短视频生态的构成，再举出三个重要指标即可。

题目4：4.业务指标有哪些，怎么衡量你所在的业务部门的贡献（滴滴）
答案：业务指标分为：
1.用户数据指标，例如新增用户数、活跃用户数、留存率等；
2.行为数据指标，例如PV、UV、K因子；
3.产品数据指标，例如GMV，ARPU，付费率；
4.付费推广指标，例如CPC、CPA等。可以采用ab-test来衡量策略落地的效果，通过假设检验来衡量策略的显著与否。
解析：引导面试官去询问ab实验的具体步骤，面试前需要准备好ab实验的细节。

题目5：5.一个业务场景问如何如分析，如何去提升（滴滴）
答案：例如如何分析短视频数据效果不好，是推荐流没有好的内容还是推不出好的内容。可以从供给情况和消费情况分析推荐流内的数据情况，例如分发布时间、播放量分层等，得到推荐流内的总体情况；再分高粉up主的稿件消费情况看是否被消费；最后再查看被消费高的稿件内容情况。最后我们可以得出一些用户喜欢的短视频稿件特征，与运营和算法沟通，进行ab实验，向一部分用户多推荐这种内容，看数据效果是否提升明显。
解析：分析思路需要严谨，得出的分析结论需要有落地，落地一般需要ab实验，引导面试官询问ab实验的具体情况。


======= ABtest-3 =======

题目1：12.选择AB实验的样本的时候，应该注意什么（滴滴）
答案：选择AB实验的样本的时候，我们最要考虑的是样本量的选择，影响样本量选择通常有4个因素：显著性水平（α）、标准差（1 – β）、统计功效（μA-μB）、均值差异（σ）
● 显著性水平：显著性水平越低，对AB实验结果的要求也就越高，越需要更大的样本量来确保精度
● 统计功效：统计功效意味着避免犯二类错误的概率，统计功效越大，需要的样本量也越大
● 均值差异：如果真实值和测试值的均值差别巨大，也不太需要多少样本，就能达到统计显著
● 标准差：标准差越小，代表两组差异的趋势越稳定。越容易观测到显著的统计结果
将这四个值带入样本计算量公式就能得到需要的样本量，通常有网站专门计算AB实验的样本量，所以只要搞清楚上面四个值，就能计算出你需要的样本量
解析：这道题主要是对AB实验样本量选择的考量，因为在选择样本的时候最关键也是最重要的一步就是对样本量的选择，对于有经验的人来说可以按照经验判断样本量级，但是对于更多人来说还是需要有更多辅助的判断。通常来说样本量太少，实验结果不大可信，但是样本量太多，也不是更好，一个最直接的原因就是样本量越大，影响的用户越多，就有可能影响到用户对产品的体验。

题目2：13.如何设计ABtest确定此功能上线收益（正负收益平衡点）（快手）
答案：A方案和B方案，哪个方案的结果更好？
首先的话，需要做需要运用假设检验，分为两种不同的检验方式，对于留存率、渗透率等漏斗类，采用卡方检验。对于人均时长类等均值类指标，采用t检验。
通过假设检验后，如果结论置信，我们就能够得到A方案和B方案哪个指标更好（有显著性差异）， 对于不置信的结论，尽管A方案和B方案 的指标可能略有差异，但可能是数据正常波动产生。
哪个 ROI 更高？
一般有活动相比无活动，留存、人均时长等各项指标均会显著。
对于 ROI 的计算，成本方面，每个实验组成本可以直接计算，对于收益方面，就要和对照组相比较，假定以总日活跃天（即 DAU 按日累计求和）作为收益指标，需要假设不做运营活动，DAU 会是多少，可以通过对照组计算，即：
● 实验组假设不做活动日活跃天 = 对照组日活跃天 * （实验组流量 / 对照组流量）
● 实验组收益 = 实验组日活跃天 -  实验组假设不做活动日活跃天
这样就可以量化出每个方案的 ROI。
解析：这道题主要是考察ABtest上线后，从哪些维度来确认哪个方案更好，或者说新的方案是否比旧的方案更加适合上线

题目3：14.根据上面说的改进点做AB测试，从什么角度来分析？（小红书）
答案：以下是ABtest常用的不同的分析指标，可以从这些指标来分析ABtest（以电商为例）
● 点击率
● 留存率
● 复购率
● 转化率
● 跳出率
● 平均保留率
● 平均使用时长（应用，手机网站、网页或游戏场景上的时间）
● 客户满意率
● 平均用户收入
● 平均订单金额
通过对比以上指标在ABtest中的效果，就可以分析不同方案的优缺点
解析：这题考虑的是ABtest的分析的角度，分析的角度可以通过不同的指标来分析，不同的指标体现了不同角度的意义

题目4：15.怎么验证你的改进办法有没有效（字节跳动）
答案：常见的方法就是去关注一下指定的指标，因为大多数ABtest在确认做之前都会指定一些关键性指标，比如，点击率、留存率、复购率和转化率等等，所以在上线后就可以直接关注这些指标是否有提高，如果有就说明办法有效，如果没有提高就需要看看办法哪里出了问题。其次也能够通过计算ROI来比对不同的方案。
对于 ROI 的计算，成本方面，每个实验组成本可以直接计算，对于收益方面，就要和对照组相比较，假定以总日活跃天（即 DAU 按日累计求和）作为收益指标，需要假设不做运营活动，DAU 会是多少，可以通过对照组计算，即：
● 实验组假设不做活动日活跃天 = 对照组日活跃天 * （实验组流量 / 对照组流量）
● 实验组收益 = 实验组日活跃天 -  实验组假设不做活动日活跃天
这样就可以量化出每个方案的 ROI。
解析：这题主要还是考察ABtest上线后的效果，最简单的是一些指标可以看出是否有效果，也能看一个投资回报率ROI来看是否有效果

题目5：16.A/B test场景问题，第一类错误，第二类错误具体是什么，你觉得哪个更严重等延伸开的问题（阿里）
答案：第一类错误：原假设正确但是拒绝原假设，弃真错误。第二类错误：原假设错误但是接受原假设，取伪错误。第一类错误更严重，由于报告了本来不存在的现象，则因此现象而衍生出的后续研究、应用的危害将是不可估量的。
解析：


======= 业务与用户分析-1 =======

题目1：1.这份实习中主要跟的项目或者case，自己独立完成的（可以使行业分析、可以使指标体系的搭建等），整个框架详细介绍（美团）
答案：先介绍项目背景：在xxx上线后，数据效果不明显，所以需要我们对其进行分析，找到原因。随后介绍分析思路：我们构建了指标体系：主指标为xxx，用户辅助指标为xxx。后我们从xxx，xxx等维度进行分析这些指标，得到xxx的现象。最后说明分析结论和对应的解决策略。如果后续有继续观察策略落地的情况可以继续说策略落地后的效果。
解析：

题目2：2.大三的实习怎么做数据的相关性分析和聚类（招联金融）
答案：相关性分析：
画散点图，观察两个变量有没有规律变化
根据变量类型或者正态性检验，选择合适的相关系数公式
计算相关系数r，评估相关程度
显著性检验，如果P<α（一般取0.05），表示存在显著相关性
总结分析结论，并从业务层面给出业务判断及策略
根据上面的步骤，即可完成相关性分析，注意，在回答的时候在每一步最好结合业务相关的场景去解释，这样回答起来会更有说服力
聚类分析：
下面以kmeans为例，因为在描述算法的时候尽量讲了解的算法，才不至于被考倒
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210414/897353_1618395172122/7A4DE85D9C7A78531905FE8CB3978E1B]
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210414/897353_1618395182172/1D6A5D5285DFFC2F20F032DCD073DD8D]
（图片来源于网络）
同样的，最好能结合具体案例分析kmeans算法
解析：

题目3：3.DAU下降分析（快手、滴滴）
答案：模板
两步分析法：首先定位问题原因，这里可以通过计算各个维度DAU的变动系数=（该维度下异常前DAU-该维度下异常后DAU）/该维度下异常前DAU，选出变动系数较大的前几个维度，对其进行分析。
然后可以从内部和外部进行分析，内部从产品（版本更新）、技术（卡顿，闪退）、运营（运营活动）分别沟通看是否能找到原因。外部从政策和竞品的角度找原因。
解析：定位问题+找到原因

题目4：4.相关性分析（快手）
答案：有四种相关性分析的方法：
1.图标相关分析（折线图及散点图）
2.计算协方差及协方差矩阵
3.计算相关系数
4.建立一元回归或多元回归模型，做回归分析，计算r方。
解析：

题目5：5.微信日收入下降分析（快手）
答案：数据验证，验证日收入的数据口径是否一致，确认是否是真的日收入下降
指标拆解，可以参考如下指标拆解
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210414/897353_1618395523329/6C751D1CBDCFF84ACC4AF1677AE99467] 
从上述指标来看是否出问题，如果某个指标出问题，可能就是因为这个指标的下降导致收入下降。比如，从每一个数据指标去看后，发现是渠道A的付费人数下降，就可以找到负责这个渠道的同事来了解这个渠道是否真的付费人数减少，如果是真的减少的话，就找到了收入下降的原因，就可以跟进这个渠道去解决付费人数下降的问题。
解析：


======= 业务与用户分析-2 =======

题目1：6.订单量下降会从哪些方面分析？（滴滴）
答案：1.版本影响：发布新版本的时候，是app出bug的高概率期，所以拉出各版本订单数量的趋势图，如果订单量下降的时间与发版时间一致，则是版本的问题。2.活动影响：是否是运营活动的影响。
3.服务端影响：服务端有时会不定期修补服务bug or 上线新策略 or 优化原策略，导致数据流出现问题。比如用户刷新页面刷不到产品信息、或服务响应变慢等都会影响用户体验，进而影响订单量。
4.其他：漏斗分析，查询漏斗数据：日活-登录-浏览商品-加购物车-支付-支付成功。排查每两个环节之间的转化率是否与近期的转化率有较大GAP值，已确定是否是某个环节的bug导致最终的订单量下降。
解析：

题目2：7.APP用户活跃度下降，如何分析（bigo）
答案：两步分析法：首先定位问题原因，
这里可以通过计算各个维度用户活跃度的变动系数=（该维度下异常前用户活跃度-该维度下异常后用户活跃度）/该维度下异常前用户活跃度，选出变动系数较大的前几个维度，对其进行分析。
然后可以从内部和外部进行分析，内部从产品（版本更新）、技术（卡顿，闪退）、运营（运营活动）分别沟通看是否能找到原因。外部从政策和竞品的角度找原因。
解析：定位问题+找到原因

题目3：8.如何检验聚类分析结果（快手）
答案：轮廓系数。计算样本i和簇内其他样本间的平均距离得到样本i的簇内不相似度ai，计算样本i和其他簇内样本间的平均距离得到样本i的簇间不相似度bi。随后我们就得到了样本i的轮廓系数为si=(bi-ai)/max(ai,bi); 所有样本的si均值就是聚类结果的轮廓系数，轮廓系数越接近于1则说明聚类效果越好。
解析：

题目4：9.猿辅导在抖音上线一个视频，首页就有优惠券，点击优惠券的用户较多，但使用优惠券的用户较少，怎么分析（猿辅导）
答案：漏斗分析。优惠券转化漏斗：点击优惠券->至购买页面->点击下单->使用优惠券->完成支付。我们首先要确定是哪一步到哪一步的转化率低，随后与技术/产品人员沟通，共同定位原因。
解析：

题目5：10.怎么预测接下来订单数 分析日活（京东）
答案：订单数=日活*转化率。我们可以对用户进行分层，按照年龄、性别等维度对用户分层，尽可能把不同转化率的用户分开。随后对各个维度用户的日活进行预测，可以采用一元回归或机器学习的方法。最后将各个维度预测出的订单量汇总，就是最后的订单数。
解析：


======= 业务与用户分析-3 =======

题目1：11.A/B test显示B组提升了20%，如何验证是否属于正常波动（阿里）
答案：对试验结果我们要积极的进行多维度的细分分析，除了总体对比，也看一看对细分受众群体的试验结果，不要以偏盖全，也不要以全盖偏。一个试验版本提升了总体活跃度，但是可能降低了年轻用户的活跃度，那么这个试验版本是不是更好呢？一个试验版本提升总营收0.1%，似乎不起眼，但是可能上海地区的年轻女性iPhone用户的购买率提升了20%，这个试验经验就很有价值了。
解析：考察辛普森悖论

题目2：12.拼多多当月月活增加，怎么分析这批新用户是会给拼多多带来一个积极收益的用户（举例：不是渠道带来的低质量的用户或者羊毛党）（拼多多）
答案：1.用户路径分析，对这批新增用户，通过数据埋点追踪用户登录后的行为，判断是否是消费/羊毛用户。
2.将用户数据分为用户画像数据、用户消费数据、用户行为数据进行建模，根据该月这部分用户的行为通过机器学习分类预测算法该用户是否为积极用户。
解析：

题目3：13.ctr下降怎么分析（网易）
答案：CTR=实际点击次数/展示量。首先定位问题原因，分别计算各个维度实际点击次数（展示量）的变动系数=（该维度下下降前实际点击次数（展示量）-该维度下下降后实际点击次数（展示量））/该维度下下降前实际点击次数（展示量），选出变动系数较大的前几个维度，对其进行分析。然后可以从内部和外部进行分析，内部从产品（版本更新）、技术（卡顿，闪退）、运营（运营活动）分别沟通看是否能找到原因。外部从政策和竞品的角度找原因。
解析：

题目4：14.如果用户经常访问app，但是下单量较少怎么分析，用户有目的的访问app（例如搜索女装），但是下单量较少怎么分析（网易）
答案：漏斗分析。下单转化漏斗：访问app--商品详情页--购买页面--支付页面--支付成功。定位是哪个环节出现问题后，与技术人员和产品人员沟通，找到原因。
解析：

题目5：15.在分析一款小游戏时，会涉及到哪些指标？（字节跳动）
答案：基础指标：dau、mau、使用时长、使用频次、留存（短期/长期，新进/活跃）；
收入指标：内部收入量化指标：付费渗透率、arpu、LTV；
广告收入量化指标：曝光、点击、转化、出价
解析：


======= 业务与用户分析-4 =======

题目1：16.你了解的回归分析有哪些（阿里）
答案：将回归分析中的Y（因变量）进行数据类型区分，如果是定量且1个（比如身高），通常我们会使用线性回归，如果Y为定类且1个（比如是否愿意购买苹果手机），此时叫logistic回归，如果Y为定量且多个，此时应该使用PLS回归（即偏最小二乘回归）。
解析：

题目2：17.淘宝某日销售额下降，分析原因（阿里）
答案：销量=下单数 *（1-订单取消率-退货率），
这个公式就可以把销量用“下单数、订单取消率、退货率”等三个维度去量化，下单数=咨询数 *（1-咨询流失率）+浏览量 *（1-浏览流失率）；
订单取消率=支付取消数/下单数；
退货率=订单退货数/已支付订单数；所以又会引出“咨询流失率、浏览流失率、支付取消数、订单退货数”等多个衡量指标。
经过这样一层一层公式化的量化，找到那些“最小不可分割的指标”，进而最可能发现本质的问题所在了。
解析：

题目3：18.如果近期贝壳二手房成交量下跌，怎么分析（贝壳找房）
答案：首先，按照省市、价格区间等维度划分，找到是哪个维度下的二手房成交量下跌。找到原因后，分内外部进行归因，内部包括产品侧、运营侧和技术测。外部包括宏观经济政策和竞品分析。
解析：定位原因+内外部分析

题目4：19.用滴滴的行为情况，问你用哪些数据做分析，方案的优缺点，可行性，效益这类问题（滴滴出行）
答案：哪些数据做分析：指标体系搭建。采用“人货场”场景化搭建指标体系。“人”数据指标主要看发单用户数、完单用户数、客单价、周期内完单订单数、取消订单数、评价订单数等。“货”数据指标主要看成交了多少，交易额多少，花了多少，到具体数据指标主要会看GMV、成交率、取消率指标等等。“场”数据指标主要看哪个渠道用户点击量大曝光率大，带来了多少新用户，完成多少交易订单，客单价是多少。
方案的优缺点可行性等可以采用AB实验才量化。具体步骤：1. 收集指标，建立评估指标体系。2.设置实验组和对照组，分配流量。3.假设检验，评估实验结果是否显著。4.给出决策方案。
解析：指标体系问题+ab实验步骤

题目5：20.总体转化率下降，但是其余各渠道转化率正常，应该怎么进行分析？（猿辅导）
答案：这是辛普森悖论问题，多组数据分别讨论时都会满足某种性质，可是一旦合并考虑，却可能导致相反的结论。要更客观分析产品的转化率情况，就需要设立更多角度去综合评判。也就是对用户进行更细致的划分。
解析：解释什么是辛普森悖论问题+解决方法


======= 业务与用户分析-5 =======

题目1：21.某日营收下滑30%怎么分析？（斗鱼）
答案：首先验证数据的准确性，确定数据异常不是因为统计口径或数据报表异常所导致的。随后，各维度进行拆解，找到是哪个维度的收入下降显著。最后定位问题维度后通过内外部分析找到原因，内部从产品、技术和运营侧找原因，外部从政策经济和竞品找原因。
解析：

题目2：22.GMV下滑严重怎么分析（拼多多）
答案：首先确定是相比于何时下滑，是环比上月、同比去年某月、环比去年还是环比上周等下滑，通过时间的比较初步可以判断出下滑是否由于季节、节日、突发性事件和天气等影响。
随后按照公式拆解，GMV = 购买人数 * 客单价 * 购买次数，由此判断是购买人数下滑，还是客单价下滑，还是购买次数下滑。
若购买人数下滑，则将购买人数进行漏斗细分，购买人数= 流量 * 进店转化率 * 购物车转化率 * 付款转化率，判断是漏斗的哪个环节出现了下滑。若流量下滑，则要重视拉新；若进店转化率下滑，则要重视营销活动等。若客单价和购买次数下滑，则可以将客户进行细分，如分为高价值用户和低价值用户；忠诚用户和一般用户；新用户和老用户；高频购买用户和低频购买用户，判断是哪类用户的客单价和购买次数下滑了。定位问题所在后，从产品、运营和技术侧分别找原因，也可以从外部政策和竞品找原因。
解析：

题目3：23.DAU下降5%怎么分析（快手）
答案：首先验证数据的准确性，确定数据异常不是因为统计口径或数据报表异常所导致的。随后两步分析法：首先定位问题原因，这里可以通过计算各个维度DAU的变动系数=（该维度下异常前DAU-该维度下异常后DAU）/该维度下异常前DAU，选出变动系数较大的前几个维度，对其进行分析。然后可以从内部和外部进行分析，内部从产品（版本更新）、技术（卡顿，闪退）、运营（运营活动）分别沟通看是否能找到原因。外部从政策和竞品的角度找原因。
解析：确定问题+定位问题+找到原因

题目4：24.留存率下降该如何分析（拼多多）
答案：首先，明确什么留存率下降，以及下降标准（对比什么下降了）。例如次日新增用户留存率下降。次日新增用户留存率 = 当天新注册用户次日仍登录数 / 当天新注册用户数。首先定位问题原因，是分子变动过大还是分母变动过大。随后进行内外部分析，内部可以从产品和运营的角度，例如版本机型不兼容、闪退、权限获取情况等原因。外部从竞品的角度分析。
解析：

题目5：25.爱奇艺想要提高付费会员数，应从哪几个方面分析。（拼多多）
答案：内部和外部进行分析。
内部：从未付费用户，持续付费用户，流失付费用户。分别分析这些用户的付费率情况，以及如何提高对应用户的付费意愿。
外部：竞品用户。分析竞品的付费用户情况，可以从外部购买数据或数据爬虫等方法获取，分析这些用户能否转化为爱奇艺的付费用户。
解析：

题目6：26.给一张流量表，怎么识别不同渠道的变化？（拼多多）
答案：取数的时候对groupby不同的渠道进行聚合。变化的话看不同渠道的影响系数=(该渠道变化前指标-该渠道变化后指标)/总的变化前指标，就可以量化比较不同渠道变化带来的影响。
解析：


======= 机器学习与数据挖掘-1 =======

题目1：1.给你一个数列，要求你构造一个新数列，新数列里每一个值小于原数列的值且大于deng1，让abs(A[i]- A[i-1])的总值最大，比如 10 2 10 2 10，你可以构建10 1 10 1 10，输出值为36（滴滴出行）
答案：简单的思路是递归，给定序列[a_0, a_1, a_2, ..., a_k]，假设新数列前i-1个数值已经构建好了，那么我们要决策是下一个数值i要不要改成1，还是保留原值
那么就变成了比较
[b_0, b_1, b_{i-1}, a_i, con(剩下的a, a_i)]
和
[b_0, b_1, b_{i-1}, 1, con(剩下的a, 1)]
所以我们可以用递归的思路来完成
def con(x, previous_number=None):
    # 输入是原始序列的话，那么最左边的比较对象设为自己就好
    # 这样可以保证不会对要不要改成1的结果有所影响
    if previous_number is None:
        previous_number = x[0]
    k = len(x)
    if k == 1:
        # 只剩一个元素了，那就比较下是保留原值好
        # 还是变成1比较好
        if abs(1 - previous_number) > abs(x[0] - previous_number):
            x[0] = 1
        v = abs(x[0] - previous_number)
    else:
        # 有多个元素
        # 算一下保留原值带来的增益是多少
        x1_remaining, v1_remaining = con(x[1:], x[0])
        v1 = abs(x[0] - previous_number) + v1_remaining

        # 算一下改为1带来的增益是多少
        x2_remaining, v2_remaining = con(x[1:], 1)
        v2 = abs(1 - previous_number) + v2_remaining

        # 改为1有利可图，把当前子数列的第一个元素改为1
        # 然后接着往后判断
        if v1 < v2:
            v = v2
            x[0] = 1
            x_remaining = x2_remaining
        else:
            v = v1
            x_remaining = x1_remaining

        # 拼接上后面的数列元素，这里也是已经调优过的
        x = [x[0]] + x_remaining

    return x, v

# 定义一个算增益的函数
def value(x):
    v = 0
    for i in range(1, len(x)):
        v += abs(x[i] - x[i - 1])
    return v

# 构造一个数列来说明，并不是直接间隔变为1是好的策略
x = [8, 9, 5, 3, 1, 4, 7, 2, 6]
print('Before: ', x)
x, v = con(x)
print('After: ', x, value(x))

x1 = [8, 1, 5, 1, 1, 1, 7, 1, 6]
x2 = [1, 9, 1, 3, 1, 4, 1, 2, 1]
print('Comparison: ', x1, value(x1))
print('Comparison: ', x2, value(x2))

输入结果为：
Before:  [8, 9, 5, 3, 1, 4, 7, 2, 6]
After:  [1, 9, 1, 3, 1, 4, 7, 1, 6] 37
Comparison:  [8, 1, 5, 1, 1, 1, 7, 1, 6] 32
Comparison:  [1, 9, 1, 3, 1, 4, 1, 2, 1] 28

这里可以看到最佳结果[1, 9, 1, 3, 1, 4, 7, 1, 6]并不完全是间隔取1的。
解析：

题目2：2.adaboost和xgboost的区别；xgboost的并行体现在哪（工程上的并行，不是计算上的并行）（猿辅导）
答案：Adaboost与GBDT两者boosting的不同策略是两者的本质区别。
Adaboost强调Adaptive（自适应），通过不断修改样本权重（增大分错样本权重，降低分对样本权重），不断加入弱分类器进行boosting。
Xgboost则是旨在不断减少残差（回归），可以人为定义损失函数（可以是最小平方差、logistic loss function、hinge loss function或者人为定义的loss function），只需要知道该loss function对参数的一阶、二阶导数便可以进行boosting，其进一步增大了模型的泛华能力
解析：

题目3：3.K-means、 K-means 算法的优缺点（bigo、字节跳动、京东、广联达）
答案：优点：当潜在的簇形状是凸面，簇与簇之间较明显，且簇大小相近时，结果较理想。对于处理大数据，该算法高效且伸缩性较好。
缺点：要事先确定k；对于初始簇中心敏感，常以局部最优结束，对孤立点敏感，不适于发现非凸的簇或大小差别大的簇。
解析：

题目4：4.KNN、K-Means区别（京东）
答案：KNN是分类算法，它是监督学习，知道了结果去效验结果是否正确。 K-Means是聚类算法，它是非监督学习，它需要先自己算去一个结果。
解析：考察分类算法和聚类算法的区别

题目5：5.介绍一下k-means,你的数据如何处理，模型的输出是什么？（浦发银行）
答案：介绍kmeans：
第一步：数据归一化、离群点处理后，随机选择k个聚类质心
第二步：所有数据点关联划分到离自己最近的质心，形成k个簇；
第三步：重新计算每个簇的质心；
重复第二步、第三步，直到簇不发生变化或达到最大迭代次数；
数据如何处理：
为了防止均值和方差大的维度将对数据的聚类产生决定性影响，所以在聚类前我们对数据进行了归一化处理。
模型输出：
n个维度，输出为[公式:图片说明|https://www.nowcoder.com/equation?tex=n*1] 的向量。[0 1 1 0 1]，就是把第1，4维分为一类，其他分为另一类。
解析：kmeans聚类的过程和步骤。


======= 机器学习与数据挖掘-2 =======

题目1：6.实习内容中：RFM模型和kmeans（猿辅导）
答案：RFM模型根据客户活跃程度和交易金额的贡献，进行客户价值细分的     一种方法。它能够识别优质客户；可以制定个性化的沟通和营销服务，为更多的营销决策提供有力支持；能够衡量客户价值和客户利润创收能力。
R（Recency）——最近一次交易时间间隔。
F（Frequency）——客户在最近一段时间内交易次数。
M（Monetray）——客户最近一段时间内交易金额。
Kmeans算法：
第一步：数据归一化、离群点处理后，随机选择k个聚类质心
第二步：所有数据点关联划分到离自己最近的质心，形成k个簇；
第三步：重新计算每个簇的质心；
重复第二步、第三步，直到簇不发生变化或达到最大迭代次数。
解析：

题目2：7.特征工程怎么做的，选择了哪些特征作为预测变量？为什么用RFM模型来构建特征变量？（字节跳动）
答案：特征工程包括：特征构建->特征提取->特征选择。
选择特征：用户行为特征、用户消费特征、用户画像特征
为什么RFM模型：因为我们没有太多的用户行为数据，能用的数据比较有限。但是有一定的成交数据。只要有成交数据，就能进行RFM的分析。其次，模型的分层可解释性强。其他很多算法模型、机器学习模型，往往通过聚类进行用户的分层，对于业务来讲，不是很好解释。但RFM模型分成的用户类别，是非常好理解的。
解析：

题目3：8.rfm模型介绍一下？（京东、作业帮）
答案：RFM模型根据客户活跃程度和交易金额的贡献，进行客户价值细分的     一种方法。它能够识别优质客户；可以制定个性化的沟通和营销服务，为更多的营销决策提供有力支持；能够衡量客户价值和客户利润创收能力。
R（Recency）——最近一次交易时间间隔。
F（Frequency）——客户在最近一段时间内交易次数。
M（Monetray）——客户最近一段时间内交易金额。
解析：

题目4：9.xgb原理（猿辅导）
答案：xgboost就是一堆CART树的集合，将每棵树的预测值加在一起得到最后的预测值。xgboost利用了损失函数二阶的导数信息，并且在目标函数之外加入了正则项，避免过拟合。
解析：

题目5：10.实习项目介绍，为什么用xgb（猿辅导）
答案：xgboosting在传统boosting的基础上，利用cpu的多线程，引入正则化项，控制了模型的复杂度。并且xgb可并行处理，并能对缺失值处理，还内置交叉验证。
解析：xgboost的优点


======= 机器学习与数据挖掘-3 =======

题目1：11.模型过拟合怎么处理（百度）
答案：1.获取更多数据，扩大数据量。
2.降低模型复杂度。
3.添加正则项。
4.改为集成学习。
解析：

题目2：12.介绍一下模型融合（百度）
答案：Bagging就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。例如随机森林。
解析：

题目3：13.文本匹配算法（中电十所）
答案：传统的文本匹配算法Jaccard：两句子分词后词语的交集中词语数与并集中词语数之比。Simhash：先计算两句子的simhash二进制编码，然后使用海明距离计算，最后使用两句的最大simhash值归一化得相似度。
解析：选2-3个传统的文本匹配算法说一下原理即可

题目4：14.怎么防止过拟合（猿辅导）
答案：1.获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法
让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是创建“假数据”并添加到训练集中——数据集增强。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。
2. 采用合适的模型（控制模型的复杂度）
过拟合主要是有两个原因造成的：数据太少+模型太复杂。所以，我们可以通过使用合适复杂度的模型来防止过拟合问题。
3.降低特征的数量
对于一些特征工程而言，可以降低特征的数量——删除冗余特征，人工选择保留哪些特征。这种方法也可以解决过拟合问题
4.结合多种模型
简而言之，训练多个模型，以每个模型的平均输出作为结果。比如bagging和boosting，都能很好的解决过拟合。
解析：这道题主要考验过拟合的概念及如何防止过拟合，过拟合是指训练误差和测试误差之间的差距太大。就是说模型复杂度高于实际问题，模型在训练集上表现很好，但在测试集上却表现很差。

题目5：15.xgboost rf不同（快手）
答案：1、随机森林采用的bagging思想，而xgboost采用的boosting思想。
2、组成随机森林的树可以并行生成；而xgboost只能是串行生成。
3、对于最终的输出结果而言，随机森林采用多数投票等；而xgboost则是将所有结果累加起来，或者加权累加起来。
4、随机森林对异常值不敏感；xgboost对异常值非常敏感。
5、随机森林对训练集一视同仁；xgboost是基于权值的弱分类器的集成。
解析：这道题主要是考察xgboost和随机森林的区别，只要能大致描述几个本质上的区别即可


======= 数据分析-8 =======

题目1：36.数据分析方面的优点和缺点（小红书）
答案：>
参考答案
优点：执行力强，在过去的学习和实习任务时，从来都不会在最后赶ddl，而是会提前准备好；沟通协作能力强，之前在xx项目上需要与其他人沟通，总是会让我去协调沟通；学习能力强，之前的学习和实习中，总是能够快速get到老师的知识点/业务的逻辑。
缺点：记忆力不是很好，但是后面我会把重要的事情写在备忘录或者笔记本上，提醒自己。
解析：优点给出2-3个即可，配上例子说明；缺点1-2个即可，并且说明自己用了什么办法改进缺点。缺点不能是致命的缺陷，例如情绪悲观这种。

题目2：37.数据分析中不同基数样本的增长比率如何比较（滴滴）
答案：对样本数据分等级，例如0-100为一级，100-500为一级，以此类推。在统一等级中比率高方差低的胜出；在不同等级中，若方差相近则直接比较比率，若方差是不齐则归一化后再比较。
解析：

题目3：38.科研项目用的数据分析方法是什么？（快手）
答案：答案解析
如果是机器学习或深度学习，则从数据来源，数据清洗，特征筛选，建立模型，模型效果分别阐述，追问可能会涉及到模型原理，特征筛选理由，需要提前准备；如果是业务相关的项目，则从数据来源，业务逻辑，项目意义的层面上分点说明自己的项目，最好提前能够总结出方法论，说明这个项目给你带来的价值也可以应用到实习/工作中。
解析：如果是机器学习或深度学习，则从数据来源，数据清洗，特征筛选，建立模型，模型效果分别阐述，追问可能会涉及到模型原理，特征筛选理由，需要提前准备；如果是业务相关的项目，则从数据来源，业务逻辑，项目意义的层面上分点说明自己的项目，最好提前能够总结出方法论，说明这个项目给你带来的价值也可以应用到实习/工作中。

题目4：39.问自己做过的数据分析的case 从中的收获 遇到了什么问题（快手）
答案：（回答模板）
从项目背景、分析思路、分析结论、策略落地、落地效果分别阐述。
项目背景也就是为什么要做这个分析。分析思路也就是你的分析过程，比如从供给侧，我们衡量了xxx和xx指标，从消费侧，我们衡量了xx。分析结论是通过这个分析，我们发现了xxx现象。针对这一现象，我们与xxx和xxx部门沟通，准备实施xxx策略，最后在几周的观察下来，这一策略有非常好的效果，xxx指标得到了显著的提高。
收获：通过这个case，我了解了数据分析的流程，以及对xxx业务更加深入的了解，收获了一些思考方向，这对我以后的业务也有很大的帮助。
问题：在分析策略落地时，由于分析过程到分析结论不够严谨，所以遭受了一些质疑和推进上的阻碍，但是在后来反思复盘后，让逻辑更为严谨，也略微改动了沟通方法，沟通也就顺畅了许多。
解析：

题目5：40.站在数据分析师的角度，如何去评价万国觉醒里的一个活动（吉比特&雷霆游戏）
答案：（可以从哪些角度）
1.活动总体效果评估：增长的平均收入、付费率、新用户数等。
2.活动效果评估：对比不同活动上线后的效果。
3.评估活动对新用户和游戏收入的影响。
4.得出分析结论。对于效果好的活动，可形成活动模板，作为长期定期进行的活动。对于没有效果的活动，进行改进后再推行，依然没有起色的，不再推进。
解析：


======= 机器学习与数据挖掘-4 =======

题目1：16.lstm的原理、lstm和rdd的区别（猿辅导）
答案：LSTM原理：
LSTM 是一种特殊的RNN。通过精巧的设计（CNN中的深度残差网络也是类似）解决长序列训练过程中的梯度消失和梯度爆炸问题（即远距离传递导致的信息丢失问题）。标准RNN由简单的神经网络模块按时序展开成链式。这个重复模块往往结构简单且单一，如一个tanh层。这种记忆叠加方式显得简单粗暴。LSTM内部有较为复杂的结构。能通过门控状态来选择调整传输的信息，记住需要长时记忆的信息，忘记不重要的信息。LSTM关键在于增加一条贯穿与链上的信息传送带，称为细胞状态（cell state）。LSTM通过精心设计门结构来对cell state上的信息进行增添和移除。门是使得信息选择式通过的方法。包含一个 sigmoid 神经网络层和一个 pointwise 乘法操作。Sigmoid 层输出0到1之间的数值，描述每个部分有多少量可以通过。0 代表“不许任何量通过”，1 代表“允许任意量通过”。LSTM通过三个门结构来维护cell state上的信息。
RNN和LSTM的区别如下：
1.RNN没有细胞状态；LSTM通过细胞状态记忆信息。
2.RNN激活函数只有tanh；LSTM通过输入门、遗忘门、输出门引入sigmoid函数并结合tanh函数，添加求和操作，减少梯度消失和梯度爆炸的可能性。
3.RNN只能够处理短期依赖问题；LSTM既能够处理短期依赖问题，又能够处理长期依赖问题。
解析：这道题主要是考察对LSTM的理解，以及与其他神经网络算法的区别

题目2：17.处理噪声数据方法（京东）
答案：1、分箱
分箱方法是一种简单常用的预处理方法，通过考察相邻数据来确定最终值。所谓“分箱”，实际上就是按照属性值划分的子区间，如果一个属性值处于某个子区间范围内，就称把该属性值放进这个子区间所代表的“箱子”内。把待处理的数据（某列属性值）按照一定的规则放进一些箱子中，考察每一个箱子中的数据，采用某种方法分别对各个箱子中的数据进行处理。在采用分箱技术时，需要确定的两个主要问题就是：如何分箱以及如何对每个箱子中的数据进行平滑处理。
分箱的方法：有4种：等深分箱法、等宽分箱法、最小熵法和用户自定义区间法。
（1）统一权重
也称等深分箱法，将数据集按记录行数分箱，每箱具有相同的记录数，每箱记录数称为箱子的深度。这是最简单的一种分箱方法。
（2）统一区间
也称等宽分箱法，使数据集在整个属性值的区间上平均分布，即每个箱的区间范围是一个常量，称为箱子宽度。
（3）用户自定义区间
用户可以根据需要自定义区间，当用户明确希望观察某些区间范围内的数据分布时，使用这种方法可以方便地帮助用户达到目的。
例：客户收入属性income排序后的值（人民币元）：800 1000 1200 1500 1500 1800 2000 2300 2500 2800 3000 3500 4000 4500 4800 5000，分箱的结果如下。
统一权重：设定权重（箱子深度）为4，分箱后
箱1：800 1000 1200 1500
箱2：1500 1800 2000 2300
箱3：2500 2800 3000 3500
箱4：4000 4500 4800 5000
统一区间：设定区间范围（箱子宽度）为1000元人民币，分箱后
箱1：800 1000 1200 1500 1500 1800
箱2：2000 2300 2500 2800 3000
箱3：3500 4000 4500
箱4：4800 5000
用户自定义：如将客户收入划分为1000元以下、、2000-3000、3000-000和4000元以上几组，分箱后
箱1：800
箱2：1000 1200 1500 1500 1800 2000
箱3：2300 2500 2800 3000
箱4：3500 4000
箱5：4500 4800 5000
（4）数据平滑方法
数据平滑方法又可以细分为：平均值平滑、按边界值平滑和按中值平滑。
按平均值平滑
对同一箱值中的数据求平均值，用平均值替代该箱子中的所有数据。
按边界值平滑
用距离较小的边界值替代箱中每一数据。
按中值平滑
取箱子的中值，用来替代箱子中的所有数据。
2、聚类
将物理的或抽象对象的集合分组为由类似的对象组成的多个类。
找出并清除那些落在簇之外的值（孤立点），这些孤立点被视为噪声。
3、回归
试图发现两个相关的变量之间的变化模式，通过使数据适合一个函数来平滑数据，即通过建立数学模型来预测下一个数值，包括线性回归和非线性回归。
解析：这道题主要考察对噪声数据的处理，在建模过程中，前期数据的处理非常麻烦，所以对噪声数据的处理就更加重要了。常用的噪声处理有3种，为分箱，聚类，回归。

题目3：18.了解逻辑回归、决策树吗（贝壳找房）
答案：逻辑回归：
逻辑回归是用来做分类算法的，大家都熟悉线性回归，一般形式是Y=aX+b，y的取值范围是[-∞, +∞]，有这么多取值，怎么进行分类呢？不用担心，伟大的数学家已经为我们找到了一个方法。也就是把Y的结果带入一个非线性变换的Sigmoid函数中，即可得到[0,1]之间取值范围的数S，S可以把它看成是一个概率值，如果我们设置概率阈值为0.5，那么S大于0.5可以看成是正样本，小于0.5看成是负样本，就可以进行分类了。
Sigmoid函数如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210419/897353_1618818226188/345CE138B0B9C9A7BF9543731F210E09]
函数中t无论取什么值，其结果都在[0,-1]的区间内，回想一下，一个分类问题就有两种答案，一种是“是”，一种是“否”，那0对应着“否”，1对应着“是”，那又有人问了，你这不是[0,1]的区间吗，怎么会只有0和1呢？这个问题问得好，我们假设分类的阈值是0.5，那么超过0.5的归为1分类，低于0.5的归为0分类，阈值是可以自己设定的。
好了，接下来我们把aX+b带入t中就得到了我们的逻辑回归的一般模型方程：
结果P也可以理解为概率，换句话说概率大于0.5的属于1分类，概率小于0.5的属于0分类，这就达到了分类的目的。
决策树：
决策树是一种机器学习的方法。决策树的生成算法有ID3, C4.5和C5.0等。决策树是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果。
决策树的构造过程：
决策树的构造过程一般分为3个部分，分别是特征选择、决策树生产和决策树裁剪。
（1）特征选择：
特征选择表示从众多的特征中选择一个特征作为当前节点分裂的标准，如何选择特征有不同的量化评估方法，从而衍生出不同的决策树，如ID3（通过信息增益选择特征）、C4.5（通过信息增益比选择特征）、CART（通过Gini指数选择特征）等。
目的（准则）：使用某特征对数据集划分之后，各数据子集的纯度要比划分钱的数据集D的纯度高（也就是不确定性要比划分前数据集D的不确定性低）
（2）决策树的生成
根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树停止生长。这个过程实际上就是使用满足划分准则的特征不断的将数据集划分成纯度更高，不确定行更小的子集的过程。对于当前数据集的每一次划分，都希望根据某个特征划分之后的各个子集的纯度更高，不确定性更小。
（3）决策树的裁剪
决策树容易过拟合，一般需要剪枝来缩小树结构规模、缓解过拟合。
决策树主要的算法有ID3,C4.5和CART，感兴趣的小伙伴可以深入研究。
解析：

题目4：19.常用pandas哪个包（京东）
答案：pandas中主要有两种数据结构，分别是：Series和DataFrame。
 Series：一种类似于一维数组的对象，是由一组数据(各种NumPy数据类型)以及一组与之相关的数据标签(即索引)组成。仅由一组数据也可产生简单的Series对象。
DataFrame：一个表格型的数据结构，包含有一组有序的列，每列可以是不同的值类型(数值、字符串、布尔型等)，DataFrame即有行索引也有列索引，可以被看做是由Series组成的字典。
常用功能：
①读入CSV
data = pd.read_csv('C:\Users\xxx.csv'）
如果涉及中文标题，加入参数： data = pd.read_csv('C:\Users\xxx.csv',encoding='GBK')
②获取行名、列名、行数、列数
data.dtypes     # 查看dataframe 的数据类型
data.columns   # 列名列表
data.shape    #获取行列，返回数组，可以在后面加[0] 行  [1] 列
data.describe()  #常看数据统计
③重命名
重命名所有列   data.columns = ['A','B']   按照顺序重新命名所有列
data.rename(columns={'A':'a', 'B':'b', 'C':'c', 'D':'d'}, inplace = True)   这种方式可以任意更改列名，且不用注意顺序。
④新增列、删除行
data['a']  = data['b']- 1      新增列并赋值
data.drop['2']                  删除索引为2的行
⑤筛选
筛选行列 ：   df.at、 df.ix、df.loc、df.iloc等用法
df.ix  可以用数字也可以用列明来筛选 如： data.ix[1,1]   data.ix["a","B"]
df.loc 只能用行名和列名来筛选  data.loc["b","B"]    data.loc['b':'c','B','C']
df.iloc 只能用数字 data.loc[1,1]
 df.at     可以支持数字行序和列名的混合使用： data[1,'a']   可支持变量序号 如：  for i in range(0,100):    print(data.at[i,'shop_name'])
筛选空值、等于某值：
单条件： df[df.D>0]
多条件：  df[(df.D>0)&(df.C<0)]
包含多值： df.A.isin([‘重庆’,’成都’])
⑥分组
data.groupby("a")   #按照a列来分组处理数据，可以对处理后的数据进行sum(),count(),mean()等方式处理
解析：这道题主要考察对pandas的使用，只要说出pandas常用的功能及使用方式即可

题目5：20.PCA知道吗（广联达）
答案：在统计学中，主成分分析(PCA)是一种简化数据集的技术。它是一个线性变换。这个变换把数据变换到一个新的坐标系统中，使得任何数据投影的第一大方差在第一个坐标(称为第一主成分)上，第二大方差在第二个坐标(第二主成分)上，依次类推。主成分分析经常用减少数据集的维数，同时保持数据集的对方差贡献最大的特征。这是通过保留低阶主成分，忽略高阶主成分做到的。这样低阶成分往往能够保留住数据的最重要方面。但是，这也不是一定的，要视具体应用而定。
PCA的算法步骤如下:
设有m条n维数据。
1、将原始数据按列组成n行m列矩阵X
2、将X的每一行(代表一个属性字段)进行零均值化，即减去这一行的均值
3、求出协方差矩阵[公式:图片说明|https://www.nowcoder.com/equation?tex=C%3D%20%5Cfrac%7B1%7D%7Bm%7DX%20X%5E%7BT%7D]
4、求出协方差矩阵的特征值及对应的特征向量
5、将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P
 Y=PX即为降维到k维后的数据
解析：这道题主要考察PCA主成分分析，只要将主成分分析的基本概念描述出来即可


======= 机器学习与数据挖掘-5 =======

题目1：21.EM算法知道吗（广联达）
答案：EM算法解决问题的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含参数(EM 算法的E步)，接着基于观察数据和猜测的隐含参数一起来极大化对数似然，求解我们的模型参数(EM算法的M步)。由于我们之前的隐含参数是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。我们基于当前得到的模型参数，继续猜测隐含参数(EM算法的E步)，然后继续极大化对数似然，求解我们的模型参数(EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。
例如：
先设定男生和女生的身高分布参数(初始值)，例如男生的身高分布为 N(p=172=52)，女生的身高分布为N(2=162,吃=52)，当然了，刚开始肯定没那么准;然后计算出每个人更可能属于第一个还是第二个正态分布中的(例如，这个人的身高是180那很明显，他极大可能属于男生)，这个是属于Expectation 一步。
我们已经大概地按上面的方法将这200个人分为男生和女生两部分，我们就可以根据之前说的极大似然估计分别对男生和女生的身高分布参数进行估计，这步称为 Maximization。
然后，当我们更新这两个分布的时候，每一个学生属于女生还是男生的概率又变了，那么我们就再需要调整E步。
如此往复，直到参数基本不再发生变化或满足结束条件为止。
解析：这道题考验EM算法，EM的意思是“Expectation Maximization"。只要将EM算法的大致流程描述清楚即可

题目2：22.评价指标（广联达）
答案：1、混淆矩阵
混淆矩阵是监督学习中的一种可视化工具，主要用于比较分类结果和实例的真实信息。矩阵中的每一行代表实例的预测类别，每一列代表实例的真实类别。
真正(True Positive , TP)：被模型预测为正的正样本。
假正(False Positive , FP)：被模型预测为正的负样本。
假负(False Negative , FN)：被模型预测为负的正样本。
真负(True Negative , TN)：被模型预测为负的负样本。
真正率(True Positive Rate,TPR)：TPR=TP/(TP+FN)，即被预测为正的正样本数 /正样本实际数。
假正率(False Positive Rate,FPR) ：FPR=FP/(FP+TN)，即被预测为正的负样本数 /负样本实际数。
假负率(False Negative Rate,FNR) ：FNR=FN/(TP+FN)，即被预测为负的正样本数 /正样本实际数。
真负率(True Negative Rate,TNR)：TNR=TN/(TN+FP)，即被预测为负的负样本数 /负样本实际数/2
2、准确率（Accuracy）
准确率是最常用的分类性能指标。
Accuracy = (TP+TN)/(TP+FN+FP+TN)
即正确预测的正反例数 /总数
3、精确率（Precision）
精确率容易和准确率被混为一谈。其实，精确率只是针对预测正确的正样本而不是所有预测正确的样本。表现为预测出是正的里面有多少真正是正的。可理解为查准率。
Precision = TP/(TP+FP)
即正确预测的正例数 /预测正例总数
4、召回率（Recall）
召回率表现出在实际正样本中，分类器能预测出多少。与真正率相等，可理解为查全率。
Recall = TP/(TP+FN)，即正确预测的正例数 /实际正例总数
5、F1 score
F值是精确率和召回率的调和值，更接近于两个数较小的那个，所以精确率和召回率接近时，F值最大。很多推荐系统的评测指标就是用F值的。
2/F1 = 1/Precision + 1/Recall
6、AUC
AUC（Area Under Curve）被定义为ROC曲线下的面积(ROC的积分)，通常大于0.5小于1。随机挑选一个正样本以及一个负样本，分类器判定正样本的值高于负样本的概率就是 AUC 值。AUC值(面积)越大的分类器，性能越好
解析：这道题主要考察机器学习的评价指标，需要将机器学习的常见指标描述出来。

题目3：23.那，表示距离的指标有哪些？（广联达）
答案：1.欧氏距离，最常见的两点之间或多点之间的距离表示法，又称之为欧几里得度量，它定义于欧几里得空间中，如点 x = (x1,...,xn) 和 y = (y1,...,yn) 之间的距离为：
[公式: |https://uploadfiles.nowcoder.com/images/20210419/897353_1618823145127/7DEBE3A97AF4B18B759EC0B368D49F7C]
2. 曼哈顿距离，我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。例如在平面上，坐标（x1,y1）的点P1与坐标（x2, y2）的点P2的曼哈顿距离为：[公式: |https://uploadfiles.nowcoder.com/images/20210419/897353_1618823212338/F68256781DDBE8D2569864A19B181152] ，要注意的是，曼哈顿距离依赖座标系统的转度，而非系统在座标轴上的平移或映射。
3. 切比雪夫距离，若二个向量或二个点p 、and q，其座标分别为及，则两者之间的切比雪夫距离定义如下：[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210419/897353_1618823257759/2224F121579945D91E9DE9106890A074]
4. 标准化欧氏距离 (Standardized Euclidean distance )，标准化欧氏距离是针对简单欧氏距离的缺点而作的一种改进方案。标准欧氏距离的思路：既然数据各维分量的分布不一样，那先将各个分量都“标准化”到均值、方差相等。
5. 汉明距离(Hamming distance)，两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2。应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。
6. 夹角余弦(Cosine) ，几何中夹角余弦可用来衡量两个向量方向的差异，机器学习中借用这一概念来衡量样本向量之间的差异。
解析：

题目4：24. ROC的了解情况，怎么画ROC（猿辅导）
答案：逻辑回归里面，对于正负例的界定，通常会设一个阈值，大于阈值的为正类，小于阈值为负类。如果我们减小这个阀值，更多的样本会被识别为正类，提高正类的识别率，但同时也会使得更多的负类被错误识别为正类。为了直观表示这一现象，引入ROC。根据分类结果计算得到ROC空间中相应的点，连接这些点就形成ROC curve，横坐标为False Positive Rate(FPR假正率)，纵坐标为True Positive Rate(TPR真正率)。一般情况下，这个曲线都应该处于(0,0)和(1,1)连线的上方。
ROC曲线中的四个点和一条线: 点(0,1)：即FPR=0, TPR=1，意味着FN＝0且FP＝0，将所有的样本都正确分类。 点(1,0)：即FPR=1，TPR=0，最差分类器，避开了所有正确答案。 点(0,0)：即FPR=TPR=0，FP＝TP＝0，分类器把每个实例都预测为负类。 点(1,1)：分类器把每个实例都预测为正类。 总之：ROC曲线越接近左上角，该分类器的性能越好。而且一般来说，如果ROC是光滑的，那么基本可以判断没有太大的overfitting
解析：这道题主要是考察ROC的基础知识，需要能够描述ROC的计算方式和如何画出曲线

题目5：25.有很多维度的特征怎么来筛选？有什么方法？具体讲一个例子来（拼多多）
答案：1.Filter方法（过滤式）：对每一维特征打分，即给每一维的特征赋予权重，这样的权重就代表着该特征的重要性，然后依据权重排序。
2.Wrapper方法（包裹式）：将子集的选择看作是一个搜索寻优问题，生成不同的组合，对组合进行评价，再与其他的组合进行比较。
3. Embedded方法（嵌入式）：在模型既定的情况下学习出对提高模型准确性最好的特征。也就是在确定模型的过程中，挑选出那些对模型的训练有重要意义的特征。
具体的例子：岭回归，在线性回归过程加入了L2正则项。
解析：高维数据中的特征筛选方法


======= 机器学习与数据挖掘-6 =======

题目1：26.L1、L2的原理？两者区别？（苏宁）
答案：原理：
L1正则是基于L1范数和项，即参数的绝对值和参数的积项；L2正则是基于L2范数，即在目标函数后面加上参数的平方和与参数的积项。
区别：
1.鲁棒性：L1对异常点不敏感，L2对异常点有放大效果。
2.稳定性：对于新数据的调整，L1变动很大，L2整体变动不大。
解析：数据分析只需要简单知道原理和区别就行，公式推导不需要，面试过程中也不会出现。

题目2：27.boosting 和 bagging的区别（快手）
答案：boosting：训练基分类器时采用串行的方法，各个基分类器有依赖，每一层训练时，对前一层分错的样本给与更高的权重，测试时，根据各层分类器的结果的加权得到最终结果。
bagging：集体决策，分而治之。基分类器最好是本身，对样本分布较为敏感。
解析：

题目3：28.逻辑回归和xgboost有什么区别（字节跳动、美团）
答案：逻辑回归：假设数据服从伯努利分布，通过极大似然函数的方法，运用梯度下降来求解参数，来达到数据二分类的目的。
xgboost：通过boosting的思想，由一堆cart树，将每棵树的预测值加在一起就得到了最后的预测值。
1.从模型的角度上来说，两者本质都是监督学习，但是LR是线性模型，XGB是非线性模型。
2.从策略的角度上来说，LR本质是分类器算法，XGB本质是回归算法。
3.从使用的角度上来说，XGB的Loss比较复杂，参数比较多，但是可以支持自定义Loss，会自动求一阶和二阶导数，也就是说其实是一个残差学习框架，应用于适用感知器准则的任何框架。
4.从特征的角度上来说，LR不具备特征筛选的能力，它假设特征之间是相互独立的，只具有线性分界面。
解析：说明定义+从2-3个角度上说一下两者的区别。

题目4：29.有关机器学习random forest 和xgboost的区别（同盾科技）
答案：RF：采用Bootstrap的随机有放回的抽样，抽样出N份数据集，训练出N个决策树。然后根据N个决策树输出的结果决定最终结果。xgboost：通过boosting的思想，由一堆cart树，将每棵树的预测值加在一起就得到了最后的预测值。
1.RF属于集成学习Bagging，而XGB属于集成学习Boosting。2.RF是通过减少模型方差提高性能；XGB是通过减少模型偏差提高性能。3.对于最终的输出结果而言，RF采用多数投票等；而XGB则是将所有结果累加起来，或者加权累加起来。
解析：

题目5：30.介绍自己学习了JD中提到的XGBOOST算法（美团）
答案：1.xgboost中把损失函数的二阶泰勒展开的差值作为学习目标，利用牛顿法进行优化，来逼近损失函数的最小值。
2.并且利用L2正则来防止过拟合。
3.在缺失值的处理上，通过枚举所有缺失值在当前节点是进入左子树，还是进入右子树更优来决定一个处理缺失值默认的方向。
解析：从xgb的几个重要特征或者优点来介绍。


======= 机器学习与数据挖掘-7 =======

题目1：31.决策树模型用到的xgboost（腾讯）
答案：首先，介绍背景（包括项目背景+所用数据集特征+预设目标）。随后根据这个数据集的特征再结合xgb的优势，所以才用xgb（为什么要用xgb）。最后说明用了之后的效果，是否达成了预设目标/达成了其他的目标。
解析：需要结合简历上的项目来介绍，包括为什么要用以及用了之后的效果。

题目2：32.xgboost的特性（腾讯）
答案：1.梯度下降，利用损失函数的二阶导数作为学习目标，采用牛顿法进行优化。2.正则项，利用L2正则来防止过拟合。
3.树节点分裂方法，不是简单地按照样本个数进行分位，而是以二阶导数值作为权重。
4。shrinkage（收缩）方法，相当于学习系数eta。对每颗子树都要乘上该系数，防止过拟合。
解析：

题目3：33.为什么选择xgboost而不是其他（腾讯）
答案：介绍项目背景（主要是数据集特征），再说明xgb的优点（符合你的项目背景和数据集特征的优点），实在没有符合项目背景的优点可以直接介绍xgb与其他集成学习优势的地方（利用了损失函数的二阶导数，L2正则，缺失值处理等）来说明自己了解这个算法的优点。
解析：

题目4：34.xgboost的优点（腾讯）
答案：1.利用了损失函数的二阶导数，使得最终值逼近真实值。
2.out-of-core, cache-aware优化内存等方法来加速计算。
3.利用L2正则来防止过拟合。
4.shrinkage（收缩）方法，相当于学习系数eta。对每颗子树都要乘上该系数，防止过拟合。
5.缺失值处理：通过枚举所有缺失值在当前节点是进入左子树，还是进入右子树更优来决定一个处理缺失值默认的方向。
6.支持并行处理，提高了处理速度。
解析：选3-4个即可

题目5：35.xgboost常用的调参参数有哪些（腾讯）
答案：1.max_depth：树的最大深度。 这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。 需要使用CV函数来进行调优。
2.eta：学习率。 通过减少每一步的权重，可以提高模型的鲁棒性。3.n_estimator: 这是生成的最大树的数目，也是最大的迭代次数。4.objective：定义需要被最小化的损失函数。
5.booster：选择每次迭代的模型
解析：

题目6：36.研究生项目的面部识别模型，问了我GBM是什么，优缺点；还问了SVM/GBM/XGBoost的共同点和比较；最后问了XGBoost比较GBDT的区别。（招联金融）
答案：GBM算法是先根据初始模型计算伪残差，之后建立一个基学习器来解释伪残差，该基学习器是在梯度方向上减少残差。再将基学习器乘上权重系数(学习速率)和原来的模型进行线性组合形成新的模型。这样反复迭代就可以找到一个使损失函数的期望达到最小的模型。
优点：
1.继承了单一决策树的优点，又摒弃了它的缺点；
2.能处理缺失数据；
3.对于噪声数据不敏感；
4.能拟合复杂的非线性关系；
5.精确度较高；
6.通过控制迭代次数能控制过度拟合；
7.计算速度快，性能较优。
缺点：
1.顺序计算；
2.可能会出现过拟合现象；
3.设置参数较多；
4.抗干扰能力不强。
GBM/XGBoost的共同点和比较
相同点：
1.都是采用集成学习boosting的思想。
2.都可以在特征上并行处理。
不同点：
1.XGBoost 使用的是近似算法，先对特征值进行预排序，然后根据二阶梯度进行分桶，能够更精确的找到数据分隔点，但是复杂度较高。LightGBM 使用的是 histogram 算法，只需要将数据分割成不同的段即可，不需要进行预先的排序。占用的内存更低，数据分割的复杂度更低。
2.决策树生长策略，XGBoost 采用的是 Level-wise 的树生长策略，LightGBM 采用的是 leaf-wise 的生长策略，以最大信息增益为导向。后者进度更高，容易过拟合，所以要控制最大深度。
3.并行策略对比，XGBoost 的并行主要集中在特征并行上，而 LightGBM 的并行策略分特征并行，数据并行以及投票并行。
XGBoost比较GBDT的区别：
1.GBDT无显式正则化;
2.GBDT仅使用了目标函数一阶泰勒展开，而XGBoost使用了二阶的泰勒展开值，加快收敛速度；
3.XGBoost加入了列采样；
4.XGBoost对缺失值的处理；
5.XGBoost通过预排序的方法来实现特征并行，提高模型训练效率；
6.XGBoost支持分布式计算。
解析：

题目7：37.SVM原理（工商银行、同盾科技、腾讯）
答案：SVM是在特征空间上找到最佳的分离超平面，使得训练集上的正负样本间隔最大。是用来解决二分类问题的有监督学习算法，在引入核方法后也可以解决非线性问题。
解析：


======= python-1 =======

题目1：1.python讲自己用过的包的具体用法（滴滴）
答案：1.numpy，用来做多维数组的运算的，之前在xx项目中用numpy做一些数据运算的工作。
2.pandas，用来处理表格和复杂数据的，我主要用它在数据清洗这一步。3.matplotlib，用来数据可视化，在对处理好的数据我想简单看一下频数分布或者相关性之类的很轻松的可以画出图片。
4.sklearn，用户机器学习建模，在数据建模这部分用到，我经常用的模型有随机森林和xgb（引导面试官问这两者的区别）。
解析：用过的包+用途+用这个做了什么

题目2：2.python 斐波那契数列（猿辅导）
答案：def fib(self, n: int) -> int:
        a, b = 0, 1
        for i in range(n):
            a, b = b, a + b
        return a % 1000000007
解析：

题目3：3.python去重（京东）
答案：1.set对list去重
2.groupby去重
3.distinct去重
解析：

题目4：4.介绍自己常用的语言，是否会用python（中银金科）
答案：在实习的过程中，主要使用的语言是sql和python，sql主要用于将数据从数据库中提取出来，如果数据量较小的话我就直接用excel处理，但是如果数据量较大的话我就要用python处理。平时除了用python做数据处理外，还会用python做一些可视化的图表和机器学习建模。
解析：数据分析常用的语言是sql和python

题目5：5.Python的list和numpy的array有什么区别（工商银行）
答案：1.list可以存放不同类型的数据，比如int、float和str，甚至布尔型；而一个numpy数组中存放的数据类型必须全部相同，例如int或float。
2.在索引方式上，numpy.array支持比list更多的索引方式。
解析：


======= 业务指标-2 =======

题目1：6.业务问题- 异常订单 两者纠纷处理（京东）
答案：京东作为一家优先考虑用户体验及服务的电商平台，在出现异常订单时应优先考虑用户的利益，在第一时间了解情况，要求用户或商家提供相应的文字、图片等关键证据。在了解情况下，根据提前制定的针对订单所处状态及用户诉求制定的策略，尽最大可能满足用户的诉求。事后再根据用户或商家补充的证据进行回检。若确定用户诉求合理的情况下，损失由商家承担。如果用户提出的无理诉求，则予以退回。因此异常订单整体的处理流程应为：
1） 第一时间向用户和商家了解情况，要求提供关键证据
2） 根据制度尽最大可能满足用户的诉求
3） 用户诉求合理则损失由商家承担，否则拒绝
解析：

题目2：7.游戏业务中有哪些常用指标？（字节跳动）
答案：[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210419/897353_1618827421571/15023A859221A658B98C3F2DA745436E]
解析：比较关键的指标，流量相关的有用户量、用户转化率、留存率，内容相关的有用户在线时长、有效游戏时长，收入相关指标有用户付费率、LTV、ROI等。

题目3：8.淘宝想发展短视频业务，请你对行业进行分析，并分析淘宝短视频的竞争力等（阿里）
答案：短视频行业现状：目前我国正处于短视频风口之上，各大互联网巨头纷纷入局短视频行业，在遇到新冠疫情之后，短视频的传播力进一步增强，市场规模进一步扩大。虽然产品及派系众多，但目前国内市场格局相对稳定，抖音、快手稳居第一梯队，两APP的用户数与用户粘性都很高。目前短视频开始向各个领域蔓延，美妆、搞笑、美食、游戏等领域已经逐渐成熟，短视频也成了各大广告主营销的主要渠道。
淘宝短视频竞争力：淘宝本身自带大型流量，为短视频业务提供了重要的基础；当前抖音快手主要以音乐、情景剧、段子等内容为主，淘宝若想入局，就要找到突破口，打造与快抖不同的产品。由于淘宝用户都是有电商心智的用户，因此可以把产品营销、产品功能使用介绍等内容作为视频内容主攻口，在短视频中进行品牌宣传，实现引流变现。
解析：

题目4：9.介绍一个和卡中心业务比较相关的项目（深挖：难点、负责板块、项目论文成果等）（招商银行信用卡）
答案：以信用评分卡模型为例，参与的流程有数据获取、数据预处理、探索性数据分析、变量选择、模型开发、模型评估、信用评分和系统建立。
（1）用到的数据主要包括以下几个方面：
基本属性：包括了借款人当时的年龄。
偿债能力：包括了借款人的月收入、负债比率。
信用往来：两年内35-59天逾期次数、两年内60-89天逾期次数、两年内90天以上逾期次数。
财产状况：包括了开放式信贷和贷款数量、不动产贷款或额度数量。
贷款属性：商业贷款、公积金贷款。
其他因素：包括了借款人的家属数量（不包括本人在内）。
时间窗口：自变量的观察窗口为过去两年，因变量表现窗口为未来两年。
（2）变量选择阶段，通过WOE分析方法来确定指标是否符合经济意义，通过相关性分析和IV筛选确定所需变量。
（3）模型建立阶段使用python中的statsmodels包实现逻辑回归，在各变量通过显著性检验后验证了模型的预测能力，使用在建模开始阶段预留的test数据进行检验。通过ROC曲线和AUC来评估模型的拟合能力，结果显示AUC值为0.85，说明模型的预测效果还是不错的。
（4）在信用评分阶段将Logistic模型转换为标准评分卡的形式，选取基础分值、 PDO（比率翻倍的分值）和好坏比基本参数，个人总评分为基础分加各部分得分。整合模型及代码，建立自动评分系统，并用滚动数据进行模型迭代。
解析：

题目5：10.对拼多多业务的理解（拼多多）
答案：拼多多作为平台为商户提供商品的展示、向消费者提供个性化推荐服务，并从中收取商品销售佣金。而“拼购”模式是指：一个顾客发现某商品，发现一起买更便宜，与是找到自己的亲朋好友进行拼单，达到一单购买的人数后拼单成功，拼单的每个用户都可以拼单价购买（通常价格能比原价便宜10%~20%），而如果24小时内没有足够的人数，则拼单失败。由于拼购价格更低，很多时候甚至出现了1元包邮，2元包邮的情况出现；再加上早期微信流量扶持，因此拼多多起步阶段确实达到拼购链接漫天飞的效果。
解析：


======= 业务指标-3 =======

题目1：11.讲几个关于用数据进行业务分析的经历或例子（京东、拼多多）
答案：互联网数据与运营紧密结合，实习、工作中通常需要使用数据对业务进行分析。接下来以通过数据驱动制定APP活动页资源投放分发策略为例，对数据分析及业务相关的流程进行剖析。APP活动页资源投放分发策略的制定较为复杂，需要对页面各营销位的浏览量和点击率进行分析。在进行全面的评估后，考虑进行千人千面的营销，以提升其点击率。首先需要对客群进行细分，根据用户历史访问场景及app特征进行分群。然后基于用户的访问场景数据进行关联性分析，计算出各场景间的关联度，在活动页针对有某个场景访问历史的用户投放与其关联度高的场景优惠券，提升用户最终的点击率。
解析：

题目2：12.更倾向于业务方向还是技术方向（百度、拼多多、滴滴、快手）
答案：数据分析个人理解比较重要的能力是问题拆解能力、业务理解能力、数据敏感性与洞察力，这些能力都是技术知识不能弥补的，同时一些必要的数据库、数据仓库的知识还是需要懂的，而有很多人比较热衷于算法模型、机器学习模型等一些比较炫酷的技术，这些对于数据分析来说只能添砖加瓦但根基还是需要业务知识来支撑
解析：

题目3：13.如何做一个能出圈的业务。如果做出这样一个业务，怎么验证出圈与否。（快手）
答案：每个公司都会有自己的主营业务，在业务快速发展多年以后也会进入红海，陷入存量竞争的时代，此刻就应该考虑扩展业务，做一个能出圈的业务。在设想出圈的业务时应首先思考与主营业务相关的业务有哪些，并从中进行筛选受众面广的业务，并且考虑其中能够与主营业务形成互补的业务，然后选择进行尝试。
那么如何验证出圈与否呢，不仅可以从获客渠道出发，通过新业务的获客渠道是否突破原有业务的边界。而且可以从客群维度予以区分，出圈的业务面向客群应与主营业务不同，与主营业务能形成互补，拥有大量潜在的客群可扩展。
解析：

题目4：14.说一个之前实习经历中，给业务建议的case。（拼多多）
答案：实习经历中，有一个关于薅羊毛用户的问题：发现来的用户虽然裂变率很高，但是后续的转化很低，分析原因发现参与活动的用户活跃在下沉城市且邀请人为薅羊毛用户且带来的用户质量远远低于正常用户带来的用户质量，而且邀请人数越多带来的用户质量越差。后来向运营方反馈这个问题之后，建议将原来的策略改变，即：原来是实物奖励现在改成现金奖励，原来可能是邀请5人一个实物奖励，现在邀请人数和对应的现金数相同，只有当邀请人数达到一定数量的时候再赠送实物，大大减少了薅羊毛的用户
解析：

题目5：15.估算下10年后的高考人数（拼多多）
答案：思路1: 时间序列方法，可以根据历史数据，运用ARMA/ARIMA方法及其衍生时序方法进行10年后高考人数预测。
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210419/897353_1618830630059/4DCD9FF75C8D6A30EFB3ED141EF125D1]
思路2: 高考的平均年龄为18岁，故10年后参加高考的学生现在是8岁，正在上小学三年级，因此可以先获取目前全国处于8岁或三年级的学生数量；由于升学率相对较为稳定，因此可以考虑每年高考人数与小学三年级学生的比例，将这个比例作为从小学三年级到高三的整体升学率，从而计算出10年后的高考人数。
解析：


======= ABtest-1 =======

题目1：1.在abtest的应用 p值的意义，第一类和第二类错误的定义是什么？（快手、字节跳动、猿辅导）
答案：AB实验实际上是建立在假设检验的基础上的，P值就是在原假设成立的前提下，出现原假设以及更极端现象的概率，定义了第一类错误的具体程度，第一类错误α叫弃真错误或显著性水平，即原假设为真时却被我们拒绝的概率；
第二类错误β叫采伪错误，即原假设为伪我们没有拒绝的概率。在一定样本量的情况下，减小一类错误必然会增大另一类错误，在实践中我们一般会优先控制第一类错误，因为原假设是非常明确的
解析：1-第一类错误也即原假设为真的情况我们接受的概率，对于AB实验，犯这个错误代表新策略没有收益，我们却认为有收益，然后上线的错误，一般第一类错误不超过5%，第一类错误是明显的，也就是说在原假设为真的情况下接受原假设的概率要超过95%；
统计功效=1-第二类错误，也即当AB两组实际有差异时,能被我们检测出来差异的概率

题目2：2.abtest的流程（快手、拼多多、阿里巴巴、作业帮）
答案：实验的流程：确定目标和假设->确定指标->确定实验单位->计算样本量->实施测试->分析实验结果
解析：● 其中确定指标中比较关键的是要确定评价指标和护栏指标，评价指标就是驱动公司实现核心价值的指标，要具有可归因性、可测量性、敏感性和稳定性；护栏指标也就是辅助指标
● 确定实验单位有从用户层面、访问层面和页面层面进行考虑的情况，用户层面适用于易被用户察觉的变化实验，访问和页面层面适用于不易被用户察觉的变化实验；从用户层面到页面层面实验粒度越来越细，累计的样本量也越来越多
● 计算样本量，需要预先确认以下数值：显著性水平、功效、实验组和对照组的综合方差以及期望的最小差值。实验组和对照组数据量最好均分，非均分的时候只有相对较小的组达到最小样本量，实验结果才可能显著，并不是说实验组越大越好，因为瓶颈是在样本量较小的对照组上，所以实验组和对照组的样本量最好相同
● 分析测试结果的时候要注意辛普森悖论等问题，而且要保证样本达到足够的量、检验是否在正常的波动范围内

题目3：3.自变量是不良体验反馈，因变量是留存率，方法论是ABtest，二者相关性该注意什么?（滴滴）
答案：需要注意可能存在幸存者偏差现象。有些用户在有不良体验后会进行反馈，这种反馈在一定程度上可能解释了用户留存率下降的原因，但同时应该注意到，能进行反馈的用户通常是对平台有感情的用户，希望能通过反馈改善平台环境，继而留下来；很多真正失望的用户可能一言不发便直接流失，所以可能出现不良反馈的数量减少但留存率却下降的情况。
解析：

题目4：4.AB Test有什么缺点？（滴滴）
答案：（1）制作AB版本的开发、数据收集的工作量较大、以及后期维护成本增加，ROI低；
（2）AB测试受场景限制，产品版本发布后，无法增加或更改AB测试场景；
（3）通常应用于短期即刻行为，不适用与需要很长时间才能验证的测试；
（4）需要的用户人数多，要有足够的样本量。
解析：

题目5：5.AB测试在什么平台上进行？介绍一下主要步骤？（字节跳动）
答案：（1）定义策略：确定分流的目的、放量规模、递增的频率、回滚的策略等；
（2）筛选用户：确定分流访问的用户特征，定义规则（根据IP，user_id，cookie，业务需求（商户）等因素，指定分流策略）或导入名单；
（3）访问分流：技术支撑，根据分流策略向用户展示不同内容；
（4）发布运行：根据不同的实现方案进行部署；
（5）采集分析：收集数据，比较不同的方案效果，确定最终方案。
解析：


======= ABtest-2 =======

题目1：6.分析一个case，case背景是陌陌换了匹配算法，要做abtest（字节跳动）
答案：关键指标：匹配后互动成功率
相关指标：DAU、用户在线时长，次均聊天时长、用户付费率、各类功能的使用情况
负向指标：用户流失率
解析：

题目2：7.算法部门上线了新的推荐算法，在ab-test中败给了老算法，让你找出其中的原因，需要说出具体思路和框架（拼多多）
答案：电商平台的商品推荐中，商品历经曝光、点击、加购物车、下单这一系列漏斗。应该分别比较两个算法推荐商品在各环节的转化率，并针对不同环节寻找原因。如果较老算法而言，新算法推的商品从曝光至点击的转化率很低，则应该从推荐推送客群的画像思考，说明推荐算法推送的商品并不适合推送的客群，以此为依据重新调整算法逻辑。
解析：

题目3：8.简要介绍AB测，并给出样本量计算公式。（拼多多、携程）
答案：AB实验经常运用在活动策略是否有效的问题上，进行实验的步骤是：实验的流程：确定目标和假设->确定指标->确定实验单位->计算样本量->实施测试->分析实验结果
      其中样本量的计算是比较重要的内容，A/B 测试所需的时间 = 总样本量 / 每天可以得到的样本量。从公式就能看出来，样本量越小，意味着实验所进行的时间越短。在实际业务场景中，时间往往是最宝贵的资源，毕竟，快速迭代贵在一个“快”字。另外，我们做 A/B 测试的目的，就是为了验证某种改变是否可以提升产品、业务，当然也可能出现某种改变会对产品、业务造成损害的情况，所以这就有一定的试错成本。那么，实验范围越小，样本量越小，试错成本就会越低。实践和理论上对样本量的需求，其实是一对矛盾。所以，我们就要在统计理论和实际业务场景这两者中间做一个平衡：在 A/B 测试中，既要保证样本量足够大，又要把实验控制在尽可能短的时间内。样本量的计算公式如下：
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210423/897353_1619170420988/10FB15C77258A991B0028080A64FB42D]
解析：

题目4：9.拼多多最近在测试两个不同的推荐算法，其中A比B好，从哪几个方面可以分析好的原因。（拼多多）
答案：关键指标提升：A组用户下单转化率明显高于B组
相关指标正向：A组用户人均订单量增加、GMV提升、用户活跃时间更长、物品的收藏率和分享率更高、用户拉新拉活数量更多
负向指标减少：A组用户退款率下降、用户差评率降低
解析：

题目5：10.ABtest, 为了提高点击率，对界面进行了小幅度修改，有两个组 一组1000个人，有100个人点击，另一组1000个人，120人点击，怎么判断好不好（拼多多）
答案：在比例类别指标的假设检验中，可以使用卡方检验方法。首先进行假设，设H0为两组实验的点击率无明显差异，H1为第二组点击率要高于第一组。在该实验中，A组1000人中有100人点击，则点击率为10%，置信区间为[8.3%, 12%]；B组1000人中有120人点击，则点击率为12%，置信区间为[10.1%, 14.2%]，在95%的置信度下，进行计算得到p-value=0.15>0.05，不能拒绝原假设H0，因此认为两组点击率无明显差异。
解析：卡方检验：卡方检验是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为0，表明理论值完全符合。
[公式:图片说明|https://uploadfiles.nowcoder.com/images/20210423/897353_1619170993063/C924C84B92E36B0FC94AAD6FCF3EC1ED]

题目6：11.有没有接触过ABtest/经验，请说说对他的理解（滴滴、快手、字节跳动）
答案：AB实验经常运用在活动策略是否有效的问题上，它的理论基础是假设检验，也就是选择一种合适的检验方法，去验证在 A/B 测试中我们提出的假设是否正确。现在，你只要知道“假设检验”中，最重要也最核心的是“检验”就可以了，因为选取哪种检验方法，取决于指标的统计属性。A/B 测试是促进业务持续增长的最实用、最有效的方式。
解析：


======= 业务指标-4 =======

题目1：16.你做的分析报告有问题，业务方不满意怎么办（蓝月亮）
答案：首先看问题出在什么地方，是双方由于沟通导致数据口径、结果呈现方式、分析方向有问题，还是由于自身在树立框架的时候方向出错，导致没有得到业务方想得到的数据结果和结论的问题。如果是前者的问题，就需要再和业务方进行详细沟通，将每一个维度、每一个指标的口径和呈现方式都聊清楚；如果是后者的问题，那么可能需要请教一些比较资深的同事来帮你重新梳理一下需求，重新找到正确的方向
解析：

题目2：17.如何衡量一个活动的ROI（字节跳动）
答案：● 解决了什么问题：活动的目标&背景是什么，可以对应到哪些核心指标，可以具体细拆到哪些指标
● 这个活动有哪些难点，它的受众有哪些特性，流程具体是怎样设计的
● 活动是否可以长期进行
● 最终测算的指标需要结合活动的类型以及活动最终的目的来决定：
● 活动属于拉新下载类型的，需要考虑的是活动带来的新用户数、下载量以及活动的收益成本比，ROI的计算公式是：收益/成本
● 活动属于品牌宣传类的，可以看活动页面的浏览量、文章的阅读量、评论数、点赞数和分享数等
● 活动属于促销类的，那么gmv就是重要的指标
● 活动属于提升用户粘性的，可能留存率、平均使用时长等都是结果指标
解析：

题目3：18.你在分析的时候有没有和业务的人沟通？去发现一些问题风险？（京东）
答案：与业务进行沟通是数据分析师的必备技能，许多业务现状需要与业务人员确认。同时，在大环境不断变化的情况下，对于不同的业务场景，数据分析师需要不断与业务人员讨论迭代策略方案。真理越辩越明，道理越讲越清，在与业务人员沟通过程中许多现存的风险点就会不自然地暴露出来。这时结合数据和业务的力量就能保证项目持续稳定的向前推进。
解析：

题目4：19.面试官表示自己是买菜部门的，大致介绍了一遍买菜的流程，然后问如何给这个业务建立一些指标。（拼多多）
答案：在“用户”层面，需要监控的指标包括“总用户数”、“活跃用户数”、“用户留存率”、“用户付费转化率”等。这些指标能较为明显地反映平台中的用户的参与情况。当这些指标处于一个高位时，说明平台业务做的比较好。
在“产品”层面，需要监控的指标包括“品类覆盖率”、“销量类指标”、“库存类指标”等，重点研究当前的产品（货物）是否有足够的覆盖面和销量，同时不会积压过多额库存（生鲜类产品保存期较短）。
在“平台”层面，需要监控的指标包括“GMV”、“ROI”、“市场占有率”等，主要是看当前平台的规模如何，投资回报率是否在可以接受的范围（是在烧钱阶段还是已经获得盈利），平台被用户所接触并使用的范围有多大。
解析：

题目5：20.平时用不用pdd，有什么理解（拼多多）
答案：平时用的不多，只有在百亿补贴购买iPhone或Airpods时用pdd。pdd在短短几年就与京东、淘宝形成了三足鼎立的局面。pdd贯彻了农村包围城市的想法，以水果为基地，利用裂变营销活动获取广大三四线城市的用户。在获取大量的长尾用户以后，pdd逐渐向高端客群发力，开展一系列的百亿补贴活动来获取一二线的用户，形成完整的客群结构。总体上来看，pdd的营销能力很强，能够设计出极具创新性的获客活动模型，同时推出的活动能够较大程度地促用户留存。长期看来，pdd具备很强的发展潜力。
解析：


======= 业务指标-5 =======

题目1：21.常用的APP，楼主说了B站豆瓣酷安三个社区类APP，面试官要求分析一下B站优缺点（拼多多）
答案：B站，全名“哔哩哔哩（Bilibili）”，昵称“小破站”，于2009年6月26日诞生。创站初期的定位为ACG弹幕视频网站，目标用户是二次元爱好者；平台初期的核心功能在于分享第三方平台视频的同时，在视频上进行“弹幕”形式的评论与交流。
B站优缺点：
● 社区氛围
B站的独特社区氛围为B站建立了⼀条独具特特色的文化“护城河”，使得B站在巨头厮杀的环境中依旧可以做到“圈地自萌”，在ACG和UGC/PUGC领域占据高地。但这文化“壁垒”既是保护B站存活的城墙，也是限制B站发展的禁锢。即使B站正在努力从最早的二次元/泛二次元社区转变为年轻社区，和“爱优腾”针对全国网民的市场定位相比，理论目标用户规模依然不是⼀个量级。而西瓜视频的果断杀入UGC领域，也在威胁着B站的未来发展空间，并且这个“未来”并不远。
● 商业模式
B站的商业化方式相对多元，各业务间的关联性较弱，独立性强，抵抗风险能力强。每一个独立的业务都有发展的潜力和空间。但深入来看，B站的收入结构仍是有很大风险的，具体在于占据B站营收半壁江山的游戏业务发展并不明朗。虽然2019Q3财报显示游戏业务营收占比已经下降到50%，似乎是B站营收平衡达到了⼀个很好的效果。然而不可忽略的是，带来这⼀份平衡的原因可能并不是非游戏业务的飞速发展，而更是因为游戏业务的增长停滞。代理FGO带来的营收，向来是B站游戏业务的大头。而任何一款游戏都是有生命周期的，过分依赖⼀款游戏带来的游戏业务营收是极具风险的（并且B站还没有FGO的版权，每年都要和Aniplex重新签约）。具体可以从B站财报数据看到，2018Q4、2019Q1、2019Q2、2019Q3游戏业务的收⼊分别是7.1亿元、8.7亿元、9.1亿元、9.3亿元，环比增长分别为22.5%，4.6%和2.2%，明显体现出增长放缓。并且与此同时，B站并没有摸索出另⼀个可以带来巨大收益的游戏，来优化游戏业务的收入结构。
解析：

题目2：22.怎么样的数据挖取能真正对业务起到指导作用？（快手）
答案：数据分析通常分为四个阶段：最初等的就是客观呈现出事物的现状，更进一步是能够被动支持也无妨的决策，更高一层次是能够主动定义问题并指导业务方，最终阶段是将数据融入思维和工作的各个方面。想要数据分析能够对业务起到指导作用，首先应该充分了解当前的业务。而每个公司、每项业务都离不开四个步骤，获客、激活、留存、变现，因此对业务的指导也是围绕这几个方面展开的，数据分析应该落地于帮助业务优化成本、扩大规模，让潜在的用户真正使用我们的产品，提高用户粘性、尽力留住用户，并提高每个用户所带来的收益。这个过程需要分析师不断提供想法，不断进行假设，不断检验甄别，不断指引方向，不断创造价值。
解析：

题目3：23.快手和抖音目前都是滑滑的形态，你觉得在业务层面有什么不同？（快手）
答案：两者产品理念不同，快手记录世界和你，追求真实; 抖音则是记录美好生活，经过了过滤和修饰。
宿华曾谈到他认为快手最重要的是记录，通过普通人的视角，去记录生活中的方方面面。       其次就是普惠。普惠就是让所有人都有同样能力留下自己的记录。不会因为他高矮胖瘦、穷富美丑来做判断，希望能给用户平等的对待。这种理念的直接体现就是，快手不与头部KOL签约，不设置热点话题等榜单。
抖音的“记录美好生活”，从字面上理解，就是要让用户浏览和分享美好的、高质量的内容。这就意味着，平台已经定了调性，打造了⼀套好玩炫酷的模板，告诉你什么是美好的、好玩的，然后你就按照这个模板来，开始你的表演。同时，抖音签约了一大批明星、网红、MCN机构来保证优质内容的产出，不断分食草根或者背靠小MCN机构网红的流量。
这就是抖音与快手在产品理念上的最大区别——中心化or去中心化。所以抖音上会出爆品，但是快手上更适合长尾流量。
解析：

题目4：24.滴滴业务关注的几个点是：司机、乘客、以及司乘之间供需关系的平衡，供需关系的调节可以通过调价、发放优惠券等手段（滴滴）
答案：制定评分策略：考虑出勤率、运行时长等供给相关内容，对司机进行评分，评分高者给予一定的激励，如派单概率更高、会有平台补贴、奖励等；
调整定价策略：运力紧缺->价格增加->部分乘客使用其它交通工具/部分沉默司机被召回->供需平衡；
进行调度优化：为司机提供区域订单热力图进行参考，让司机自行决定去什么位置接单；推荐商家去指定位置进行服务，给予奖励措施；让司机表达意愿，比如愿意以更低的价格选择顺路的订单。
解析：

题目5：25.跟领导汇报抖音的业务，你会选择哪5个指标，为什么（字节跳动）
答案：从用户增长角度出发，套用AARRR模型，包括获取，激活，留存，转化，传播五个阶段。
获取-日新增用数
激活-日视频观看人数
留存-次,3,7日留存率
转化-总收入
传播-分享转化数
解析：


======= 业务指标-6 =======

题目1：26.你用过飞书吗?或者共享文档也行,你觉着怎么去通过拆分得到业务流程中的一个ah moment呢（字节跳动）
答案：没用过飞书，但是用过腾讯文档。对于共享文档来说，最大的功能点在于多人能同时对文档进行编辑，并且能够实时保存及同步，ah moment在用户首次远程阅读编辑共享文档。对于一个普通的业务，需要寻找其ah moment的时候，需要重点关注留存用户与流失用户的行为差异，找出与留存用户正相关的所有行为。然后进行A/B测试，对低频活跃的用户进行测试，促使其完成留存户具备的正向行为。若低活用户在完成该行为后留存率有所提升，说明找到了该产品的ah moment。
解析：

题目2：27.实习最有价值的部分详细讲了讲背景、过程以及结果（给业务带来的实际增长效果）（滴滴）
答案：参考模板
实习中最有价值的部分就是能够充分理解业务方的需求并能根据需求找到相应的痛点，在业务方需要解答的问题上给予充分的支持，并能够根据分析得到的结论给出相应的比较有价值的意见。这些意见和业务方讨论之后，且经过实验之后被证明是有效的，最终能够全量上线。
解析：

题目3：28.公司中小微方向做的主要业务内容（同盾科技）
答案：同盾科技专注于智能分析与决策，是一家第三方智能风险管理服务商，其中小微方向的主要职能是研究中小微企业。通过整合更全面、具有公信力的工商、税收、人社、司法等政府部门数据，对中小微企业进行反欺诈检测、信用评分等。银行、信贷公司等金融机构将同盾的数据与自有数据相结合完成对中小微企业的信用评分、评级，最终确定其贷款额度和贷款利率。
解析：

题目4：29.线下零售店全国销售额相比Q2季度下降30%，请你分析下原因（美团）
答案：首先确定一下数据是否有问题，如果没有问题的话，可能需要考虑以下几点：
分内外环境分析：
外部环境（PEST）：
政策：如国家出台有关政策。
经济：如市场经济环境影响，竞品的影响。
社会：如社会上产生不利于舆论。
科技：如新技术出现并没有促进消费，反而产生不利影响。
内部环境：
时间段：确定哪个时间段销售额下降比较厉害。
渠道：确定那个渠道顾客销售额下降比较多。
新老用户：确定销售额下降主要用户群体。
地区：确定销售额下降比较多的地区。
商品：确定是哪些商品的销售额下降了。
解析：

题目5：30.对国际化业务是否有了解（滴滴）
答案：在国际化战场上，滴滴的主要竞争对手是 Uber。但滴滴拥有足够的本金保证在各地的收购、投资，同时实现本土化运营，相较Uber而言显得非常有优势。就目前而言，滴滴国际化业务已经取得不菲的成绩，在巴西、墨西哥、澳洲、日本、智利、哥伦比亚、哥斯达黎加、巴拿马等 8 个国家落地，其中拉美洲贡献了超过 50% 的单量。未来，滴滴一方面将继续吸收更多的资金开疆扩土，另一方面则针对不同国情寻找到更合适的本地化运营模式，实现业务的持续增长。
解析：


======= 业务指标-7 =======

题目1：31.结合你实习中的业务场景，介绍一下获取和处理数据的途径和流程？（神策数据）
答案：参考模板
因为实习中是处于增长团队的，所以活动是日常生活中不可缺少的。活动数据的衡量一般用活动漏斗来衡量，活动漏斗会在活动页中埋点来获取到，埋点需要规范埋点的url和参数，需要研发配合将埋点加到页面中。活动结束之后，数据仓库同学会帮忙将埋点数据接入数据库中，利用sql或者python对数据进行处理，建立活动漏斗数据，进而分析活动数据在各个环节上的表现，为下一次迭代或者复盘提供支持
解析：

题目2：32.关于视频app（比如爱奇艺）首页推荐的推荐顺序，你会考虑哪些指标？（小米）
答案：（1）用户行为数据：浏览、点击、播放、搜索、收藏、点赞、转发、滑动、在某个位置的停留时长、快进等等一切操作行为；
（2）用户属性数据：年龄、性别、地域、学历、家庭组成、职业等；
（3）视频属性数据：评分、播放量、评论数、出品方、导演、主演、国别、年代、语言、是否获奖、剧情等；
（4）上下文数据：用户最近观看历史记录、最近偏好的演员明星、最近常看的视频类型等。
解析：

题目3：33.有20000人的就餐需求，现建了一个新食堂，如何规划食堂的座位数？（小米）
答案：假设食堂就餐时间为2h，则每小时需要为10000人提供就餐服务；假设每人就餐时间为15min，且人员到达食堂的时间点分布均匀，则1h可以服务4批就餐人员，平均每批2500人，意味着将会有这么多人同时就餐，就可以按照上述数据进行座位规划。
解析：

题目4：34.boss直聘的投递量较低，你会如何提高？从前期调研、方案策划到推广复盘等过程说明一下（小米）
答案：1） 前期调研
进行竟品分析，通过调研了解当前各招聘App的现状。从获客、活跃、投递及转化率多维度进行评估比较，了解boss直聘在各维度的能力水平。
2） 方案策划
根据待加强的环节制定相应的方案。如果是当前boss直聘的规模小导致投递量较低，那应该多从获客端思考，增加丰富获客渠道或提升各渠道的获客能力。如果其规模已经非常大，但是活跃用户非常少，那应该积极采取营销活动以促活，提升最终的投递量。若规模和留存率已经足够高，问题大概率存在产品上，应充分充分思考漏斗中的每一个环节产生漏损的原因，从用户旅程出发，优化用户体验，提升每一个环节的转化率，最终达到提升投递量的目的。
3） 推广复盘
根据策划的方案，进行小规模的测试，在复盘后发现该策略能够有效提升投递量，则可以进行推广。
解析：


======= 费米估算-1 =======

题目1：1.费米问题：北京11点左右上空飞行的飞机数量？（拼室友）
答案：北京机场年旅客吞吐量一亿人次，每天旅客量1亿/365=27万；
考虑到机场有大中小型飞机,假设平均每架飞机载客150人，于是北京每天起降飞机架次：27万/150~1800架；
大部分的航班集中在早6点-晚12点的18个小时内。城市上空的飞机主要是起飞或等待降落,每架飞机起飞会立刻飞离北京,降落之前需盘旋等待进场,假设每架飞机在北京上空滞留时间在半小时.
故在白天的任意时刻（11点）,北京上空飞机数量=1800*0.5/18=50架
解析：

题目2：2.费米估计：上海大约有多少家用小轿车（MobTech）
答案：[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%AE%B6%E7%94%A8%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F%3D%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F%5Ctimes%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E7%9A%84%E5%AE%B6%E5%BA%AD%E6%95%B0%E9%87%8F%3D%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F%5Ctimes%E4%B8%8A%E6%B5%B7%E5%AE%B6%E5%BA%AD%E6%95%B0%E9%87%8F%5Ctimes%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E7%9A%84%E6%AF%94%E4%BE%8B%3D%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F%5Ctimes%E4%B8%8A%E6%B5%B7%E4%BA%BA%E5%8F%A3%E6%95%B0%E9%87%8F%2F%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E4%BA%BA%E5%8F%A3%E6%95%B0%E9%87%8F%5Ctimes%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E7%9A%84%E6%AF%94%E4%BE%8B]
假设家庭拥有家用小轿车：电动车：自行车：啥都没有=6：2：1：1
即：有私家车的家庭占比=60%
假设平均每家有小轿车的数量为1。上海人口：2500w，平均每家人口数量4人。
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%AE%B6%E7%94%A8%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F%3D1%5Ctimes2500w%2F4%20%5Ctimes0.6%3D375w]
解析：

题目3：3.估算北京五环实时车流量（滴滴）
答案：北京每日车流量约50w人次，主要车流动的时间段为7点-20点，假设北京六环的车流量比例为：4：4：3：3：2：2；即五环车流量占比约11%。
故在白天的任意时刻，北京五环的实时车流量=50w*11%/14=4000辆。
解析：

题目4：4.每天全国的电单订单量大概是多少?（滴滴）
答案：[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%85%A8%E5%9B%BD%E8%AE%A2%E5%8D%95%E9%87%8F%3D%E7%94%A8%E6%88%B7%E5%9F%BA%E6%95%B0%5Ctimes%E6%B8%97%E9%80%8F%E7%8E%87%5Ctimes%E8%B4%AD%E4%B9%B0%E9%A2%91%E6%AC%A1%5Ctimes%E5%8D%95%E6%AC%A1%E8%B4%AD%E4%B9%B0%E4%BB%B6%E6%95%B0]
由于不同城市的渗透率和购买频次不同，所以将用户分为一线城市，二线城市，三线城市，四线及以下城市。
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E4%B8%80%E7%BA%BF%E5%9F%8E%E5%B8%82%E8%AE%A2%E5%8D%95%E9%87%8F%3D%E4%B8%80%E7%BA%BF%E5%9F%8E%E5%B8%82%E4%BA%BA%E6%95%B0%5Ctimes%E6%B8%97%E9%80%8F%E7%8E%87%5Ctimes%E8%B4%AD%E4%B9%B0%E9%A2%91%E6%AC%A1%5Ctimes%E5%8D%95%E6%AC%A1%E8%B4%AD%E4%B9%B0%E4%BB%B6%E6%95%B0%3D7000%E4%B8%87%5Ctimes0.8%5Ctimes1%2F7%5Ctimes1%3D800w] ，
同理可以得到其他城市的订单量，汇总就得到了全国的每日订单量。
解析：

题目5：5.如何估计某一时刻某地上空的飞机数量，或者说如何获取相关信息（滴滴）
答案：某一时刻某地上空的飞机数量=某地机场年旅客吞吐量/365/平均每架飞机载客人数/航班集中时间*每架飞机在某地空滞留时间
平均每架飞机载客人数约为159人；航班集中在早6点-晚12点的18个小时内；每架飞机在上空滞留时间在半小时。
解析：

题目6：6.估计北五环有多少辆车（滴滴）
答案：[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%8C%97%E4%BA%94%E7%8E%AF%E8%BD%A6%E6%95%B0%E9%87%8F%3D%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F*%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E7%9A%84%E5%AE%B6%E5%BA%AD%E6%95%B0%E9%87%8F*%E5%8C%97%E4%BA%94%E7%8E%AF%E8%BD%A6%E8%BE%86%E5%8D%A0%E6%AF%94%20%3D%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F*%E5%8C%97%E4%BA%AC%E5%AE%B6%E5%BA%AD%E6%95%B0%E9%87%8F*%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E7%9A%84%E6%AF%94%E4%BE%8B*%E5%8C%97%E4%BA%94%E7%8E%AF%E8%BD%A6%E8%BE%86%E5%8D%A0%E6%AF%94%3D%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E6%95%B0%E9%87%8F*%E5%8C%97%E4%BA%AC%E4%BA%BA%E5%8F%A3%E6%95%B0%E9%87%8F%2F%E5%B9%B3%E5%9D%87%E6%AF%8F%E5%AE%B6%E4%BA%BA%E5%8F%A3%E6%95%B0%E9%87%8F*%E6%9C%89%E5%B0%8F%E8%BD%BF%E8%BD%A6%E7%9A%84%E6%AF%94%E4%BE%8B*%E5%8C%97%E4%BA%94%E7%8E%AF%E8%BD%A6%E8%BE%86%E5%8D%A0%E6%AF%94] 假设家庭拥有私家车：电动车：自行车：啥都没有=6：2：1：1即：有自行车的家庭占比=60%；
假设北京六环的车量比例为：4：4：3：3：2：2；即五环车量占比约11%。
假设平均每家有小轿车的数量为1。北京人口：2500w，平均每家人口数量4人。
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%8C%97%E4%BA%94%E7%8E%AF%E8%BD%A6%E6%95%B0%E9%87%8F%3D1*2500w%2F4%20*60%25*11%25%3D41w]
解析：

题目7：7.若贝壳要进入一个新的城市要如何去估计这个城市的需求量（贝壳找房）
答案：[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%B8%82%E5%9C%BA%E8%A7%84%E6%A8%A1%3D%E7%94%A8%E6%88%B7%E5%9F%BA%E6%95%B0*%E6%B8%97%E9%80%8F%E7%8E%87*%E6%B6%88%E8%B4%B9%E9%A2%91%E6%AC%A1*%E5%8D%95%E4%BB%B7] 。其中用户基数和单价很容易得到，渗透率和消费频次可以根据日常经验或者问卷调查等方法得到，如果要更细致的划分，可以把用户按照年龄、职业等分层统计后汇总。
解析：


======= 费米估算-2 =======

题目1：8.怎么估算上海外卖员的数量（拼多多）
答案：外卖员的数量 = 每天订单总数/每人每天可配送的订单数
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E6%AF%8F%E5%A4%A9%E7%9A%84%E6%80%BB%E8%AE%A2%E5%8D%95%E6%95%B0%20%3D%20%E7%9B%AE%E6%A0%87%E7%94%A8%E6%88%B7%E6%95%B0%2F%E7%82%B9%E5%8D%95%E9%A2%91%E5%BA%A6%20%3D%20%E4%B8%8A%E6%B5%B7%E5%B8%82%E6%80%BB%E4%BA%BA%E6%95%B0%5Ctimes%E7%82%B9%E5%A4%96%E5%8D%96%E4%BA%BA%E6%95%B0%E5%8D%A0%E6%AF%94%2F5%20%3D%202500%E4%B8%87%5Ctimes0.4%2F5%3D200%E4%B8%87]
每人每天可配送的订单数 = 每天工作时间/完成一个订单需要的时间= 每天工作时间/（骑手到商家的时间+排队等待时间+配送时间 + 用户等待时间）= 每天工作时间/（商家距离/骑手速度+排队等待时间+目的地距离/骑手速度 + 用户等待时间 ）= 10/（3/25 + 0.25 + 4/25 + 0）= 18.9 单
外卖员的数量 = 每天订单总数/每人每天可配送的订单数 = 10.5万人
解析：

题目2：9.如何预估全国大学生人数（拼多多）
答案：大学生为大一到大四的人数，一般为18-22岁，我们可以找到1999-2003年的出生人数平均为1800w，假设上学率为80%，都进行了九年义务教育，中考升学率60%，高考升学率60%，则最后[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E4%BA%BA%E6%95%B01800%5Ctimes4%5Ctimes0.8%5Ctimes0.6%5Ctimes0.6%3D2000%E4%B8%87]
解析：

题目3：10.如何预估2030年高考生的数量。（拼多多）
答案：高考生一般为18岁，2030年高考生为2012年出生，2012年我国出生人口为1600万，假设上学率为80%，都进行了九年义务教育，中考升学率60%，则最后高考人数
[公式:图片说明|https://www.nowcoder.com/equation?tex=1600%5Ctimes0.8%5Ctimes0.6%3D768%E4%B8%87]
解析：

题目4：11. 估算上海地铁每天的客运量（拼多多）
答案：[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%AE%A2%E8%BF%90%E9%87%8F%3D%E6%AF%8F%E8%8A%82%E8%BD%A6%E5%8E%A2%E5%AE%9E%E9%99%85%E5%B9%B3%E5%9D%87%E4%BA%BA%E6%95%B0%5Ctimes%E8%BD%A6%E5%8E%A2%E8%8A%82%E6%95%B0%5Ctimes%E6%AF%8F%E6%97%A5%E5%88%97%E8%BD%A6%E6%AC%A1%E6%95%B0%5Ctimes%E5%9C%B0%E9%93%81%E7%BA%BF%E8%B7%AF%E6%95%B0%E9%87%8F]
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E6%AF%8F%E8%8A%82%E8%BD%A6%E5%8E%A2%E5%AE%9E%E9%99%85%E5%B9%B3%E5%9D%87%E4%BA%BA%E6%95%B0%3D%E6%A0%B8%E5%AE%9A%E4%BA%BA%E6%95%B0%EF%BC%88250%EF%BC%89%5Ctimes%EF%BC%88%E5%86%B7%E6%B8%85%E6%97%B6%E6%AE%B5%E6%AF%94%E4%BE%8B%5Ctimes%E5%86%B7%E6%B8%85%E6%97%B6%E6%AE%B5%E4%B8%8A%E5%BA%A7%E7%8E%87%2B%E6%AD%A3%E5%B8%B8%E6%97%B6%E6%AE%B5%E6%AF%94%E4%BE%8B%5Ctimes%E6%AD%A3%E5%B8%B8%E6%97%B6%E6%AE%B5%E4%B8%8A%E5%BA%A7%E7%8E%87%2B%E9%AB%98%E5%B3%B0%E6%97%B6%E6%AE%B5%E6%AF%94%E4%BE%8B%5Ctimes%E9%AB%98%E5%88%86%E6%97%B6%E6%AE%B5%E4%B8%8A%E5%BA%A7%E7%8E%87%EF%BC%89%3D250%5Ctimes%EF%BC%880.075%5Ctimes0.15%2B0.3%5Ctimes0.95%2B0.625%5Ctimes0.6%EF%BC%89%3D250%5Ctimes0.67%3D500%2F3%3D167%E4%BA%BA%2F%E8%BD%A6%E5%8E%A2]
车厢节数约10节；
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E6%AF%8F%E6%97%A5%E5%88%97%E6%AD%A4%E6%AC%A1%E6%95%B0%3D%E5%86%B7%E6%B8%85%E6%97%B6%E6%AE%B5%E6%97%B6%E9%97%B4%2F%E5%88%97%E8%BD%A6%E9%97%B4%E9%9A%94%2B%E9%AB%98%E5%B3%B0%E6%97%B6%E6%AE%B5%E6%97%B6%E9%97%B4%2F%E5%88%97%E8%BD%A6%E9%97%B4%E9%9A%94%2B%E6%AD%A3%E5%B8%B8%E6%97%B6%E6%AE%B5%E6%97%B6%E9%97%B4%2F%E5%88%97%E8%BD%A6%E9%97%B4%E9%9A%94%3D90%2F7%2B300%2F2%2B0.625%5Ctimes20%5Ctimes60%2F5%3D15%2B150%2B150%3D315%EF%BC%9B]
地铁线路数量18条；
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E5%9C%B0%E9%93%81%E6%B5%81%E9%87%8F%3D167%5Ctimes10%5Ctimes315%5Ctimes18%3D950%E4%B8%87%E3%80%82]
解析：冷清时段：地铁一早开始运营的0.5个小时和晚上最后的1个小时，假设上座率是15%
高峰时段：从早晨6:30-9:30,下午4:30-7:30，假设上座率是95%
正常时段：剩下的时间里，假设上座率是60%

题目5：12.估算江苏省面积（快手）
答案：我国国土面积为960平方公里，东北和西南和西北省份占地面积较大，新疆、西藏、内蒙古、青海、四川、黑龙江、甘肃、云南八个省份约占我国2/3的土地，剩下28个省占1/3，江苏省960/3/28=11平方公里。
解析：

题目6：13.估算今年国庆全国的旅游消费总支出？（神策数据）
答案：将出游城市划分为一线城市、二线城市、三线城市和四线及以下城市。
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E6%97%85%E6%B8%B8%E6%B6%88%E8%B4%B9%E6%80%BB%E6%94%AF%E5%87%BA%3D%E8%AF%A5%E7%B1%BB%E5%9F%8E%E5%B8%82%E6%80%BB%E4%BA%BA%E6%95%B0%5Ctimes%E5%87%BA%E6%B8%B8%E7%8E%87%5Ctimes%E5%B9%B3%E5%9D%87%E5%87%BA%E6%B8%B8%E5%A4%A9%E6%95%B0%5Ctimes%E6%97%A5%E5%9D%87%E6%B6%88%E8%B4%B9]
[公式:图片说明|https://www.nowcoder.com/equation?tex=%E4%B8%80%E7%BA%BF%E5%9F%8E%E5%B8%82%E5%B1%85%E6%B0%91%E6%97%85%E6%B8%B8%E6%B6%88%E8%B4%B9%3D7000w%5Ctimes0.4%5Ctimes5%5Ctimes100%3D14%E4%BA%BF]
将各类城市的消费总支出汇总就得到了全国消费总支出。
解析：


======= 数据分析工具 =======

题目1：1.用过Tableau嘛，公司内部用这个软件画什么图呢（滴滴）
答案：在公司经常用tableau做一些可视化的图表，基础的图标像频数分布图、饼图、条形图，还有一些分析图像地图、标靶图、达标图这种。
解析：

题目2：2.用Tableau画过气泡图嘛（滴滴）
答案：有的，之前需要做各个地区的酒店数量的气泡图，把‘地区’拖到‘列’，‘记录数’拖到‘行’，然后点击‘智能显示’中的‘气泡图’，最后再添加标签就做好了。
解析：最好举出一个具体的例子。

题目3：3.EXCEL的熟悉程度（网易）
答案：1.会使用常用的快捷键。
2.会使用基本函数如sumif，vlookup。
3.了解所有的函数并会使用。
4.会使用excel编写宏函数。
解析：看个人基本情况，1至4熟练度逐级增加。

题目4：4.EXCEL的基本概念（中国联通）
答案：工作簿：excel创建的文件，由工作表组成；
工作表：即电子表格，由许多横向和纵向的网格组成；
单元格：工作表的最小单位，由行号和列标所确定的坐标来标示和引用；
常用函数：sumif，vlookup，rank，average，sum。
解析：

题目5：5.Power BI和Excel的对比（浦发银行）
答案：Power BI是比Excel更强大的工具：
Power BI处理大数据，而Excel无法处理大数据。
Power BI可以连接各种不同的源，而Excel只可以连接到有限的源。
Power BI仪表板更具交互性和自定义性，而Excel仪表板交互性不强。
Power BI 主要用于数据可视化和与大量用户的仪表板共享，而Excel主要用于深入的驱动程序分析。
解析：


======= 自我介绍 =======

题目1：1.英文自我介绍+一段solo（随便讲一个主题）（滴滴国际化）
答案：Hi~I'm xxx from xx university, major in xxx. Today I am for the position of data analysis. I had one/two/three internship and one/two project about data analysis. The first internship was in xxx company, I responsibled for xxx; The third is in xxx company, in order to xxxx; and the third is in xxx company, mainly for xxx. And I also have a data analysis project which is xxx, if you are intersted in this then we can discuss about it. That is all, thank you.
 
solo:  I have a variety of hobbies.My favorate sport is table tennis.I can get a lot of happiness from that game. I also like reading especially novels and poems.When i am free,i interested to watch some films.I think get some experience and different feelings through films.
解析：

题目2：2.两分钟自我介绍（京东数科、工商银行）
答案：面试官好，我叫xxx，来自xxxx大学，今天我来应聘的是数据分析岗位。我之前有x段的数据分析实习经历和x段数据分析的项目经历，最近是在xxx公司的xxx部门担任数据分析实习生，主要负责xxx项目的分析工作，此前在xxx公司的xxx部门担任数据分析实习生，主要负责xxx方面的分析工作，除此之外还在xxx公司担任过数据分析实习，负责的是xxx模块的分析工作。除此之外，我还有xx项目和xx项目，xx项目的目的是xxx，我在其中主要负责xxx；xx项目主要是做xxx，我在其中主要负责的是xxx。以上就是我的自我介绍，谢谢。
解析：两分钟自我介绍需要介绍实习经历和每段实习所负责的大概内容，还有项目经历上的项目描述和自己负责的模块。

题目3：3.三分钟自我介绍（腾讯）
答案：面试官好，我叫xxx，来自xxxx大学，今天我来应聘的是数据分析岗位。我之前有x段的数据分析实习经历和x段数据分析的项目经历，最近是在xxx公司的xxx部门担任数据分析实习生，主要负责xxx项目的分析工作，此前在xxx公司的xxx部门担任数据分析实习生，主要负责xxx方面的分析工作，除此之外还在xxx公司担任过数据分析实习，负责的是xxx模块的分析工作。在这x段实习中，我从一个数据分析小白，学习到了xx方面的业务知识，在xx专题分析中，我学习到了xxx分析思维，我认为这些实习经历对我的数据思维和业务思维的提升非常大。
除此之外，我还有xx项目和xx项目，xx项目的目的是xxx，我在其中主要负责xxx；xx项目主要是做xxx，我在其中主要负责的是xxx。在这x段项目经历中，我把在课本上学习到的一些机器学习的知识运用到实际中，提高了我的动手能力，丰富了我的实践储备，这对我在数据分析和数据挖掘上的学习和应用都非常有帮助。以上就是我的自我介绍，谢谢。
解析：三分钟自我介绍需要介绍实习经历和每段实习所负责的大概内容，还有项目经历上的项目描述和自己负责的模块，还有自己在实习、项目种所学到的东西。

题目4：4.一分钟自我介绍（vivo、南京银行）
答案：面试官好，我叫xxx，来自xxxx大学，今天我来应聘的是数据分析岗位。我之前有x段的数据分析实习经历，最近是在xxx公司的xxx部门担任数据分析实习生，主要负责xxx项目的分析工作，此前在xxx公司的xxx部门担任数据分析实习生，主要负责xxx方面的分析工作，除此之外还在xxx公司担任过数据分析实习，负责的是xxx模块的分析工作。以上就是我的自我介绍，谢谢。
解析：一分钟自我介绍只需要介绍实习经历和每段实习所负责的大概内容即可。

题目5：5.五分钟自我介绍（滴滴）
答案：面试官好，我叫xxx，来自xxxx大学，今天我来应聘的是数据分析岗位。我之前有x段的数据分析实习经历和x段数据分析的项目经历，最近是在xxx公司的xxx部门担任数据分析实习生，主要负责xxx项目的分析工作，此前在xxx公司的xxx部门担任数据分析实习生，主要负责xxx方面的分析工作，除此之外还在xxx公司担任过数据分析实习，负责的是xxx模块的分析工作。在这x段实习中，我从一个数据分析小白，学习到了xx方面的业务知识，在xx专题分析中，我学习到了xxx分析思维，我认为这些实习经历对我的数据思维和业务思维的提升非常大。
除此之外，我还有xx项目和xx项目，xx项目的目的是xxx，我在其中主要负责xxx；xx项目主要是做xxx，我在其中主要负责的是xxx。在这x段项目经历中，我把在课本上学习到的一些机器学习的知识运用到实际中，提高了我的动手能力，丰富了我的实践储备，这对我在数据分析和数据挖掘上的学习和应用都非常有帮助。
我的性格比较自信开朗，能够并且愿意主动和他人沟通，之前实习和项目中都和大家有良好的合作关系，并且我在工作中也有很高的责任感，并且没有拖延症，分配的任务能够及时完成，不会拖沓，如果有三个词语来描述我的话，我想应该是自信、乐观、责任。
以上就是我的自我介绍，谢谢。
解析：一分钟自我介绍需要介绍实习经历和每段实习所负责的大概内容，还有项目经历上的项目描述和自己负责的模块，还有自己在实习、项目种所学到的东西。再说一下自己性格品质方面的，加深面试官的印象

题目6：6.自我介绍
答案：面试官好，我叫xxx，来自xxxx大学，今天我来应聘的是数据分析岗位。我之前有x段的数据分析实习经历，最近是在xxx公司的xxx部门担任数据分析实习生，主要负责xxx项目的分析工作，此前在xxx公司的xxx部门担任数据分析实习生，主要负责xxx方面的分析工作，除此之外还在xxx公司担任过数据分析实习，负责的是xxx模块的分析工作。以上就是我的自我介绍，谢谢。
解析：自我介绍不需要过于复杂，需要介绍实习经历和每段实习所负责的大概内容即可，引导面试官之后去深挖简历上的实习。


======= python-2 =======

题目1：6.学Python多久（招联金融）
答案：python在我的实习中和项目中都是经常用的，在其中用python做数据处理、特征筛选、数据可视化和数据建模。能够熟练使用numpy、pandas、matliplot和sklearn包中的函数。
解析：考察python熟练程度

题目2：7.Python处理脚本都做过哪些东西呀（经纬恒润）
答案：我们要完成网上的实验安全考试。系统快关闭的时候辅导员通知我们必须完成并且必须在90分以上才通过。那时刚好学了点爬虫，然后就先把题库抓下来，保存到本地。然后模拟登录，进入考试，从本地题库里匹配答案，提交表单。然后用py2exe编译成exe可执行文件，出于学习与交流的目的，把程序发给班上的同学了。
解析：

题目3：8.会用R语言和python是吗？（快手）
答案：会的。在学校的xxx课程上，我们是用的R语言进行编程，并且大作业是需要用R语言完成xxx项目，在这门课中我也从一个R语言小白成长了一点。Python是我自己在课外学习的，并且在xx项目/实习中我用python来做数据处理和数据建模的工作，除此之外还会用python做一些可视化的图表。
解析：需要说自己会用的模块和使用的地方。

题目4：9.Python数据处理的常用函数（小米）
答案：数据处理主要用的就是pandas里面的函数。
去重：drop_duplicates()
填充缺失值:fillna()
处理某列:apply(), lambda函数
替换函数：replace()
解析：

题目5：10.python方面的读取json（美团）
答案：如果你要处理的是文件而不是字符串，你可以使用 json.dump() 和 json.load()来编码和解码 JSON 数据。 例如： # 写入一个json数据 with open('data.json', 'w') as f：json.dump(data, f) ；with open('data.json', 'r') as f：data = json.load(f)
解析：


======= python-3 =======

题目1：11.python题map一道（MobTech）
答案：map() 会根据提供的函数对指定序列做映射。map(function, iterable, ...)---function：函数；iterable：一个或多个序列
解析：

题目2：12.Python你常用的包有哪些？（字节跳动）
答案：1.numpy，用来做多维数组的运算的，之前在xx项目中用numpy做一些数据运算的工作。2.pandas，用来处理表格和复杂数据的，我主要用它在数据清洗这一步。
3.matplotlib，用来数据可视化，在对处理好的数据我想简单看一下频数分布或者相关性之类的很轻松的可以画出图片。
4.sklearn，用户机器学习建模，在数据建模这部分用到，我经常用的模型有随机森林和xgb（引导面试官问这两者的区别）。
解析：用过的包+用途+用这个做了什么

题目3：13.工作中python会用到哪些？（作业帮）
答案：1.做大数据清洗工作，在xx的实习/项目过程中，我用python中的numpy和pandas完成了xx量级的数据清洗工作，也让我对这些函数的参数有了更全面的认识。
2.做数据建模工作，在xxx的项目中，我用sklearn中的xxx算法，完成了xxx，最后精度达到了xxx。
解析：

题目4：14.python：数组逆序输出（快手）
答案：if __name__ == '__main__':
    a = [9,6,5,4,1]
    N = len(a) 
    print a
    for i in range(len(a) / 2):
        a[i],a[N - i - 1] = a[N - i - 1],a[i]
    print a
解析：


======= 行业分析 =======

题目1：1.对你来说面对这样一个全新的行业，你并不是很熟悉，如果你接手这样一份工作，到岗后你会通过哪些方面的努力去适应这份工作，把这份工作做好？（京东）
答案：1.和同事、上级沟通，明确自己的目标，需要在短期内达到什么程度。2.在知乎、公众号等渠道搜寻相关行业的信息，主动去了解该行业情况。3.整理数据字典，了解目前数据表情况，尽快上手数据表和各个指标的统计口径。
解析：

题目2：2.谈谈对在线教育行业的理解（作业帮）
答案：首先，该行业中长期来看会往哪个方向走：比如在线教育行业：国内市场继续供小于求，长期来看市场规模非常大；中期来看各家互联网教育企业都在抢占市场份额烧钱中。
其次，识别出这个行业的关键风险和成功的驱动因素：比如在线教育行业：市场价格风险，成本风险，高资本支出，政治风险。
最后，这个行业成功的企业和失败的企业大概都有哪些，为什么？：比如在线教育行业：成功的企业比如新东方、猿辅导，失败的比如跟谁学（股价大跌）。
解析：

题目3：3.谈谈对短视频行业的理解（快手、四达时代）
答案：首先，该行业中长期来看会往哪个方向走：短期和长期该行业都有着蓬勃向上的发展趋势，市场规模非常庞大，18年增长率超过了700%，虽然现在增长率放缓，但规模仍在增长。
其次，识别出这个行业的关键风险和成功的驱动因素：内容生产者的质量，人们碎片化的时间等（本质上是内容行业，需要靠内容吸引用户）
最后，这个行业成功的企业和失败的企业大概都有哪些，为什么？：现阶段仍有大量产品进场，但是市场为红海，头部效应明显，抖音快手占比非常大。因为抖音和快手的优质内容创作者数量较大，并且其他失败的app没有自身品类特色，抖音风快手风趋同，没有吸引足够的用户流量。
解析：

题目4：4.谈谈对游戏行业的理解（吉比特&雷霆游戏、西山居）
答案：首先，该行业中长期来看会往哪个方向走：目前手游市场正在快速增长阶段，很多之前的页游正在转型成手游，并且游戏在很多企业中收入占比非常大，腾讯的游戏收入占了总收入的45%，哔哩哔哩的游戏收入也占了总收入的40%，前景非常广阔。
其次，识别出这个行业的关键风险和成功的驱动因素：政治风险、成本风险、竞品风险；成功主要是由于人们可以从游戏中得到即时 的正反馈，把享受折现，促使人分泌多巴胺，折现率越高，游戏越吸引人。
最后，这个行业成功的企业和失败的企业大概都有哪些，为什么？：成功的产品，比如王者荣耀，原神，明日方舟，王者荣耀主要依靠腾讯庞大的社交网络传播以及对lol的成功借鉴改良。近几年，二次元手游赛道也非常火热，因为现在的二次元手游消费群体是当年热爱动漫的那群年轻人，并且二次元手游的流水也非常可观。
第2~4题整体
解析：从三个方面：1.该行业中长期来看会往哪个方向走。2.识别出这个行业的关键风险和成功的驱动因素。3.这个行业成功的企业和失败的企业大概都有哪些，为什么？一般问你面试的行业都是前景非常好的。


======= 职业规划-1 =======

题目1：1.为什么选择我们公司（滴滴、拼多多、京东）
答案：公司的基础能力：贵公司是中国TOPxxx，在xxx领域有绝对的市场份额，最近盈利xxx，新进入xxx市场，比竞争对手优势在于xxx等等
岗位的能力：贵公司的大数据能力很好，擅长用数据进行xxx分析，在这个岗位上出了很多厉害的xxx人员等等
自我匹配：从大一开始就向往贵公司的xxx岗位，因为公司的xxx理念和我一致，在岗位上能学到xxx能力，比起之前或者在学校中能从xxx方面提高自己。
主要是从上面几个方面去回答这个问题，记得要结合自身经历来描述，最好不要说太多空话，表现出真诚
解析：这道题主要考察对面试公司的熟悉程度，需要提前准备对面试公司的一些基础了解，我建议从公司的基础能力、岗位的能力及自我匹配来回答

题目2：2.目前是否还在xx实习？为什么不继续（美团）
答案：自身的发展：经过一段时间的实习，已经基本熟悉目前公司的各个流程，所负责的方向已经做得比较深入所以受限制，所以想要寻求新的突破点。或者。公司目前发展得方向和我自己认定得方向不是很匹配，我自己想要做xxx。
目前公司限制：目前实习的公司能给我的资源比较受限制，包括项目和数据，在项目上已经到了重复劳动的程度，所以我想寻求点突破，在数据上，目前公司的数据量级和贵公司相差较大，所以希望有个更好的平台发展
解析：这道题主要是了解面试者目前的情况，可以按照真实情况回答，面试官可以从不继续的原因中挖掘面试者的问题，所以尽量不要去抱怨目前的情况，主要以有更好的发展平台为主。可以从目前公司的限制，自身的发展来回答

题目3：3.想通过这个岗位收获什么（快手）
答案：自身的发展：从大一开始我就认定了自己要从事xxx的岗位，所以我阅读的大量相关的书籍，并从中总结出的xxx岗位的要点，比如xxx,xxx,xxx ,在有了这些基础理论后我还学习了许多岗位相关的能力，比如xxx，xxx。有了这些基础知识和理论后，我就开始寻找实习，在实习中我的表现是xxx，通过实习我认定我的发展方向就是这个岗位
岗位的能力：这个岗位要求的能力是xxx，xxx。我在过去的实习中证明过我xxx，xxx的能力，比如xxxx。所以我觉得我很匹配这个岗位。但是之前实习的这个岗位，由于公司xxx，xxx的限制，我感觉我提升的空间不大了。先比与之前公司这个岗位，贵公司这个岗位有xxx，xxx的优势，所以我想通过这个岗位获得xxx，xxx的能力
解析：这道题主要考察的是面试者对自己岗位的一个思考，思考自己想要的和岗位能给的一个匹配。主要从自身的发展、岗位的能力要求等来解答

题目4：4.为什么不做算法？（字节跳动）
答案：首先，我并不是计算机的专业出身，所以在编程的能力上可能还有所欠缺。其次，算法要求xxx，xxx的能力，但是我觉得我目前的能力并不匹配，所以在算法这个道路上我的竞争优势并不大，我擅长的是xxx，xxx，并且在之前的实习中我也验证我自己xxx，xxx的能力，所以我觉得xxx还是我想要走的方向。但是如果非要我往一个方向走的话，我觉得我也愿意去做尝试，学习算法能力。
解析：这道题主要考察的是面试者对自己职业方向的一个思考，只要能给出自己的思考就可以

题目5：5.喜欢技术还是商业（美团）
答案：首先，我并不是计算机的专业出身，所以在技术的能力上可能还有所欠缺。其次，技术要求xxx，xxx的能力，但是我觉得我目前的能力并不匹配，所以在算法这个道路上我的竞争优势并不大，我擅长的是商业，并且之前的实习也都是和商业相关的岗位，所以我更加熟悉商业的流程及所需要的能力，相比与技术会更有优势。但是如果在工作中需要用到技术方面的能力的话，我也愿意去学习。
解析：这道题主要考察的是面试者对自己职业方向的一个思考，只要能给出自己的思考就可以


======= 职业规划-2 =======

题目1：6.了解美团吗？（美团）
答案：美团的产品丰富，用户体量也大，能够在这里更好的发挥自己的所长。同时，美团是一家处于快速增长中的公司，个人成长的空间也相对比较大，且注重人才的培养，这对一个校招生来说很吸引人。
解析：这道题考察的是面试者对面试公司的了解程度，建议在面试前好好了解下面试的公司，做好充足的准备

题目2：7.平时都玩什么游戏和小游戏？（字节跳动）
答案：我平常主要玩moba类型的游戏，比如xxx，xxx。和fps游戏，比如xxx，xxx。在小游戏方面，我主要玩的是xxx，xxx，其中我最熟悉的是xxx，xxx（将面试官引导到这几个你准备过或者熟悉的游戏，以便于回答问题）。因为xxx，好玩的点在与xxx，xxx。与其竞争对手相比，这个游戏的优势在于xxx，xxx。
解析：这道题主要是考察面试者对游戏方面的熟悉程度，在回答这个问题是尽量说自己非常非常熟悉的游戏，才不会在后续的问题中被问倒，因为这个问题只是一个引导，一般接下来会就你说的游戏展开提问

题目3：8.为什么寻找新的机会？（字节跳动）
答案：自身的发展：经过一段时间的实习，已经基本熟悉目前公司的各个流程，所负责的方向已经做得比较深入所以受限制，所以想要寻求新的突破点。或者。公司目前发展得方向和我自己认定得方向不是很匹配，我自己想要做xxx。
目前公司限制：目前实习的公司能给我的资源比较受限制，包括项目和数据，在项目上已经到了重复劳动的程度，所以我想寻求点突破，在数据上，目前公司的数据量级和贵公司相差较大，所以希望有个更好的平台发展
解析：这道题主要是了解面试者目前的情况，可以按照真实情况回答，面试官可以从回答的原因中挖掘面试者的问题，所以尽量不要去抱怨目前的情况，主要以有更好的发展平台为主。可以从目前公司的限制，自身的发展来回答

题目4：9.选择offer时，会考虑哪些因素？（字节跳动）
答案：作为毕业生，我在选择offer的时候，主要考虑职业发展、公司发展、个人薪资等因素。第一考虑的是职业发展，主要是第一份工作的岗位是否和我自己兴趣的方向匹配，比如我兴趣的是xxx，所以我在选择职业的时候会往这个上靠近。第二考虑是公司发展，只有公司有稳定的发展，我的个人发展也才有空间，所以对公司的选择，或者说对团队的选择也都很重要。最后考虑的是薪资，因为作为应届毕业生，工资其实没有那么重要，主要是学习一些能力，所以对薪资的要求在平均线左右就好。
解析：这道题主要是了解面试者目前的情况，可以把真实情况和想法跟面试官聊，主要是以相互了解为主，注意回答的时候应该要有逻辑回答

题目5：10.想要选择哪个城市定居？（字节跳动）
答案：作为南方人，我希望在南方定居，但是至于工作的地方的话，作为毕业生，我在哪里工作都可以，主要是考虑适合的工作，并不考虑地点，因为刚毕业出来应该多多在职位上打基础，尽快学习职业知识和职场经验，为未来发展打基础。所以在我考虑第一份工作的时候，城市的优先级并不是很高
解析：这道题主要是了解面试者目前的情况，可以把真实情况和想法跟面试官聊，主要是以相互了解为主，注意回答的时候应该要有逻辑回答


======= 职业规划-3 =======

题目1：11.还有其他offer吗？（字节跳动、招商银行信用卡）
答案：我目前手上的确有两个offer。分别是xxx和xxx，但是我感觉他们的公司和岗位并不是我想要的，原因是xxx，xxx。我更希望能获得贵公司的offer，因为我觉得我目前和贵公司的xxx岗位能力要求比较匹配，所以贵公司对于我自己来说，比较适合我的职业发展，也希望我能够为贵公司提供一些我自己的帮助
解析：这道题主要是了解面试者目前的情况，可以把真实情况和想法跟面试官聊，主要是以相互了解为主，注意回答的时候应该要有逻辑回答

题目2：12.期待薪资是多少，可以什么时候入职？（字节跳动）
答案：因为作为应届毕业生，薪资其实没有那么重要，我更看重的是学习一些能力和找到未来的发展方向，所以对薪资的要求在平均线左右就好。一般的岗位都能在offershow上看到大致的水平，所以只要和上面的薪资差不太多，我都能接受。入职的话，在完成毕业论文和学习的规定后就能够立即入职，因为我也想早点接触工作，积累经验。
解析：这道题主要是了解面试者目前的情况，可以把真实情况和想法跟面试官聊，甚至可以反问面试官这边能给的薪资大概是什么范围，主要是以相互了解为主

题目3：13.你了解这个岗位是做什么的吗？符合你的职业规划吗？（字节跳动）
答案：以我过去的实习经历来说，这个岗位主要负责的是xxx，xxx。对应所需要的能力是xxx，xxx。在我过去的实习经历中，我已经掌握了这个岗位大致的运转流程以及对其中的关键性指标比较熟悉，但是我在xxx，xxx方向上还需要努力，所以我希望能在贵公司获得锻炼xxx的机会，让我有更好的发展。这个岗位上所做的事，很适合我的职业规划，因为我的职业规划是xxx，所以我希望能够在贵公司的该岗位上继续锻炼自己。
解析：这道题主要是了解面试者对岗位的了解，以及对自己的自身规划，需要提前准备一套属于自己的回答模板来应对，这种题十分重要，可以考察出面试者对自己所做的事情是否有思考

题目4：14.你认为这个岗位的核心能力是什么？（字节跳动）
答案：我认为这个岗位可以从三个方面来看核心能力：
业务能力：在业务上需要能够快速理解基本的业务逻辑，对常用的业务流程必须十分熟悉，能够快速理解未接触过的业务流程，和业务人员能够有效的沟通需求，达成目标。
数据能力：在数据上能够从取数到清洗都十分熟练，能够高效的利用hive、sql等数据库平台取数，在数据处理上能够利用python高效处理大量级的数据
分析能力：能够掌握一些基本的数据分析框架，并能够将框架应用到日常分析中，能够发现数据中存在的问题，并能够寻找到问题的根源再解决问题
解析：这道题主要是了解面试者对岗位的了解，需要提前准备一套属于自己的回答模板来应对，这种题十分重要，可以考察出面试者对自己所做的事情是否有思考

题目5：15.有什么发展规划（贝壳找房、京东、字节跳动、美团、百度、中电十所）
答案：我目前对自己的规划是，在这次校招中先找到一份对自己职业生涯有帮助的工作，来摸清自己未来的方向。在通过一段时间的工作后，希望能够认定自己的方向，并逐渐主导项目，将每一个项目做到最好。在三到五年后希望能够做一个leader，来主导一个方向的项目。希望自己能够稳定得一步一步成长。
解析：这道题主要是了解面试者对自己的自身规划，需要提前准备一套属于自己的回答模板来应对，这种题十分重要，可以考察出面试者对自己的未来发展是否有思考


======= 业务与用户分析-6 =======

题目1：27. 分析的y，也就是因变量是什么（ATL）
答案：因变量是因为自变量的变化而产生的现象变化或结果，也叫函数值。
解析：

题目2：28. 假如在天猫上有两款商品，如何分析它们的优势、劣势以及它们之间的差异，并根据结果给出相应的建议，思考5分钟再回答（三诺生物）
答案：可以从价格、销量、评价和商品介绍四个方面对比两款商品的优劣势和差异。可以按照自己的偏好设置权重，将价格、销量、评价和商品介绍量化打分后进行加权，得到最后的得分帮助自己选择。
解析：

题目3：29. 讲述一个在实习中遇到的异动指标分析的实例（字节跳动）
答案：我先简单介绍一下背景：是在xxx过程中我们发现xxx指标出现异常，于是我们需要找到问题原因。随后我们从xx和xx维度进行拆解，发现xx维度出现了异常。在我们与产品/技术团队沟通后发现是由于xx原因造成的xx指标异常。最后我们想到可以用xxx方法解决这个异常，并推动运营/产品/技术对这一策略进行落地。
解析：项目背景+具体问题+分析过程+分析结论+策略落地

题目4：30. 情景是直播打赏，给主播刷礼物。平台希望通过刺激不付费的用户消费（提升付费率），来提升直播收入，所以现在上线了单价较低的打赏礼物。打个比方，原来最低价格的礼物是10抖币，现在新增的礼物只需要付2抖币。但发现直播的收益并没有明显提升，该如何分析？（字节跳动）
答案：首先，我们需要对用户进行分层，可以分为上线较低打赏礼物前不付费用户和付费用户，再细分的话可以把付费用户按照付费金额划分区间。统计出各用户群的消费变动。若未付费用户转变为付费用户，则说明策略有效。
解析：考察能够想到用户分层。

题目5：31. 平时分析中对接的人员（滴滴）
答案：产品/运营人员：对接产品/运营的数据需求并搭建数据看板。
分析人员：进行专题分析和异常分析，并推动策略落地。
技术人员：数据平台出现bug以及看板报错情况，需和技术人员进行沟通。
解析：


======= 业务与用户分析-7 =======

题目1：32. 夏天北京网约车呼叫量增加，分析原因（滴滴）
答案：对北京路段网约车始发地进行划分，例如分为xx商圈，xx机场等，查看是否存在哪些路段网约车车辆突增的趋势。随后对该路段情况进行分析，是否存在气候、工作等原因。针对这些原因，我们可以做出相应的策略来提高我们日常网约车的数量。
解析：

题目2：33. 现在的工作中涉及到分析的具体工作有哪些？（京东）
答案：专题分析：对业务出现的异常情况进行专题分析，定位问题找出原因，并制订解决策略，推进落地；
临时分析需求：对小数据需求进行分析（指标监控），例如用户点赞行为分析；
报表分析：制作实时更新的可视化报表，实时定位异常情况。
解析：分2-3各层面，并列举实习中的工作实例。

题目3：34. 除了指标的监控之外，会有分析相关的工作吗？（京东）
答案：专题分析：我独立负责过xxx的专题分析，背景是我们发现xxx现象（可以是指标异常也可以是其他现象），随后我们通过xx和xx层面分析了xx指标，发现了xx现象，于是我们想了xxx策略，并与运营和技术沟通，推进策略落地，策略落地后，我们观测xx指标，发现xx指标的xx变动，表明我们的策略是正向的。
解析：可以说一下自己做的专题分析，从背景介绍+分析思路+策略推进+落地效果来介绍。

题目4：35. 举一个具体的例子，在工作中分析了什么问题，对公司有哪些影响和风险，你是怎么给出方案去改善去落地的？（京东）
答案：（项目背景）在xx实习的时候，我们全量上线了一个短视频流的功能，但是全量上线后的数据表现没有达到预期，所以我们做了关于这个短视频流稿件的分析。
（分析过程）我们分别从近一周被消费的短视频情况、高粉博主发布的视频消费情况以及消费情况好的视频的详情分析。
（分析结论）结果发现虽然我们有好的视频但是好的视频并没有得到好的消费。
（策略落地）所以我们去与运营团队沟通分析什么是符合我们app特色的视频，并与算法团队沟通推荐策略。
（落地影响）在我们推进后一周，xx数据和xx数据得到了显著的提高。
解析：

题目5：36. 你现在独立做分析报告吗？多久做一次？（京东）
答案：之前有尝试过做xx项目的分析报告，我是从xxx方面进行分析，后和我的mentor讨论发现还可以从xxx方面进行分析，随后我们得出了xxx结论，想出来xx策略。大约一个月两次的样子，没有固定的时间，是业务出现问题或者我们在日常分析中发现问题后才回去做分析报告。
解析：不止是回答有分析报告，最好介绍之前准备的分析项目报告，引导面试官接下来的问题。


======= 业务与用户分析-8 =======

题目1：37. 假设给一个数据集，我会选择的分析步骤是什么样的？（快手）
答案：数据清洗（删除重复项、填充缺失值和删除异常值等）--思考需要分析的问题，得到分析思路--指标整合--可视化
解析：

题目2：38. 就快手而言，要如何分析在没有营销手段拉动的情况下，什么样的作者/作品类型/作品内容自然增长是具有快速增长增量的（快手）
答案：首先，制订指标体系（七天内涨粉量、播转粉率、点赞率等）识别出快速增长的作者/作品。将这些作者的明细分为消费和供给两方面进行分析。消费包括这些作者的稿件的点赞情况、点赞率情况等指标；供给包括投稿频次，稿件属于哪一类型等。通过这些数据来看是否具有一定的共性规律性。
解析：

题目3：39. 所以你擅长的内容实际上是在现成数据集上做挖掘分析对吗？（快手）
答案：不是，我熟练掌握python对数据集清洗，以及sql从数据库中取出数据。对于其他网络数据，我也会使用python爬虫从网站上爬取数据。
解析：

题目4：40. 实习中如何分析用户流失路径（字节跳动）
答案：做埋点。用户的流失率的分析需要统计次日留存，三日留存，七日留存和一月留存，我们的流程是：
1、画出用户地图，每一步埋点，最后通过对数据的分析判断每一个步骤上的流失率，
2、优化具体的操作步骤，看题主描述的引导页应该是注册——选择喜欢音乐类型——选择喜爱歌手——APP首页，至于进入后的其他环节不太清楚，要对产品核心功埋点，分析每一个核心功能每一个步骤，分析用户在哪一步流失，这些数据的收集和分析有助于优化该功能，提高用户留存。
解析：

题目5：41. 工作中做过什么专题分析（字节跳动）
答案：介绍专题分析的背景（为什么要做这个专题）-->分析思路（从什么方面进行分析，分析了哪些指标）-->分析结论（发现了什么现象，找出了什么原因）-->策略落地（针对这些现象实施什么策略，与哪些部门进行沟通）-->落地效果
解析：


======= 业务与用户分析-9 =======

题目1：42. 我们假设，飞书现在视频会议功能用户量骤减，你会怎么分析（字节跳动）
答案：首先，验证数据的准确性，不是由于底层数据库或数据口径出现问题而出现的骤降。
随后，将用户进行分层，可以从地区、时段、行业等维度进行划分，看哪部分的用户显著下降。
最后从内部和外部进行原因分析，内部从产品、运营、技术层面找原因，外部从竞品找原因。
解析：

题目2：43. 那要是你作为一个内部人员的话,怎么分析这些数据呢（字节跳动）
答案：首先，我会先从产品现状发现问题，针对问题进行分析。
随后，我会对问题进行拆解，再构建数据指标体系。
最后我会对用户进行分层，对各个层级的用户统计数据指标体系，看各层级用户是否有明显区别，能够解释问题。
解析：

题目3：44. 说一个你在实习中做异动指标分析的例子（滴滴）
答案：在某视频直播平台实习时，我做过优质传输率异常值分析。这里的优质传输率指的是a和b在视频通话过程中的丢包情况，优质传输率一般在95%以上，但是当时突然下降到了85%。对此，我们将数据按照省份、传输机房、运营商等维度进行拆解，看各个维度的优质传输率情况。我们发现有两个省份的优质传输率很低，并且后来发现是机房原因，我们把该省份的传输端口手动接入附近省份，次日优质传输率恢复。
解析：

题目4：45. 如果最近DUA有较大抖动，你怎么去找核心原因？可以添加什么因素在这个分析模型中？（字节跳动）
答案：首先确定是否是底层表或统计口径的问题造成的较大抖动。随后对用户进行分层，分层的维度可以有新老用户、各年龄段用户等，找到是哪部分用户的DAU下滑明显。随后从产品内部和外部进行分析，内部可以从产品、运营和技术上找原因，外部可以从政治经济和竞品分析找原因。
解析：

题目5：46. 你刚才提到了版本你会用什么方法分析。（新版本上线分析）（字节跳动）
答案：我主要从以下几个方面写的分析报告：
1.基于什么样的背景（在什么样背景下版本更新了）。
2.为了达成怎样的目的（版本更新针对什么问题，针对哪些人群）。
3.做了怎样的功能（新功能/改动功能有哪些）。
4.监控了哪些指标项。
5.各指标得到的结论。
6.总结这次版本更新的表现。
解析：

